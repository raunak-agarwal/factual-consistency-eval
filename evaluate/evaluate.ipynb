{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, balanced_accuracy_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# import os\n",
    "# import ray\n",
    "# ray.init()\n",
    "\n",
    "# os.environ[\"RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE\"] = \"1\"\n",
    "# os.environ[\"MODIN_MEMORY\"] = \"10000000000\"\n",
    "\n",
    "# import modin.pandas as mpd\n",
    "# import modin.config as cfg; print(cfg.CpuCount.get()); cfg.CpuCount.put(12); print(cfg.CpuCount.get())\n",
    "\n",
    "\n",
    "# Increse column width to display the full content of the columns\n",
    "pd.set_option('display.max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe26727758354ec7aabc6b0771f19eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c75b029a304908b83927e2333024e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/15.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709a224a041a4fd3a38dc333037af64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a20a67273348c0a8e87d3a58517354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/15080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f0015e150d4013a0c441794e740c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/12949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12949\n",
      "subset\n",
      "AggreFact-CNN     558\n",
      "AggreFact-XSum    558\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tom o'carroll , a leading member of the notorious paedophile information exchange ( above ) , has joined the supporters of the media pressure group hacked off\\na leading member of the notorious paedophile information exchange , which campaigned to legalise child sex in the 1970s and 80s , has joined the supporters of the media pressure group hacked off .\\ntom o'carroll , a former open university information officer and formerly a key activist for pie , attended a hacked off rally in the houses of parliament on february 25 to lobby mps for state involvement in media regulation .\\nthe organisation , set up in the wake of the phone-hacking scandal , is campaigning against what it sees as the ` biased and unfair ' independent press standards organisation .\\nit wants mps to set up a statuto...</td>\n",
       "      <td>tom o'carroll is a former open university information officer and formerly a key activist for pie . \\nhe attended a hacked off rally in the houses of parliament on february 25 to lobby mps for state involvement in media regulation . \\nthe organisation is campaigning against what it sees as the ` biased and unfair ` independent press standards organisation .</td>\n",
       "      <td>Yes</td>\n",
       "      <td>AggreFact-CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>The review into 22 abuse cases in Northern Ireland criticised the authorities for not doing enough.\\nThe young people went missing a number of times over a 20-month period while being looked after in the care system.\\nThe Police Service of Northern Ireland (PSNI) said it has recently made policy changes aimed at keeping children safe.\\nIn September 2013, the PSNI said it had begun a major investigation into the sexual exploitation of children and young people who had gone missing from care in Northern Ireland.\\nOfficers said they had identified 22 people, aged between 13 and 18, who may have been sexually exploited.\\nThe PSNI investigation was known was Operation Owl.\\nThursday's report, examining the PSNI response, has been published by the Safeguarding Board for Northern Ireland.\\nIt...</td>\n",
       "      <td>A police investigation into the sexual exploitation of teenagers who went missing from care was `` limited and inconsistent'', a report has found.</td>\n",
       "      <td>No</td>\n",
       "      <td>AggreFact-XSum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              source  \\\n",
       "1    tom o'carroll , a leading member of the notorious paedophile information exchange ( above ) , has joined the supporters of the media pressure group hacked off\\na leading member of the notorious paedophile information exchange , which campaigned to legalise child sex in the 1970s and 80s , has joined the supporters of the media pressure group hacked off .\\ntom o'carroll , a former open university information officer and formerly a key activist for pie , attended a hacked off rally in the houses of parliament on february 25 to lobby mps for state involvement in media regulation .\\nthe organisation , set up in the wake of the phone-hacking scandal , is campaigning against what it sees as the ` biased and unfair ' independent press standards organisation .\\nit wants mps to set up a statuto...   \n",
       "623  The review into 22 abuse cases in Northern Ireland criticised the authorities for not doing enough.\\nThe young people went missing a number of times over a 20-month period while being looked after in the care system.\\nThe Police Service of Northern Ireland (PSNI) said it has recently made policy changes aimed at keeping children safe.\\nIn September 2013, the PSNI said it had begun a major investigation into the sexual exploitation of children and young people who had gone missing from care in Northern Ireland.\\nOfficers said they had identified 22 people, aged between 13 and 18, who may have been sexually exploited.\\nThe PSNI investigation was known was Operation Owl.\\nThursday's report, examining the PSNI response, has been published by the Safeguarding Board for Northern Ireland.\\nIt...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      target  \\\n",
       "1    tom o'carroll is a former open university information officer and formerly a key activist for pie . \\nhe attended a hacked off rally in the houses of parliament on february 25 to lobby mps for state involvement in media regulation . \\nthe organisation is campaigning against what it sees as the ` biased and unfair ` independent press standards organisation .   \n",
       "623                                                                                                                                                                                                                       A police investigation into the sexual exploitation of teenagers who went missing from care was `` limited and inconsistent'', a report has found.   \n",
       "\n",
       "    label          subset  \n",
       "1     Yes   AggreFact-CNN  \n",
       "623    No  AggreFact-XSum  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set \n",
    "\n",
    "test = pd.read_json(\"../data/test-data/final_combined_test_data.json\", lines=True)\n",
    "\n",
    "all_scores_df = test.copy()\n",
    "\n",
    "print(len(test))\n",
    "test.label.value_counts()\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "llm_aggrefact = load_dataset(\"lytang/LLM-AggreFact\")\n",
    "llm_aggrefact = llm_aggrefact['test'].to_pandas()\n",
    "\n",
    "llm_aggrefact = llm_aggrefact.rename(columns={'doc': 'source', 'claim': 'target', 'label': 'label', 'dataset': 'subset'})\n",
    "\n",
    "# replace 1 and 0 with Yes and No\n",
    "def replace_label(row):\n",
    "    label = row['label']\n",
    "    if label == 1:\n",
    "        row['label'] = 'Yes'\n",
    "    else:\n",
    "        row['label'] = 'No'\n",
    "    return row\n",
    "print(len(llm_aggrefact))\n",
    "llm_aggrefact = llm_aggrefact.apply(replace_label, axis=1).drop_duplicates(subset=['source', 'target'])\n",
    "\n",
    "y_aggrefact = llm_aggrefact[llm_aggrefact['subset'].isin( [\"AggreFact-CNN\", \"AggreFact-XSum\"])]\n",
    "print( y_aggrefact['subset'].value_counts())\n",
    "\n",
    "y_aggrefact = y_aggrefact[['source', 'target', 'label', 'subset']]\n",
    "\n",
    "subsets_llm_aggrefact = [\"tofueval_meetingbank\", \"tofueval_mediasum\", \"WiCE\",\\\n",
    "    \"ExpertQA\", \"Reveal\", \"FactCheck-GPT\", \"ClaimVerify\", \"Lfqa\"]\n",
    "\n",
    "y_aggrefact.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggrefact_cnndm: 1017\n",
      "aggrefact_xsum: 1335\n",
      "bump_cnndm: 785\n",
      "halueval_cnndm: 19998\n",
      "fib_xsum: 3534\n",
      "fib_cnndm: 543\n",
      "llm_summaries_cnndm: 1829\n",
      "llm_summaries_xsum: 1726\n",
      "gumsum_gumsum: 95\n",
      "instrusum_instrusum: 458\n",
      "tofueval_mediasum: 725\n",
      "tofueval_meetingbank: 770\n",
      "diasumfact_QMSum: 569\n",
      "diasumfact_SAMSum: 669\n",
      "anli: 3200\n",
      "alisawuffles/WANLI: 5000\n",
      "scitail: 2126\n",
      "DeFacto: 1836\n",
      "DADC-NLI: 766\n",
      "FoolMeTwice: 1379\n",
      "WiCE: 358\n",
      "Seahorse: 4135\n",
      "Reveal: 1705\n",
      "ClaimVerify: 1087\n",
      "FactCheck-GPT: 1565\n",
      "ExpertQA: 3702\n",
      "Lfqa: 1911\n"
     ]
    }
   ],
   "source": [
    "# Print subset sizes\n",
    "for subset in test.subset.unique():\n",
    "    print(f\"{subset}: {len(test[test.subset == subset])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggrefact_cnndm: label\n",
      "Yes    0.885939\n",
      "No     0.114061\n",
      "Name: proportion, dtype: float64\n",
      "aggrefact_xsum: label\n",
      "Yes    0.508614\n",
      "No     0.491386\n",
      "Name: proportion, dtype: float64\n",
      "bump_cnndm: label\n",
      "No     0.873885\n",
      "Yes    0.126115\n",
      "Name: proportion, dtype: float64\n",
      "halueval_cnndm: label\n",
      "No     0.50005\n",
      "Yes    0.49995\n",
      "Name: proportion, dtype: float64\n",
      "fib_xsum: label\n",
      "No     0.858517\n",
      "Yes    0.141483\n",
      "Name: proportion, dtype: float64\n",
      "fib_cnndm: label\n",
      "No     0.823204\n",
      "Yes    0.176796\n",
      "Name: proportion, dtype: float64\n",
      "llm_summaries_cnndm: label\n",
      "Yes    0.911974\n",
      "No     0.088026\n",
      "Name: proportion, dtype: float64\n",
      "llm_summaries_xsum: label\n",
      "Yes    0.767092\n",
      "No     0.232908\n",
      "Name: proportion, dtype: float64\n",
      "gumsum_gumsum: label\n",
      "Yes    0.621053\n",
      "No     0.378947\n",
      "Name: proportion, dtype: float64\n",
      "instrusum_instrusum: label\n",
      "Yes    0.759825\n",
      "No     0.240175\n",
      "Name: proportion, dtype: float64\n",
      "tofueval_mediasum: label\n",
      "Yes    0.762759\n",
      "No     0.237241\n",
      "Name: proportion, dtype: float64\n",
      "tofueval_meetingbank: label\n",
      "Yes    0.805195\n",
      "No     0.194805\n",
      "Name: proportion, dtype: float64\n",
      "diasumfact_QMSum: label\n",
      "Yes    0.585237\n",
      "No     0.414763\n",
      "Name: proportion, dtype: float64\n",
      "diasumfact_SAMSum: label\n",
      "Yes    0.639761\n",
      "No     0.360239\n",
      "Name: proportion, dtype: float64\n",
      "anli: label\n",
      "No     0.665625\n",
      "Yes    0.334375\n",
      "Name: proportion, dtype: float64\n",
      "alisawuffles/WANLI: label\n",
      "No     0.6284\n",
      "Yes    0.3716\n",
      "Name: proportion, dtype: float64\n",
      "scitail: label\n",
      "No     0.603951\n",
      "Yes    0.396049\n",
      "Name: proportion, dtype: float64\n",
      "DeFacto: label\n",
      "Yes    0.583878\n",
      "No     0.416122\n",
      "Name: proportion, dtype: float64\n",
      "DADC-NLI: label\n",
      "No     0.537859\n",
      "Yes    0.462141\n",
      "Name: proportion, dtype: float64\n",
      "FoolMeTwice: label\n",
      "No     0.506164\n",
      "Yes    0.493836\n",
      "Name: proportion, dtype: float64\n",
      "WiCE: label\n",
      "No     0.689944\n",
      "Yes    0.310056\n",
      "Name: proportion, dtype: float64\n",
      "Seahorse: label\n",
      "Yes    0.53688\n",
      "No     0.46312\n",
      "Name: proportion, dtype: float64\n",
      "Reveal: label\n",
      "No     0.766569\n",
      "Yes    0.233431\n",
      "Name: proportion, dtype: float64\n",
      "ClaimVerify: label\n",
      "Yes    0.725851\n",
      "No     0.274149\n",
      "Name: proportion, dtype: float64\n",
      "FactCheck-GPT: label\n",
      "No     0.759744\n",
      "Yes    0.240256\n",
      "Name: proportion, dtype: float64\n",
      "ExpertQA: label\n",
      "Yes    0.802539\n",
      "No     0.197461\n",
      "Name: proportion, dtype: float64\n",
      "Lfqa: label\n",
      "Yes    0.586604\n",
      "No     0.413396\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Percentage of \"No\" in each subset\n",
    "\n",
    "for subset in test.subset.unique():\n",
    "    print(f\"{subset}: {test[test.subset == subset].label.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size:  62823\n",
      "Average source length:  413.05130286678445\n",
      "Average target length:  34.68107221877338\n"
     ]
    }
   ],
   "source": [
    "def get_length(row):\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    \n",
    "    row['length_source'] = len(source.split())\n",
    "    row['length_target'] = len(target.split())\n",
    "    \n",
    "    return row\n",
    "\n",
    "test = test.apply(get_length, axis=1)\n",
    "\n",
    "print(\"Test set size: \", len(test))\n",
    "print(\"Average source length: \", test.length_source.mean())\n",
    "print(\"Average target length: \", test.length_target.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggrefact_cnndm\n",
      "Size:  1017\n",
      "Average source length:  498.0540806293019\n",
      "Average target length:  54.52015732546706\n",
      "\n",
      "aggrefact_xsum\n",
      "Size:  1335\n",
      "Average source length:  324.84044943820226\n",
      "Average target length:  23.283146067415732\n",
      "\n",
      "bump_cnndm\n",
      "Size:  785\n",
      "Average source length:  696.5031847133758\n",
      "Average target length:  52.085350318471335\n",
      "\n",
      "halueval_cnndm\n",
      "Size:  19998\n",
      "Average source length:  663.1723172317231\n",
      "Average target length:  60.84253425342534\n",
      "\n",
      "fib_xsum\n",
      "Size:  3534\n",
      "Average source length:  231.25070741369552\n",
      "Average target length:  20.475099037917374\n",
      "\n",
      "fib_cnndm\n",
      "Size:  543\n",
      "Average source length:  390.81767955801104\n",
      "Average target length:  61.60957642725599\n",
      "\n",
      "llm_summaries_cnndm\n",
      "Size:  1829\n",
      "Average source length:  458.3428102788409\n",
      "Average target length:  69.32094040459268\n",
      "\n",
      "llm_summaries_xsum\n",
      "Size:  1726\n",
      "Average source length:  307.41077636152954\n",
      "Average target length:  25.01332560834299\n",
      "\n",
      "gumsum_gumsum\n",
      "Size:  95\n",
      "Average source length:  777.0842105263158\n",
      "Average target length:  27.063157894736843\n",
      "\n",
      "instrusum_instrusum\n",
      "Size:  458\n",
      "Average source length:  971.3427947598253\n",
      "Average target length:  96.81877729257641\n",
      "\n",
      "tofueval_mediasum\n",
      "Size:  725\n",
      "Average source length:  778.3379310344827\n",
      "Average target length:  18.904827586206896\n",
      "\n",
      "tofueval_meetingbank\n",
      "Size:  770\n",
      "Average source length:  779.2597402597403\n",
      "Average target length:  20.09090909090909\n",
      "\n",
      "diasumfact_QMSum\n",
      "Size:  569\n",
      "Average source length:  309.08260105448153\n",
      "Average target length:  23.1195079086116\n",
      "\n",
      "diasumfact_SAMSum\n",
      "Size:  669\n",
      "Average source length:  132.4932735426009\n",
      "Average target length:  9.959641255605382\n",
      "\n",
      "anli\n",
      "Size:  3200\n",
      "Average source length:  54.415625\n",
      "Average target length:  10.2196875\n",
      "\n",
      "alisawuffles/WANLI\n",
      "Size:  5000\n",
      "Average source length:  17.4838\n",
      "Average target length:  9.8322\n",
      "\n",
      "scitail\n",
      "Size:  2126\n",
      "Average source length:  16.849952963311384\n",
      "Average target length:  12.469896519285042\n",
      "\n",
      "DeFacto\n",
      "Size:  1836\n",
      "Average source length:  310.09640522875816\n",
      "Average target length:  16.633986928104576\n",
      "\n",
      "DADC-NLI\n",
      "Size:  766\n",
      "Average source length:  116.86031331592689\n",
      "Average target length:  10.122715404699738\n",
      "\n",
      "FoolMeTwice\n",
      "Size:  1379\n",
      "Average source length:  39.286439448875996\n",
      "Average target length:  13.719361856417693\n",
      "\n",
      "WiCE\n",
      "Size:  358\n",
      "Average source length:  88.32960893854748\n",
      "Average target length:  29.553072625698324\n",
      "\n",
      "Seahorse\n",
      "Size:  4135\n",
      "Average source length:  383.35259975816206\n",
      "Average target length:  22.47956469165659\n",
      "\n",
      "Reveal\n",
      "Size:  1705\n",
      "Average source length:  88.04574780058651\n",
      "Average target length:  9.715542521994134\n",
      "\n",
      "ClaimVerify\n",
      "Size:  1087\n",
      "Average source length:  1582.0239190432383\n",
      "Average target length:  19.6163753449862\n",
      "\n",
      "FactCheck-GPT\n",
      "Size:  1565\n",
      "Average source length:  87.11948881789138\n",
      "Average target length:  11.90479233226837\n",
      "\n",
      "ExpertQA\n",
      "Size:  3702\n",
      "Average source length:  432.89113992436523\n",
      "Average target length:  25.553484602917344\n",
      "\n",
      "Lfqa\n",
      "Size:  1911\n",
      "Average source length:  323.55468341182626\n",
      "Average target length:  22.345368916797486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print subset sizes and average lengths for each subset\n",
    "\n",
    "for subset in test.subset.unique():\n",
    "    subset_data = test[test.subset == subset]\n",
    "    print(subset)\n",
    "    print(\"Size: \", len(subset_data))\n",
    "    print(\"Average source length: \", subset_data.length_source.mean())\n",
    "    print(\"Average target length: \", subset_data.length_target.mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FactAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823\n",
      "62823\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/wanli       5000\n",
      "seahorse                 4135\n",
      "expertqa                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "lfqa                     1911\n",
      "defacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "reveal                   1705\n",
      "factcheck-gpt            1565\n",
      "foolmetwice              1379\n",
      "aggrefact_xsum           1335\n",
      "claimverify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "dadc-nli                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_samsum         669\n",
      "diasumfact_qmsum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "wice                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/wanli       5000\n",
      "seahorse                 4135\n",
      "expertqa                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "lfqa                     1911\n",
      "defacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "reveal                   1705\n",
      "factcheck-gpt            1565\n",
      "foolmetwice              1379\n",
      "aggrefact_xsum           1335\n",
      "claimverify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "dadc-nli                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_samsum         669\n",
      "diasumfact_qmsum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "wice                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "Index(['input', 'label', 'preds', 'subset', 'label_prob'], dtype='object')\n",
      "Index(['input', 'label', 'preds', 'subset', 'label_prob'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "base_bf16 = pd.read_csv('../data/eval-data/base-bf16.csv')\n",
    "large_bf16 = pd.read_csv('../data/eval-data/large-bf16.csv')\n",
    "\n",
    "\n",
    "print(len(base_bf16))\n",
    "print(len(large_bf16))\n",
    "print(base_bf16.label.value_counts())\n",
    "print(large_bf16.label.value_counts())\n",
    "print(base_bf16.subset.value_counts())\n",
    "print(large_bf16.subset.value_counts())\n",
    "print(base_bf16.columns)\n",
    "print(large_bf16.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_source_target(text):\n",
    "    \n",
    "    source = text.split('_target_')[1]\n",
    "    target = source.split('_source_')[0].strip()\n",
    "    source = source.split('_source_')[1].strip()\n",
    "    \n",
    "    return source, target\n",
    "\n",
    "# get_source_target(base_bf16.iloc[0]['input'])\n",
    "\n",
    "new_base_bf16 = base_bf16.copy()\n",
    "new_large_bf16 = large_bf16.copy()\n",
    "\n",
    "new_base_bf16['source'], new_base_bf16['target'] = zip(*new_base_bf16['input'].map(get_source_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = new_base_bf16.drop_duplicates(subset=['source', 'target'], inplace=False)\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64 preds\n",
      "Yes    36930\n",
      "No     25893\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64 preds\n",
      "Yes    37532\n",
      "No     25291\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 input  \\\n",
       " 61002  Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ It also mentions the need for a structural engineer in the planning department and the use of outside planned check services. _source_ Speaker 1: Five F recommendation to authorize the Interim City Manager to execute an agreement with CSG consulting services for professional plant services for 12 months. Permanent amount not to exceed 300,000. Speaker 0: And I pulled this item. I don't know if staff wants to present anything about it. I pulled it because it's for up to 300,000 for structural engineer or an engineering firm. And it's my understanding that we, the city had had had an engineer through that, resigned in Ju...   \n",
       " 13791  Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ Nevada woman receives distracted driving ticket for applying makeup while driving with a $200 fine. The statewide crackdown on distracted driving hopes for zero driving fatalities in 2015. _source_ A Nevada woman received a $200 ticket after she was pulled over for putting on makeup while she was behind the wheel as part of a statewide crackdown on distracted drivers. So what sort of beauty product was she applying while stopped at a red light? Lip balm. Stephanie Fragoso was cited on Wednesday, April Fools' Day, after she was stopped in Las Vegas by a Nevada Highway Patrol (NHP) trooper. Scroll down for video. Stephan...   \n",
       " \n",
       "       label preds                subset  label_prob  \n",
       " 61002   Yes   Yes  tofueval_meetingbank    0.668459  \n",
       " 13791    No   Yes        halueval_cnndm    0.999738  ,\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 input  \\\n",
       " 9602  Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ Legendary Australian cricket commentator Richie Benaud was known not only for his vast knowledge of the game, but also his ability to connect with viewers on a personal level. Alongside former cricketer David Lloyd, Benaud provided hours of insightful commentary to fans around the world. He built strong relationships with co-commentators Tony Greig and Bill Lawry and was known for his attention to detail and dry wit. Even in his later years, Benaud remained passionate about cricket and its various forms, including the fast-paced excitement of Twenty20. It is clear that he will be missed by sports fans around the world....   \n",
       " 5507  Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ Jockey Aidan Coleman wants to right past wrongs at The Grand National. Coleman prepares to ride the well-backed The Druids Nephew. The eight-year-old is a 12-1 shot for the £1million steeplechase this year. Coleman rode the seventh fence faller Stan six years ago. CLICK HERE for Sportsmail's 2015 Grand National sweepstake kit. _source_ Jockey Aidan Coleman is hoping he has received the call up for the ride that will finally help him banish his Crabbie's Grand National blues at Aintree on Saturday. The 26-year-old rides well-backed The Druids Nephew, stepping in for broken leg victim Barry Geraghty on the Neil Mulhollan...   \n",
       " \n",
       "      label preds          subset  label_prob  \n",
       " 9602    No    No  halueval_cnndm    0.850806  \n",
       " 5507   Yes   Yes  halueval_cnndm    0.998591  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(base_bf16.label.value_counts(), base_bf16.preds.value_counts())\n",
    "print(large_bf16.label.value_counts(), large_bf16.preds.value_counts())\n",
    "base_bf16.sample(2), large_bf16.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "      <th>subset</th>\n",
       "      <th>label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media reports. Journalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says. Andreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says. _source_ Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwings Flight 9525 insisted Wednesday that he was not aware of any video footage from on board the plane. Marseille prosecutor Brice Robin told CNN that \"so far no videos were used in the crash investigation.\" He a...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>0.998905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ A video showing the final moments of Germanwings Flight 9525 has been recovered by investigators from the wreckage site. Marseille prosecutor Brice Robin urged anyone who might have more footage to turn it over immediately. Andreas Lubitz, the co-pilot accused of deliberately crashing the plane, had a history of severe depression and suicidal tendencies. _source_ Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwings Flight 9525 insisted Wednesday that he was not aware of any video footage from on board the plane. Marseille prosecutor Brice Robin told CNN that \"so far no vid...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>0.096444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             input  \\\n",
       "0  Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media reports. Journalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says. Andreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says. _source_ Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwings Flight 9525 insisted Wednesday that he was not aware of any video footage from on board the plane. Marseille prosecutor Brice Robin told CNN that \"so far no videos were used in the crash investigation.\" He a...   \n",
       "1  Can the target text be inferred from the source text? In other words, is the target text factually consistent with the source text? Answer with a \"Yes\" or \"No\". _target_ A video showing the final moments of Germanwings Flight 9525 has been recovered by investigators from the wreckage site. Marseille prosecutor Brice Robin urged anyone who might have more footage to turn it over immediately. Andreas Lubitz, the co-pilot accused of deliberately crashing the plane, had a history of severe depression and suicidal tendencies. _source_ Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwings Flight 9525 insisted Wednesday that he was not aware of any video footage from on board the plane. Marseille prosecutor Brice Robin told CNN that \"so far no vid...   \n",
       "\n",
       "  label preds          subset  label_prob  \n",
       "0   Yes   Yes  halueval_cnndm    0.998905  \n",
       "1    No    No  halueval_cnndm    0.096444  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invert probs if preds = No\n",
    "\n",
    "def invert_prob(row):\n",
    "    preds = row['preds']\n",
    "    label_prob = row['label_prob']\n",
    "    if preds == 'No':\n",
    "        row['label_prob'] = 1 - label_prob\n",
    "    return row\n",
    "\n",
    "base_bf16 = base_bf16.apply(invert_prob, axis=1)\n",
    "base_bf16.head(2)\n",
    "large_bf16 = large_bf16.apply(invert_prob, axis=1)\n",
    "large_bf16.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Change \"No\" to 0 and \"Yes\" to 1\n",
    "\n",
    "def change(row):\n",
    "    label = row['label']\n",
    "    prediction = row['preds']\n",
    "    \n",
    "    if label == 'No':\n",
    "        row['label'] = 0\n",
    "    if label == 'Yes':\n",
    "        row['label'] = 1\n",
    "    \n",
    "    if prediction == 'No':\n",
    "        row['preds'] = 0\n",
    "    if prediction == 'Yes':\n",
    "        row['preds'] = 1\n",
    "        \n",
    "    return row\n",
    "\n",
    "base_bf16 = base_bf16.apply(change, axis=1)\n",
    "large_bf16 = large_bf16.apply(change, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "aggrefact_cnndm         0.685206\n",
       "aggrefact_xsum          0.740744\n",
       "alisawuffles/wanli      0.877220\n",
       "anli                    0.753980\n",
       "bump_cnndm              0.685735\n",
       "claimverify             0.799364\n",
       "dadc-nli                0.861109\n",
       "defacto                 0.773372\n",
       "diasumfact_qmsum        0.700476\n",
       "diasumfact_samsum       0.756583\n",
       "expertqa                0.594624\n",
       "factcheck-gpt           0.822948\n",
       "fib_cnndm               0.271905\n",
       "fib_xsum                0.820808\n",
       "foolmetwice             0.918891\n",
       "gumsum_gumsum           0.814972\n",
       "halueval_cnndm          0.598213\n",
       "instrusum_instrusum     0.574425\n",
       "lfqa                    0.885055\n",
       "llm_summaries_cnndm     0.843179\n",
       "llm_summaries_xsum      0.757090\n",
       "reveal                  0.900094\n",
       "scitail                 0.984603\n",
       "seahorse                0.720948\n",
       "tofueval_mediasum       0.781425\n",
       "tofueval_meetingbank    0.766602\n",
       "wice                    0.865959\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each subset calculate the AUC ROC score\n",
    "\n",
    "def calculate_auc(df):\n",
    "    return roc_auc_score(df['label'], df['label_prob'])\n",
    "\n",
    "\n",
    "\n",
    "base_bf16_auc = base_bf16.groupby('subset').apply(calculate_auc)\n",
    "base_bf16_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "aggrefact_cnndm         0.696788\n",
       "aggrefact_xsum          0.748482\n",
       "alisawuffles/wanli      0.889535\n",
       "anli                    0.833812\n",
       "bump_cnndm              0.769488\n",
       "claimverify             0.799725\n",
       "dadc-nli                0.899190\n",
       "defacto                 0.807595\n",
       "diasumfact_qmsum        0.623149\n",
       "diasumfact_samsum       0.759011\n",
       "expertqa                0.614970\n",
       "factcheck-gpt           0.840107\n",
       "fib_cnndm               0.546304\n",
       "fib_xsum                0.875578\n",
       "foolmetwice             0.940031\n",
       "gumsum_gumsum           0.827213\n",
       "halueval_cnndm          0.673818\n",
       "instrusum_instrusum     0.556923\n",
       "lfqa                    0.881214\n",
       "llm_summaries_cnndm     0.854328\n",
       "llm_summaries_xsum      0.758234\n",
       "reveal                  0.904887\n",
       "scitail                 0.992728\n",
       "seahorse                0.744268\n",
       "tofueval_mediasum       0.754100\n",
       "tofueval_meetingbank    0.758817\n",
       "wice                    0.887843\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_bf16_auc = large_bf16.groupby('subset').apply(calculate_auc)\n",
    "large_bf16_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_ = ['reveal', 'tofueval_mediasum', 'tofueval_meetingbank', 'wice', 'expertqa', 'claimverify', 'factcheck-gpt', 'lfqa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_bf16_llm_aggrefact = base_bf16[base_bf16['subset'].isin(subsets_)]\n",
    "large_bf16_llm_aggrefact = large_bf16[large_bf16['subset'].isin(subsets_)]\n",
    "\n",
    "y_base_bf16 = pd.read_csv(\"../data/eval-data/base-bf16-aggrefact-llm.csv\", )\n",
    "y_large_bf16 = pd.read_csv(\"../data/eval-data/large-bf16-aggrefact-llm.csv\", )\n",
    "\n",
    "\n",
    "y_base_bf16 = y_base_bf16.apply(change, axis=1)\n",
    "y_large_bf16 = y_large_bf16.apply(change, axis=1)\n",
    "\n",
    "\n",
    "base_bf16_llm_aggrefact = pd.concat([base_bf16_llm_aggrefact, y_base_bf16], axis=0)\n",
    "large_bf16_llm_aggrefact = pd.concat([large_bf16_llm_aggrefact, y_large_bf16], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(subset\n",
       " expertqa                3702\n",
       " lfqa                    1911\n",
       " reveal                  1705\n",
       " factcheck-gpt           1565\n",
       " claimverify             1087\n",
       " tofueval_meetingbank     770\n",
       " tofueval_mediasum        725\n",
       " aggrefact-cnn            558\n",
       " aggrefact-xsum           558\n",
       " wice                     358\n",
       " Name: count, dtype: int64,\n",
       " subset\n",
       " expertqa                3702\n",
       " lfqa                    1911\n",
       " reveal                  1705\n",
       " factcheck-gpt           1565\n",
       " claimverify             1087\n",
       " tofueval_meetingbank     770\n",
       " tofueval_mediasum        725\n",
       " aggrefact-xsum           558\n",
       " aggrefact-cnn            558\n",
       " wice                     358\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_bf16_llm_aggrefact.subset.value_counts(), large_bf16_llm_aggrefact.subset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 1    7725\n",
       " 0    5214\n",
       " Name: count, dtype: int64,\n",
       " preds\n",
       " 1    6857\n",
       " 0    6082\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 1    7725\n",
       " 0    5214\n",
       " Name: count, dtype: int64,\n",
       " preds\n",
       " 1    7474\n",
       " 0    5465\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_bf16_llm_aggrefact.label.value_counts(), base_bf16_llm_aggrefact.preds.value_counts(), large_bf16_llm_aggrefact.label.value_counts(), large_bf16_llm_aggrefact.preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tofueval_mediasum 725 0.68153622944615\n",
      "factcheck-gpt 1565 0.7334990068536048\n",
      "expertqa 3702 0.5668986246898311\n",
      "claimverify 1087 0.7107650496338072\n",
      "lfqa 1911 0.8071884280536139\n",
      "wice 358 0.7658751869278185\n",
      "tofueval_meetingbank 770 0.7093548387096774\n",
      "reveal 1705 0.798525911885364\n",
      "aggrefact-cnn 558 0.5734846097279126\n",
      "aggrefact-xsum 558 0.6815693078850973\n",
      "Average balanced accuracy:  0.7028697193812877\n",
      "\n",
      "claimverify 1087 0.7405070559113991\n",
      "expertqa 3702 0.5894884015616532\n",
      "tofueval_mediasum 725 0.6987152529542874\n",
      "tofueval_meetingbank 770 0.6860215053763441\n",
      "reveal 1705 0.8100544805127396\n",
      "wice 358 0.7998869314658787\n",
      "factcheck-gpt 1565 0.7721310595351001\n",
      "lfqa 1911 0.8011410472114635\n",
      "aggrefact-xsum 558 0.6903412377096587\n",
      "aggrefact-cnn 558 0.5775291522218721\n",
      "Average balanced accuracy:  0.7165816124460396\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "n = 0\n",
    "\n",
    "for subset in base_bf16_llm_aggrefact.subset.unique():\n",
    "    subset_data = base_bf16_llm_aggrefact[base_bf16_llm_aggrefact.subset == subset]\n",
    "    score = balanced_accuracy_score(subset_data['label'].to_list(), subset_data['preds'].to_list())\n",
    "    acc += score\n",
    "    size = len(subset_data)\n",
    "    print(subset, size, score)\n",
    "    n += 1\n",
    "\n",
    "print(\"Average balanced accuracy: \", acc/n)\n",
    "print()\n",
    "acc = 0\n",
    "n = 0\n",
    "\n",
    "for subset in large_bf16_llm_aggrefact.subset.unique():\n",
    "    subset_data = large_bf16_llm_aggrefact[large_bf16_llm_aggrefact.subset == subset]\n",
    "    score = balanced_accuracy_score(subset_data['label'].to_list(), subset_data['preds'].to_list())\n",
    "    acc += score\n",
    "    size = len(subset_data)\n",
    "    print(subset, size, score)\n",
    "    n += 1\n",
    "    \n",
    "    \n",
    "print(\"Average balanced accuracy: \", acc/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_set = pd.read_json(\"../data/test-data/final_combined_test_data.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggrefact_cnndm\n",
      "Length: 1017\n",
      "Aggregate ROUGE-1: 0.21336238081138642\n",
      "Aggregate ROUGE-2: 0.18292301039355094\n",
      "Aggregate ROUGE-L: 0.18967448228850625\n",
      "\n",
      "aggrefact_xsum\n",
      "Length: 1335\n",
      "Aggregate ROUGE-1: 0.12337285704193096\n",
      "Aggregate ROUGE-2: 0.04194765176067925\n",
      "Aggregate ROUGE-L: 0.08243328944798624\n",
      "\n",
      "bump_cnndm\n",
      "Length: 785\n",
      "Aggregate ROUGE-1: 0.13706340423598337\n",
      "Aggregate ROUGE-2: 0.0759082226851162\n",
      "Aggregate ROUGE-L: 0.09803528013557283\n",
      "\n",
      "halueval_cnndm\n",
      "Length: 19998\n",
      "Aggregate ROUGE-1: 0.16267543526898423\n",
      "Aggregate ROUGE-2: 0.08451953190630239\n",
      "Aggregate ROUGE-L: 0.11249894803312982\n",
      "\n",
      "fib_xsum\n",
      "Length: 3534\n",
      "Aggregate ROUGE-1: 0.12062514152347291\n",
      "Aggregate ROUGE-2: 0.03506305169123534\n",
      "Aggregate ROUGE-L: 0.08082083106524639\n",
      "\n",
      "fib_cnndm\n",
      "Length: 543\n",
      "Aggregate ROUGE-1: 0.2874173456871638\n",
      "Aggregate ROUGE-2: 0.2641649319649293\n",
      "Aggregate ROUGE-L: 0.26786481912216975\n",
      "\n",
      "llm_summaries_cnndm\n",
      "Length: 1829\n",
      "Aggregate ROUGE-1: 0.24071999641651523\n",
      "Aggregate ROUGE-2: 0.1988684248408106\n",
      "Aggregate ROUGE-L: 0.21488670276301783\n",
      "\n",
      "llm_summaries_xsum\n",
      "Length: 1726\n",
      "Aggregate ROUGE-1: 0.13806098034226172\n",
      "Aggregate ROUGE-2: 0.07368226288264289\n",
      "Aggregate ROUGE-L: 0.10701127297236294\n",
      "\n",
      "gumsum_gumsum\n",
      "Length: 95\n",
      "Aggregate ROUGE-1: 0.05551945611850703\n",
      "Aggregate ROUGE-2: 0.02711017259000255\n",
      "Aggregate ROUGE-L: 0.04504089378951072\n",
      "\n",
      "instrusum_instrusum\n",
      "Length: 458\n",
      "Aggregate ROUGE-1: 0.16208502411518516\n",
      "Aggregate ROUGE-2: 0.1083089216796667\n",
      "Aggregate ROUGE-L: 0.12494904349658416\n",
      "\n",
      "tofueval_mediasum\n",
      "Length: 725\n",
      "Aggregate ROUGE-1: 0.03851396055664802\n",
      "Aggregate ROUGE-2: 0.017764195605170487\n",
      "Aggregate ROUGE-L: 0.03077068809870911\n",
      "\n",
      "tofueval_meetingbank\n",
      "Length: 770\n",
      "Aggregate ROUGE-1: 0.042923717737825114\n",
      "Aggregate ROUGE-2: 0.02350947120020338\n",
      "Aggregate ROUGE-L: 0.036191586900180525\n",
      "\n",
      "diasumfact_QMSum\n",
      "Length: 569\n",
      "Aggregate ROUGE-1: 0.1381684254650248\n",
      "Aggregate ROUGE-2: 0.09334594111998216\n",
      "Aggregate ROUGE-L: 0.12120811056100504\n",
      "\n",
      "diasumfact_SAMSum\n",
      "Length: 669\n",
      "Aggregate ROUGE-1: 0.14296648929429404\n",
      "Aggregate ROUGE-2: 0.0640639585432673\n",
      "Aggregate ROUGE-L: 0.11899147333536503\n",
      "\n",
      "anli\n",
      "Length: 3200\n",
      "Aggregate ROUGE-1: 0.19890496984952158\n",
      "Aggregate ROUGE-2: 0.09891293028552621\n",
      "Aggregate ROUGE-L: 0.16950739918506105\n",
      "\n",
      "alisawuffles/WANLI\n",
      "Length: 5000\n",
      "Aggregate ROUGE-1: 0.5426756690429889\n",
      "Aggregate ROUGE-2: 0.39748125114175425\n",
      "Aggregate ROUGE-L: 0.5028156546162342\n",
      "\n",
      "scitail\n",
      "Length: 2126\n",
      "Aggregate ROUGE-1: 0.34913644668773497\n",
      "Aggregate ROUGE-2: 0.11060233191267085\n",
      "Aggregate ROUGE-L: 0.2672312694719534\n",
      "\n",
      "DeFacto\n",
      "Length: 1836\n",
      "Aggregate ROUGE-1: 0.10246599908361038\n",
      "Aggregate ROUGE-2: 0.03647887119324402\n",
      "Aggregate ROUGE-L: 0.07378673581328463\n",
      "\n",
      "DADC-NLI\n",
      "Length: 766\n",
      "Aggregate ROUGE-1: 0.10653403605149009\n",
      "Aggregate ROUGE-2: 0.03395971194278378\n",
      "Aggregate ROUGE-L: 0.08442805399188485\n",
      "\n",
      "FoolMeTwice\n",
      "Length: 1379\n",
      "Aggregate ROUGE-1: 0.25257819193271985\n",
      "Aggregate ROUGE-2: 0.10394097777099653\n",
      "Aggregate ROUGE-L: 0.21719909949199506\n",
      "\n",
      "WiCE\n",
      "Length: 358\n",
      "Aggregate ROUGE-1: 0.28614769506991616\n",
      "Aggregate ROUGE-2: 0.12154905565531487\n",
      "Aggregate ROUGE-L: 0.21429805311188788\n",
      "\n",
      "Seahorse\n",
      "Length: 4135\n",
      "Aggregate ROUGE-1: 0.1080600857024571\n",
      "Aggregate ROUGE-2: 0.0484897736332085\n",
      "Aggregate ROUGE-L: 0.08352652708475806\n",
      "\n",
      "Reveal\n",
      "Length: 1705\n",
      "Aggregate ROUGE-1: 0.15130186399930762\n",
      "Aggregate ROUGE-2: 0.055670468861415495\n",
      "Aggregate ROUGE-L: 0.12546374192580942\n",
      "\n",
      "ClaimVerify\n",
      "Length: 1087\n",
      "Aggregate ROUGE-1: 0.04520639345963343\n",
      "Aggregate ROUGE-2: 0.027634440966887715\n",
      "Aggregate ROUGE-L: 0.03880825973817313\n",
      "\n",
      "FactCheck-GPT\n",
      "Length: 1565\n",
      "Aggregate ROUGE-1: 0.12516583302801593\n",
      "Aggregate ROUGE-2: 0.03740369515571943\n",
      "Aggregate ROUGE-L: 0.09907426275337346\n",
      "\n",
      "ExpertQA\n",
      "Length: 3702\n",
      "Aggregate ROUGE-1: 0.16731241641883773\n",
      "Aggregate ROUGE-2: 0.06715278506483993\n",
      "Aggregate ROUGE-L: 0.12289407277971962\n",
      "\n",
      "Lfqa\n",
      "Length: 1911\n",
      "Aggregate ROUGE-1: 0.10309623246475803\n",
      "Aggregate ROUGE-2: 0.05461742652387815\n",
      "Aggregate ROUGE-L: 0.08310414002733175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_rouge(df):\n",
    "    predictions = df['target'].to_list()\n",
    "    references = df['source'].to_list()\n",
    "    r = rouge.compute(predictions=predictions, references=references, use_aggregator=False)\n",
    "    \n",
    "    rouge1 = r['rouge1']\n",
    "    rouge2 = r['rouge2']\n",
    "    rougeL = r['rougeL']\n",
    "    \n",
    "    print(f\"Aggregate ROUGE-1: {np.mean(rouge1)}\\nAggregate ROUGE-2: {np.mean(rouge2)}\\nAggregate ROUGE-L: {np.mean(rougeL)}\\n\")\n",
    "    \n",
    "    return r\n",
    "\n",
    "new_df = pd.DataFrame(columns=['subset', 'source', 'target', 'rouge1', 'rouge2', 'rougeL', 'label'])\n",
    "# For each subset calculate the ROUGE scores\n",
    "for subset in test_set['subset'].unique():\n",
    "    if not subset:\n",
    "        continue\n",
    "    print(subset)\n",
    "    subset_df = test_set[test_set['subset'] == subset]\n",
    "    print(f\"Length: {len(subset_df)}\")\n",
    "    results = calculate_rouge(subset_df)\n",
    "    \n",
    "    rouge1 = results['rouge1']\n",
    "    rouge2 = results['rouge2']\n",
    "    rougeL = results['rougeL']\n",
    "    \n",
    "    subset_df['rouge1'] = rouge1\n",
    "    subset_df['rouge2'] = rouge2\n",
    "    subset_df['rougeL'] = rougeL\n",
    "    \n",
    "    new_df = pd.concat([new_df, subset_df])\n",
    "    \n",
    "    # print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62823, 62823)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set), len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subset</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aggrefact_cnndm</td>\n",
       "      <td>looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to c...</td>\n",
       "      <td>lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .</td>\n",
       "      <td>0.224101</td>\n",
       "      <td>0.216561</td>\n",
       "      <td>0.177590</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aggrefact_cnndm</td>\n",
       "      <td>tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens...</td>\n",
       "      <td>a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .</td>\n",
       "      <td>0.300716</td>\n",
       "      <td>0.278177</td>\n",
       "      <td>0.300716</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subset  \\\n",
       "0  aggrefact_cnndm   \n",
       "1  aggrefact_cnndm   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            source  \\\n",
       "0  looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to c...   \n",
       "1  tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            target  \\\n",
       "0                                                                                                       lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .   \n",
       "1  a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .   \n",
       "\n",
       "     rouge1    rouge2    rougeL label  \n",
       "0  0.224101  0.216561  0.177590   Yes  \n",
       "1  0.300716  0.278177  0.300716   Yes  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.to_csv(\"../data/eval-data/rouge.csv\", sep=\"\\t\", index=False)\n",
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"../data/eval-data/rouge.csv\", sep=\"\\t\")\n",
    "\n",
    "new_df['label'] = new_df['label'].apply(lambda x: 0 if x == 'No' else 1) # convert label \"Yes\" into 1 and \"No\" into 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset\n",
      "ClaimVerify             0.533415\n",
      "DADC-NLI                0.440839\n",
      "DeFacto                 0.508740\n",
      "ExpertQA                0.514609\n",
      "FactCheck-GPT           0.568482\n",
      "FoolMeTwice             0.523795\n",
      "Lfqa                    0.772828\n",
      "Reveal                  0.608176\n",
      "Seahorse                0.509130\n",
      "WiCE                    0.500036\n",
      "aggrefact_cnndm         0.691449\n",
      "aggrefact_xsum          0.470915\n",
      "alisawuffles/WANLI      0.512884\n",
      "anli                    0.452784\n",
      "bump_cnndm              0.518678\n",
      "diasumfact_QMSum        0.561600\n",
      "diasumfact_SAMSum       0.571645\n",
      "fib_cnndm               0.047271\n",
      "fib_xsum                0.386898\n",
      "gumsum_gumsum           0.743409\n",
      "halueval_cnndm          0.424876\n",
      "instrusum_instrusum     0.456635\n",
      "llm_summaries_cnndm     0.852697\n",
      "llm_summaries_xsum      0.600992\n",
      "scitail                 0.751793\n",
      "tofueval_mediasum       0.564448\n",
      "tofueval_meetingbank    0.672796\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rouge_type = ['rouge1', 'rouge2', 'rougeL'][2]\n",
    "\n",
    "# calculate auc\n",
    "def calculate_auc(df):\n",
    "    return roc_auc_score(df['label'], df[rouge_type])\n",
    "\n",
    "\n",
    "rouge_auc = new_df.groupby('subset').apply(calculate_auc)\n",
    "\n",
    "print(rouge_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuestEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source', 'target', 'label', 'subset', 'questeval'], dtype='object')\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4135\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1335\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "62823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>questeval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to c...</td>\n",
       "      <td>lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .</td>\n",
       "      <td>Yes</td>\n",
       "      <td>aggrefact_cnndm</td>\n",
       "      <td>0.572732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens...</td>\n",
       "      <td>a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .</td>\n",
       "      <td>Yes</td>\n",
       "      <td>aggrefact_cnndm</td>\n",
       "      <td>0.508080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            source  \\\n",
       "0  looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to c...   \n",
       "1  tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            target  \\\n",
       "0                                                                                                       lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .   \n",
       "1  a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .   \n",
       "\n",
       "  label           subset  questeval  \n",
       "0   Yes  aggrefact_cnndm   0.572732  \n",
       "1   Yes  aggrefact_cnndm   0.508080  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questeval = pd.read_json(\"../data/eval-data/questeval.json\", lines=True)\n",
    "print(questeval.columns)\n",
    "print(questeval.label.value_counts())\n",
    "print(questeval.subset.value_counts())\n",
    "print(len(questeval))\n",
    "questeval.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score:  0.6240841791239211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.712643\n",
       "DADC-NLI                0.568126\n",
       "DeFacto                 0.645085\n",
       "ExpertQA                0.593886\n",
       "FactCheck-GPT           0.754832\n",
       "FoolMeTwice             0.684465\n",
       "Lfqa                    0.806550\n",
       "Reveal                  0.849062\n",
       "Seahorse                0.631419\n",
       "WiCE                    0.599519\n",
       "aggrefact_cnndm         0.714111\n",
       "aggrefact_xsum          0.610757\n",
       "alisawuffles/WANLI      0.623556\n",
       "anli                    0.480432\n",
       "bump_cnndm              0.620373\n",
       "diasumfact_QMSum        0.569502\n",
       "diasumfact_SAMSum       0.568736\n",
       "fib_cnndm               0.342142\n",
       "fib_xsum                0.611612\n",
       "gumsum_gumsum           0.793785\n",
       "halueval_cnndm          0.580613\n",
       "instrusum_instrusum     0.540282\n",
       "llm_summaries_cnndm     0.872060\n",
       "llm_summaries_xsum      0.772084\n",
       "scitail                 0.926951\n",
       "tofueval_mediasum       0.663663\n",
       "tofueval_meetingbank    0.706323\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_label(row):\n",
    "    label = row['label']\n",
    "    if label == 'Yes':\n",
    "        row['label'] = 1\n",
    "    if label == 'No':\n",
    "        row['label'] = 0\n",
    "    return row\n",
    "\n",
    "questeval = questeval.apply(convert_label, axis=1)\n",
    "\n",
    "roc = roc_auc_score(questeval['label'], questeval['questeval'])\n",
    "print(\"AUC ROC score: \", roc)\n",
    "\n",
    "# Subset wise AUC ROC score\n",
    "questeval_auc = questeval.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['questeval']))\n",
    "questeval_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BARTScore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source', 'target', 'label', 'subset', 'bartscore'], dtype='object')\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4135\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1335\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "62823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>bartscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is important to keep in mind that in most cases, this problem is caused by the absence of an organization that can lead the way.</td>\n",
       "      <td>The absence of an organization that can lead the way is the cause of the problem.</td>\n",
       "      <td>No</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>-1.228808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul Casey insists he is desperate to play in the Ryder Cup again, even though he looks unlikely to rejoin the European Tour in time to earn qualifying points this season. Only Tour members can play on the team and Phoenix-based Casey gave up his membership after deciding in January to concentrate on the PGA Tour in order to get back into the world's top 50. The move has paid off with the former world No 3 losing a play-off in the Northern Trust Open and finishing joint third in the Honda Classic to climb to 44th at the start of this week. Paul Casey, practicing ahead of the Masters in Augusta, 'desperately' wants to return to the Ryder Cup. The Englishman has returned to the world's top 50 after leaving the European Tour to concentrate on his game. However, even if he rejoins the Euro...</td>\n",
       "      <td>Paul Casey left the European Tour to get back into world's top 50. Former world No 3 is 'desperate' to return to the 2016 Ryder Cup team. Captain Darren Clarke has said he wants Casey at Hazeltine next year.\\n</td>\n",
       "      <td>Yes</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>-2.178005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            source  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              It is important to keep in mind that in most cases, this problem is caused by the absence of an organization that can lead the way.   \n",
       "1  Paul Casey insists he is desperate to play in the Ryder Cup again, even though he looks unlikely to rejoin the European Tour in time to earn qualifying points this season. Only Tour members can play on the team and Phoenix-based Casey gave up his membership after deciding in January to concentrate on the PGA Tour in order to get back into the world's top 50. The move has paid off with the former world No 3 losing a play-off in the Northern Trust Open and finishing joint third in the Honda Classic to climb to 44th at the start of this week. Paul Casey, practicing ahead of the Masters in Augusta, 'desperately' wants to return to the Ryder Cup. The Englishman has returned to the world's top 50 after leaving the European Tour to concentrate on his game. However, even if he rejoins the Euro...   \n",
       "\n",
       "                                                                                                                                                                                                              target  \\\n",
       "0                                                                                                                                  The absence of an organization that can lead the way is the cause of the problem.   \n",
       "1  Paul Casey left the European Tour to get back into world's top 50. Former world No 3 is 'desperate' to return to the 2016 Ryder Cup team. Captain Darren Clarke has said he wants Casey at Hazeltine next year.\\n   \n",
       "\n",
       "  label              subset  bartscore  \n",
       "0    No  alisawuffles/WANLI  -1.228808  \n",
       "1   Yes      halueval_cnndm  -2.178005  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bartscore = pd.read_json(\"../data/eval-data/bartscore.json\", lines=True)\n",
    "print(bartscore.columns)\n",
    "print(bartscore.label.value_counts())\n",
    "print(bartscore.subset.value_counts())\n",
    "print(len(bartscore))\n",
    "bartscore.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score:  0.569124651181143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.776601\n",
       "DADC-NLI                0.497401\n",
       "DeFacto                 0.584190\n",
       "ExpertQA                0.578560\n",
       "FactCheck-GPT           0.704020\n",
       "FoolMeTwice             0.605546\n",
       "Lfqa                    0.877772\n",
       "Reveal                  0.792830\n",
       "Seahorse                0.589391\n",
       "WiCE                    0.634789\n",
       "aggrefact_cnndm         0.657526\n",
       "aggrefact_xsum          0.618682\n",
       "alisawuffles/WANLI      0.577650\n",
       "anli                    0.452429\n",
       "bump_cnndm              0.583385\n",
       "diasumfact_QMSum        0.666998\n",
       "diasumfact_SAMSum       0.632761\n",
       "fib_cnndm               0.020554\n",
       "fib_xsum                0.441779\n",
       "gumsum_gumsum           0.689266\n",
       "halueval_cnndm          0.389579\n",
       "instrusum_instrusum     0.570977\n",
       "llm_summaries_cnndm     0.872056\n",
       "llm_summaries_xsum      0.727802\n",
       "scitail                 0.876055\n",
       "tofueval_mediasum       0.682640\n",
       "tofueval_meetingbank    0.712495\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bartscore = bartscore.apply(convert_label, axis=1)\n",
    "roc = roc_auc_score(bartscore['label'], bartscore['bartscore'])\n",
    "\n",
    "print(\"AUC ROC score: \", roc)\n",
    "\n",
    "# Subset wise AUC ROC score\n",
    "bartscore_auc = bartscore.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['bartscore']))\n",
    "bartscore_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source', 'target', 'label', 'subset', 'bertscore'], dtype='object')\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4135\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1335\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "62823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>bertscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to c...</td>\n",
       "      <td>lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .</td>\n",
       "      <td>Yes</td>\n",
       "      <td>aggrefact_cnndm</td>\n",
       "      <td>0.598911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens...</td>\n",
       "      <td>a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .</td>\n",
       "      <td>Yes</td>\n",
       "      <td>aggrefact_cnndm</td>\n",
       "      <td>0.637625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            source  \\\n",
       "0  looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to c...   \n",
       "1  tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                            target  \\\n",
       "0                                                                                                       lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .   \n",
       "1  a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .   \n",
       "\n",
       "  label           subset  bertscore  \n",
       "0   Yes  aggrefact_cnndm   0.598911  \n",
       "1   Yes  aggrefact_cnndm   0.637625  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = pd.read_json(\"../data/eval-data/bertscore.json\", lines=True)\n",
    "print(bertscore.columns)\n",
    "print(bertscore.label.value_counts())\n",
    "print(bertscore.subset.value_counts())\n",
    "print(len(bertscore))\n",
    "bertscore.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score:  0.5082214167791583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.704702\n",
       "DADC-NLI                0.438038\n",
       "DeFacto                 0.573767\n",
       "ExpertQA                0.550602\n",
       "FactCheck-GPT           0.726649\n",
       "FoolMeTwice             0.574640\n",
       "Lfqa                    0.855923\n",
       "Reveal                  0.662800\n",
       "Seahorse                0.564131\n",
       "WiCE                    0.558595\n",
       "aggrefact_cnndm         0.713403\n",
       "aggrefact_xsum          0.551644\n",
       "alisawuffles/WANLI      0.556264\n",
       "anli                    0.424766\n",
       "bump_cnndm              0.543776\n",
       "diasumfact_QMSum        0.660839\n",
       "diasumfact_SAMSum       0.625868\n",
       "fib_cnndm               0.124278\n",
       "fib_xsum                0.544288\n",
       "gumsum_gumsum           0.759416\n",
       "halueval_cnndm          0.523280\n",
       "instrusum_instrusum     0.523041\n",
       "llm_summaries_cnndm     0.887450\n",
       "llm_summaries_xsum      0.684115\n",
       "scitail                 0.800671\n",
       "tofueval_mediasum       0.706043\n",
       "tofueval_meetingbank    0.685129\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = bertscore.apply(convert_label, axis=1)\n",
    "roc = roc_auc_score(bertscore['label'], bertscore['bertscore'])\n",
    "\n",
    "print(\"AUC ROC score: \", roc)\n",
    "\n",
    "# Subset wise AUC ROC score\n",
    "bertscore_auc = bertscore.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['bertscore']))\n",
    "bertscore_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63320\n",
      "62823\n",
      "Index(['source', 'target', 'label', 'subset', 'prediction', 'prob'], dtype='object')\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4136\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3533\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1841\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1725\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1331\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gpt = pd.read_json(\"../data/eval-data/gpt3.5.json\", lines=True)\n",
    "print(len(gpt))\n",
    "gpt = gpt.drop_duplicates(subset=['source', 'target'])\n",
    "print(len(gpt))\n",
    "print(gpt.columns)\n",
    "print(gpt.label.value_counts())\n",
    "print(gpt.subset.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # Find cases from the test set that are not in the GPT-3.5 predictions\n",
    "\n",
    "# test_copy = test.copy()\n",
    "\n",
    "# x = pd.merge(test, gpt, on=['source', 'target'], how='inner')\n",
    "# x = x[['source','target','label_x','subset_x', 'prediction', 'prob']]\n",
    "# x = x.rename(columns={'label_x': 'label', 'subset_x': 'subset'})\n",
    "# # y = pd.merge(gpt, test_copy, on=['source', 'target'], how='left')\n",
    "\n",
    "# print(len(x))\n",
    "# # find null in y\n",
    "# x.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# x.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_gpt_metrics(data):\n",
    "    # Invert probabilities for cases where prediction is \"No\"\n",
    "    def invert_prob(row):\n",
    "        label = row['label']\n",
    "        preds = row['prediction']\n",
    "        label_prob = row['prob']\n",
    "                    \n",
    "        if label == 'Yes':\n",
    "            row['label'] = 1\n",
    "        if label == 'No':\n",
    "            row['label'] = 0\n",
    "        if preds == 'Yes':\n",
    "            row['prediction'] = 1\n",
    "        if preds == 'No':\n",
    "            row['prediction'] = 0              \n",
    "            row['prob'] = 1 - label_prob\n",
    "        return row\n",
    "\n",
    "    data = data.apply(invert_prob, axis=1)\n",
    "    \n",
    "    y_true = data['label']\n",
    "    y_pred = data['prediction']\n",
    "    y_pred_prob = data['prob']\n",
    "    \n",
    "    roc = roc_auc_score(y_true, y_pred_prob)\n",
    "    \n",
    "    # return {'accuracy': acc, 'f1': f1, 'roc_auc': roc}\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # Deduplicate the data\n",
    "\n",
    "# import hashlib\n",
    "\n",
    "# def get_hash(row):\n",
    "#     source = row['source']\n",
    "#     target = row['target']\n",
    "#     row['hash'] = hashlib.md5(f\"{source}{target}\".encode()).hexdigest()\n",
    "    \n",
    "#     return row\n",
    "\n",
    "# gpt = gpt.apply(get_hash, axis=1)\n",
    "\n",
    "# # drop duplicates from gpt\n",
    "# gpt_dedup = gpt.drop_duplicates(subset=['hash'], keep='first')\n",
    "\n",
    "# print(len(gpt), len(gpt_dedup))\n",
    "# gpt_dedup.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.787961\n",
       "DADC-NLI                0.840711\n",
       "DeFacto                 0.675185\n",
       "ExpertQA                0.634823\n",
       "FactCheck-GPT           0.809871\n",
       "FoolMeTwice             0.920919\n",
       "Lfqa                    0.896013\n",
       "Reveal                  0.942028\n",
       "Seahorse                0.734978\n",
       "WiCE                    0.640041\n",
       "aggrefact_cnndm         0.666128\n",
       "aggrefact_xsum          0.784158\n",
       "alisawuffles/WANLI      0.810824\n",
       "anli                    0.782509\n",
       "bump_cnndm              0.764673\n",
       "diasumfact_QMSum        0.701812\n",
       "diasumfact_SAMSum       0.806191\n",
       "fib_cnndm               0.655761\n",
       "fib_xsum                0.767938\n",
       "gumsum_gumsum           0.823917\n",
       "halueval_cnndm          0.685213\n",
       "instrusum_instrusum     0.504676\n",
       "llm_summaries_cnndm     0.861768\n",
       "llm_summaries_xsum      0.759703\n",
       "scitail                 0.903457\n",
       "tofueval_mediasum       0.737195\n",
       "tofueval_meetingbank    0.819473\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each subset calculate the metrics\n",
    "gpt_metrics = gpt.groupby('subset').apply(get_gpt_metrics)\n",
    "gpt_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62823"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlignScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "alignscore_base = pd.read_json(\"../data/eval-data/alignscore_base.json\", lines=True)\n",
    "alignscore_large = pd.read_json(\"../data/eval-data/alignscore_large.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>alignscore_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9223</th>\n",
       "      <td>Arsenal goalkeeper Wojciech Szczesny admits he feels sorry for Adam Federici, insisting the Reading stopper was 'the best player on the pitch' despite his costly error in Saturday's FA Cup semi-final. Federici allowed Alexis Sanchez's driven shot to slip through his body in extra-time as Arsenal ran out 2-1 winners at Wembley to reach their second consecutive final, having beaten Hull to lift the trophy last year. The mistake overshadowed a number of strong saves Federici had made to keep his side in the game and Szczesny had only kind words for his opposite number. Wojciech Szczesny (left) says he feels sorry for Adam Federici after his mistake in the FA Cup semi-final. 'He can be very proud. It only went to extra-time because the goalkeeper was magnificent,' Szczesny told Arsenal's o...</td>\n",
       "      <td>Wojciech Szczesny believes Adam Federici played better in the FA Cup semi-final than any other player on the pitch, despite his unfortunate error that cost Reading the game. Arsenal won the match 2-1 in extra-time after Federici allowed Alexis Sanchez to score. Szczesny empathized with Federici and stated that he was hoping to win the match. Arsenal are now one step closer to becoming the most successful FA Cup team of all time.</td>\n",
       "      <td>No</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>0.850175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58313</th>\n",
       "      <td>you to view the basic structure and design as an introduction to the parts of an airplane. The parts of a plane are basic knowledge for all pilots. Whether you fly a Cessna 172 Skyhawk or a Boeing 747, pilots must know the main sections and parts of an airplane.The Main Sections of an AirplaneAirplanes are not all alike, but they are comprised of basic components. The main sections of an airplane include the fuselage, wings, cockpit, engine, propeller, tail assembly, and landing gear. Understanding the basic functions of how these parts interact is the first step to understanding the principles of aerodynamics.What is the fuselage?The fuselage is the main section, or body, of the airplane. (If “fuselage” sounds like a French word to you, you’re right. That’s because it is derived from ...</td>\n",
       "      <td>This includes knowledge about the fuselage, wings, cockpit, engine, propeller, tail assembly, and landing gear, as well as the principles of aerodynamics .</td>\n",
       "      <td>Yes</td>\n",
       "      <td>ExpertQA</td>\n",
       "      <td>0.353359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "9223   Arsenal goalkeeper Wojciech Szczesny admits he feels sorry for Adam Federici, insisting the Reading stopper was 'the best player on the pitch' despite his costly error in Saturday's FA Cup semi-final. Federici allowed Alexis Sanchez's driven shot to slip through his body in extra-time as Arsenal ran out 2-1 winners at Wembley to reach their second consecutive final, having beaten Hull to lift the trophy last year. The mistake overshadowed a number of strong saves Federici had made to keep his side in the game and Szczesny had only kind words for his opposite number. Wojciech Szczesny (left) says he feels sorry for Adam Federici after his mistake in the FA Cup semi-final. 'He can be very proud. It only went to extra-time because the goalkeeper was magnificent,' Szczesny told Arsenal's o...   \n",
       "58313  you to view the basic structure and design as an introduction to the parts of an airplane. The parts of a plane are basic knowledge for all pilots. Whether you fly a Cessna 172 Skyhawk or a Boeing 747, pilots must know the main sections and parts of an airplane.The Main Sections of an AirplaneAirplanes are not all alike, but they are comprised of basic components. The main sections of an airplane include the fuselage, wings, cockpit, engine, propeller, tail assembly, and landing gear. Understanding the basic functions of how these parts interact is the first step to understanding the principles of aerodynamics.What is the fuselage?The fuselage is the main section, or body, of the airplane. (If “fuselage” sounds like a French word to you, you’re right. That’s because it is derived from ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                 target  \\\n",
       "9223   Wojciech Szczesny believes Adam Federici played better in the FA Cup semi-final than any other player on the pitch, despite his unfortunate error that cost Reading the game. Arsenal won the match 2-1 in extra-time after Federici allowed Alexis Sanchez to score. Szczesny empathized with Federici and stated that he was hoping to win the match. Arsenal are now one step closer to becoming the most successful FA Cup team of all time.   \n",
       "58313                                                                                                                                                                                                                                                                                       This includes knowledge about the fuselage, wings, cockpit, engine, propeller, tail assembly, and landing gear, as well as the principles of aerodynamics .   \n",
       "\n",
       "      label          subset  alignscore_base  \n",
       "9223     No  halueval_cnndm         0.850175  \n",
       "58313   Yes        ExpertQA         0.353359  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignscore_base.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Yes    31469\n",
       "No     31354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignscore_large.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Yes    31469\n",
       "No     31354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix the label column in alignscore_base by copying them from alignscore_large\n",
    "# First do a merge on the ['source', 'target'] columns\n",
    "\n",
    "alignscore_base = alignscore_base.merge(alignscore_large[['source', 'target', 'label']], on=['source', 'target'], how='left')\n",
    "\n",
    "alignscore_base['label_x'] = alignscore_base['label_y']\n",
    "alignscore_base = alignscore_base.drop(columns=['label_y'])\n",
    "alignscore_base = alignscore_base.rename(columns={'label_x': 'label'})\n",
    "\n",
    "alignscore_base.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "alignscore_base = alignscore_base.apply(convert_label, axis=1)\n",
    "alignscore_large = alignscore_large.apply(convert_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(subset\n",
       " ClaimVerify             0.727478\n",
       " DADC-NLI                0.788478\n",
       " DeFacto                 0.706138\n",
       " ExpertQA                0.573432\n",
       " FactCheck-GPT           0.777900\n",
       " FoolMeTwice             0.859929\n",
       " Lfqa                    0.845584\n",
       " Reveal                  0.917330\n",
       " Seahorse                0.616925\n",
       " WiCE                    0.723930\n",
       " aggrefact_cnndm         0.647910\n",
       " aggrefact_xsum          0.716962\n",
       " alisawuffles/WANLI      0.826411\n",
       " anli                    0.741015\n",
       " bump_cnndm              0.659820\n",
       " diasumfact_QMSum        0.663104\n",
       " diasumfact_SAMSum       0.763708\n",
       " fib_cnndm               0.140707\n",
       " fib_xsum                0.711012\n",
       " gumsum_gumsum           0.773540\n",
       " halueval_cnndm          0.654022\n",
       " instrusum_instrusum     0.530825\n",
       " llm_summaries_cnndm     0.748689\n",
       " llm_summaries_xsum      0.721820\n",
       " scitail                 0.857036\n",
       " tofueval_mediasum       0.752660\n",
       " tofueval_meetingbank    0.808946\n",
       " dtype: float64,\n",
       " subset\n",
       " ClaimVerify             0.704079\n",
       " DADC-NLI                0.869803\n",
       " DeFacto                 0.714168\n",
       " ExpertQA                0.576608\n",
       " FactCheck-GPT           0.813530\n",
       " FoolMeTwice             0.835717\n",
       " Lfqa                    0.822210\n",
       " Reveal                  0.922272\n",
       " Seahorse                0.651430\n",
       " WiCE                    0.778860\n",
       " aggrefact_cnndm         0.558144\n",
       " aggrefact_xsum          0.724258\n",
       " alisawuffles/WANLI      0.839148\n",
       " anli                    0.793175\n",
       " bump_cnndm              0.744397\n",
       " diasumfact_QMSum        0.674123\n",
       " diasumfact_SAMSum       0.782468\n",
       " fib_cnndm               0.131968\n",
       " fib_xsum                0.782268\n",
       " gumsum_gumsum           0.744350\n",
       " halueval_cnndm          0.731581\n",
       " instrusum_instrusum     0.595690\n",
       " llm_summaries_cnndm     0.787353\n",
       " llm_summaries_xsum      0.725992\n",
       " scitail                 0.880994\n",
       " tofueval_mediasum       0.740916\n",
       " tofueval_meetingbank    0.806000\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc for each subset   \n",
    "alignscore_base_auc = alignscore_base.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['alignscore_base']))\n",
    "alignscore_large_auc = alignscore_large.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['alignscore_large']))\n",
    "\n",
    "alignscore_base_auc, alignscore_large_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Yes    31469\n",
       "No     31354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unieval = pd.read_json(\"../data/eval-data/unieval.json\", lines=True)\n",
    "unieval.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>unieval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>The number of Chinese tourists eager to travel the world has risen dramatically over the last few years, and Beijing International Airport is launching the world's biggest terminal to cope with the substantial increase. Opening in 2018, the gigantic Terminal 1 will cover 700,000 square metres, and is set to handle 45million passengers a year. Renown British-Iraqi architect, Zaha Hadid, has collaborated with airport developers ADPI to create a six-tier concept which aims to decrease customer walking distances, and increase connectivity. Scroll down for video. Terminal 1 at Beijing International Airport is set to the largest in the world, in order to cope with the surge in tourist numbers. Aiming to be the perfect welcome to Beijing, the designs focus on creating a feeling of space and o...</td>\n",
       "      <td>China's tourism industry is set to reach new heights with the world's largest airport terminal opening in Beijing in 2018. The terminal will handle 45 million passengers per year and will be designed to create a feeling of openness and space. Zaha Hadid collaborated with airport developers ADPI to bring the concept to life.</td>\n",
       "      <td>No</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>0.967260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>The need for a national program to develop a common language for a new information age was recognized by the Congress in the National Information Infrastructure Act of 1996.</td>\n",
       "      <td>The need for a national program to develop a common language for a new information age was recognized by the Congress.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>0.907713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "11989  The number of Chinese tourists eager to travel the world has risen dramatically over the last few years, and Beijing International Airport is launching the world's biggest terminal to cope with the substantial increase. Opening in 2018, the gigantic Terminal 1 will cover 700,000 square metres, and is set to handle 45million passengers a year. Renown British-Iraqi architect, Zaha Hadid, has collaborated with airport developers ADPI to create a six-tier concept which aims to decrease customer walking distances, and increase connectivity. Scroll down for video. Terminal 1 at Beijing International Airport is set to the largest in the world, in order to cope with the surge in tourist numbers. Aiming to be the perfect welcome to Beijing, the designs focus on creating a feeling of space and o...   \n",
       "38944                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The need for a national program to develop a common language for a new information age was recognized by the Congress in the National Information Infrastructure Act of 1996.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                      target  \\\n",
       "11989  China's tourism industry is set to reach new heights with the world's largest airport terminal opening in Beijing in 2018. The terminal will handle 45 million passengers per year and will be designed to create a feeling of openness and space. Zaha Hadid collaborated with airport developers ADPI to bring the concept to life.   \n",
       "38944                                                                                                                                                                                                                 The need for a national program to develop a common language for a new information age was recognized by the Congress.   \n",
       "\n",
       "      label              subset   unieval  \n",
       "11989    No      halueval_cnndm  0.967260  \n",
       "38944   Yes  alisawuffles/WANLI  0.907713  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unieval.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score:  0.7017943036725703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.767457\n",
       "DADC-NLI                0.815664\n",
       "DeFacto                 0.564717\n",
       "ExpertQA                0.597975\n",
       "FactCheck-GPT           0.765852\n",
       "FoolMeTwice             0.880201\n",
       "Lfqa                    0.832551\n",
       "Reveal                  0.915155\n",
       "Seahorse                0.679787\n",
       "WiCE                    0.675967\n",
       "aggrefact_cnndm         0.704667\n",
       "aggrefact_xsum          0.634889\n",
       "alisawuffles/WANLI      0.772040\n",
       "anli                    0.677980\n",
       "bump_cnndm              0.737285\n",
       "diasumfact_QMSum        0.617346\n",
       "diasumfact_SAMSum       0.646615\n",
       "fib_cnndm               0.182047\n",
       "fib_xsum                0.678497\n",
       "gumsum_gumsum           0.545669\n",
       "halueval_cnndm          0.638827\n",
       "instrusum_instrusum     0.597126\n",
       "llm_summaries_cnndm     0.783651\n",
       "llm_summaries_xsum      0.676358\n",
       "scitail                 0.837040\n",
       "tofueval_mediasum       0.657103\n",
       "tofueval_meetingbank    0.808075\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unieval = unieval.apply(convert_label, axis=1)\n",
    "\n",
    "roc = roc_auc_score(unieval['label'], unieval['unieval'])\n",
    "\n",
    "print(\"AUC ROC score: \", roc)\n",
    "\n",
    "# Subset wise AUC ROC score\n",
    "unieval_auc = unieval.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['unieval']))\n",
    "unieval_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuestEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823\n",
      "Index(['source', 'target', 'label', 'subset', 'questeval'], dtype='object')\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4135\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1335\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>questeval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13796</th>\n",
       "      <td>Her style is followed by women across the globe and whatever she wears is sure to sell out within minutes. Yet the Duchess of Cambridge has been dismissed as an ‘uneventful’ dresser by leading author Margaret Atwood. And most controversially, the 75-year-old said Kate hasn’t lived up to the fashion icon reputation of her husband’s late mother, Princess Diana. Scroll down for video. The author said Kate (pictured right) hasn’t lived up to the fashion icon reputation of Princess Diana (left) Miss Atwood said she thinks the duchess is cautious when it comes to clothes and is told what to wear by advisers. But she added she is right not to follow in Diana’s footsteps. ‘I think she dresses quite uneventfully,’ the author of The Handmaid’s Tale said. ‘I think she’s watching her back, I think...</td>\n",
       "      <td>Author Margaret Atwood dismissed Katherine as an 'uneventful' dresser. She says Duchess of Cambridge hasn't lived up to fashion icon Diana. Miss Atwood says Kate is cautious when it comes to clothing.\\n</td>\n",
       "      <td>Yes</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>0.508444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>A youngster admiring his catch was left surprised when the fish jumped up and slapped him in the face. Quinn Patrick was on a fishing trip with his dad at Snow Lake, Indiana when the pair caught a bowfin, videoed lying lifeless on a concrete dock. Crouching over the fish, Quinn deliberates whether someone should put it back in the water. When suddenly the Bowfin propels itself from the ground and slaps the youngster straight in the face with its large tail. The sound of the fish making impact with the youngster’s face is not dissimilar to a sound effect used in a cartoon. Recoiling, Quinn stumbles backwards in shock as his dad begins laughing – prompting the youngster to laugh along with him. Quinn Patrick was on a fishing trip with his dad at Snow Lake, Indiana when the pair caught a ...</td>\n",
       "      <td>A brave young boy catches a Bowfin fish while on a fishing trip with his dad, but is surprised when it jumps up and gives him a high five with its tail. The fish is later found to have magical powers and has been labeled as a rare species.</td>\n",
       "      <td>No</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>0.449519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "13796  Her style is followed by women across the globe and whatever she wears is sure to sell out within minutes. Yet the Duchess of Cambridge has been dismissed as an ‘uneventful’ dresser by leading author Margaret Atwood. And most controversially, the 75-year-old said Kate hasn’t lived up to the fashion icon reputation of her husband’s late mother, Princess Diana. Scroll down for video. The author said Kate (pictured right) hasn’t lived up to the fashion icon reputation of Princess Diana (left) Miss Atwood said she thinks the duchess is cautious when it comes to clothes and is told what to wear by advisers. But she added she is right not to follow in Diana’s footsteps. ‘I think she dresses quite uneventfully,’ the author of The Handmaid’s Tale said. ‘I think she’s watching her back, I think...   \n",
       "7795   A youngster admiring his catch was left surprised when the fish jumped up and slapped him in the face. Quinn Patrick was on a fishing trip with his dad at Snow Lake, Indiana when the pair caught a bowfin, videoed lying lifeless on a concrete dock. Crouching over the fish, Quinn deliberates whether someone should put it back in the water. When suddenly the Bowfin propels itself from the ground and slaps the youngster straight in the face with its large tail. The sound of the fish making impact with the youngster’s face is not dissimilar to a sound effect used in a cartoon. Recoiling, Quinn stumbles backwards in shock as his dad begins laughing – prompting the youngster to laugh along with him. Quinn Patrick was on a fishing trip with his dad at Snow Lake, Indiana when the pair caught a ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                target  \\\n",
       "13796                                       Author Margaret Atwood dismissed Katherine as an 'uneventful' dresser. She says Duchess of Cambridge hasn't lived up to fashion icon Diana. Miss Atwood says Kate is cautious when it comes to clothing.\\n   \n",
       "7795   A brave young boy catches a Bowfin fish while on a fishing trip with his dad, but is surprised when it jumps up and gives him a high five with its tail. The fish is later found to have magical powers and has been labeled as a rare species.   \n",
       "\n",
       "      label          subset  questeval  \n",
       "13796   Yes  halueval_cnndm   0.508444  \n",
       "7795     No  halueval_cnndm   0.449519  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questeval = pd.read_json(\"../data/eval-data/questeval.json\", lines=True)\n",
    "print(len(questeval))\n",
    "print(questeval.columns)\n",
    "print(questeval.subset.value_counts())\n",
    "print(questeval.label.value_counts())\n",
    "questeval.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    31469\n",
      "0    31354\n",
      "Name: count, dtype: int64\n",
      "ROC AUC: 0.6240841791239211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.712643\n",
       "DADC-NLI                0.568126\n",
       "DeFacto                 0.645085\n",
       "ExpertQA                0.593886\n",
       "FactCheck-GPT           0.754832\n",
       "FoolMeTwice             0.684465\n",
       "Lfqa                    0.806550\n",
       "Reveal                  0.849062\n",
       "Seahorse                0.631419\n",
       "WiCE                    0.599519\n",
       "aggrefact_cnndm         0.714111\n",
       "aggrefact_xsum          0.610757\n",
       "alisawuffles/WANLI      0.623556\n",
       "anli                    0.480432\n",
       "bump_cnndm              0.620373\n",
       "diasumfact_QMSum        0.569502\n",
       "diasumfact_SAMSum       0.568736\n",
       "fib_cnndm               0.342142\n",
       "fib_xsum                0.611612\n",
       "gumsum_gumsum           0.793785\n",
       "halueval_cnndm          0.580613\n",
       "instrusum_instrusum     0.540282\n",
       "llm_summaries_cnndm     0.872060\n",
       "llm_summaries_xsum      0.772084\n",
       "scitail                 0.926951\n",
       "tofueval_mediasum       0.663663\n",
       "tofueval_meetingbank    0.706323\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questeval = questeval.apply(convert_label, axis=1)\n",
    "print(questeval.label.value_counts())\n",
    "\n",
    "# Calculate metrics for questeval\n",
    "questeval_roc = roc_auc_score(questeval['label'], questeval['questeval'])\n",
    "print(f\"ROC AUC: {questeval_roc}\")\n",
    "\n",
    "# roc for each subset\n",
    "questeval_auc = questeval.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['questeval']))\n",
    "\n",
    "questeval_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823\n",
      "Index(['source', 'target', 'label', 'subset', 'minicheck'], dtype='object')\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4135\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1335\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "minicheck = pd.read_json(\"../data/eval-data/minicheck.json\", lines=True)\n",
    "print(len(minicheck))\n",
    "print(minicheck.columns)\n",
    "print(minicheck.label.value_counts())\n",
    "print(minicheck.subset.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC score:  0.7500985604208029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subset\n",
       "ClaimVerify             0.810586\n",
       "DADC-NLI                0.835994\n",
       "DeFacto                 0.749103\n",
       "ExpertQA                0.617747\n",
       "FactCheck-GPT           0.841101\n",
       "FoolMeTwice             0.868752\n",
       "Lfqa                    0.931178\n",
       "Reveal                  0.938783\n",
       "Seahorse                0.698619\n",
       "WiCE                    0.767772\n",
       "aggrefact_cnndm         0.732931\n",
       "aggrefact_xsum          0.768704\n",
       "alisawuffles/WANLI      0.831861\n",
       "anli                    0.774468\n",
       "bump_cnndm              0.692243\n",
       "diasumfact_QMSum        0.734158\n",
       "diasumfact_SAMSum       0.777320\n",
       "fib_cnndm               0.469333\n",
       "fib_xsum                0.767545\n",
       "gumsum_gumsum           0.784369\n",
       "halueval_cnndm          0.672593\n",
       "instrusum_instrusum     0.561546\n",
       "llm_summaries_cnndm     0.813549\n",
       "llm_summaries_xsum      0.772313\n",
       "scitail                 0.889745\n",
       "tofueval_mediasum       0.810905\n",
       "tofueval_meetingbank    0.848237\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minicheck = minicheck.apply(convert_label, axis=1)\n",
    "\n",
    "roc = roc_auc_score(minicheck['label'], minicheck['minicheck'])\n",
    "\n",
    "print(\"AUC ROC score: \", roc)\n",
    "\n",
    "# Subset wise AUC ROC score\n",
    "minicheck_auc = minicheck.groupby('subset').apply(lambda x: roc_auc_score(x['label'], x['minicheck']))\n",
    "minicheck_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMA-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823 62821\n",
      "62823 62821\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    43929\n",
      "No     18894\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "Yes    31469\n",
      "No     31352\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    38846\n",
      "No     23975\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>Police said that someone opened fire from a passing car and witnesses spoke of up to a dozen shots being fired close to the main police station. \"Nothing is known about the culprits yet but we can guess that this involves local crime gangs,\" investigators told German media. The suspects fled and the area was quickly cordoned off. The shots were fired in Friedrich-Stoltze Square, a busy area of bars and cafes, as local people enjoyed the Ascension Day holiday in the sunshine.</td>\n",
       "      <td>Shots have been fired near a police station in the German city of Stuttgart.</td>\n",
       "      <td>No</td>\n",
       "      <td>aggrefact_xsum</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.988176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>Amargosa is an unincorporated community and census-designated place in Jim Wells County, Texas, United States. Its population was 291 as of the 2010 census. Prior to 2010, the community was grouped with nearby Owl Ranch as part of the Owl Ranch-Amargosa census-designated place. The community is named for the Amargosa Creek that runs nearby. The word \"amargosa\" means \"bitter\" in Spanish.</td>\n",
       "      <td>Amargosa is a place in Jum Wells County, Texas that has a large population.</td>\n",
       "      <td>No</td>\n",
       "      <td>anli</td>\n",
       "      <td>No</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "3334   Police said that someone opened fire from a passing car and witnesses spoke of up to a dozen shots being fired close to the main police station. \"Nothing is known about the culprits yet but we can guess that this involves local crime gangs,\" investigators told German media. The suspects fled and the area was quickly cordoned off. The shots were fired in Friedrich-Stoltze Square, a busy area of bars and cafes, as local people enjoyed the Ascension Day holiday in the sunshine.   \n",
       "18576                                                                                            Amargosa is an unincorporated community and census-designated place in Jim Wells County, Texas, United States. Its population was 291 as of the 2010 census. Prior to 2010, the community was grouped with nearby Owl Ranch as part of the Owl Ranch-Amargosa census-designated place. The community is named for the Amargosa Creek that runs nearby. The word \"amargosa\" means \"bitter\" in Spanish.   \n",
       "\n",
       "                                                                             target  \\\n",
       "3334   Shots have been fired near a police station in the German city of Stuttgart.   \n",
       "18576  Amargosa is a place in Jum Wells County, Texas that has a large population.    \n",
       "\n",
       "      label          subset prediction      prob  \n",
       "3334     No  aggrefact_xsum        Yes  0.988176  \n",
       "18576    No            anli         No  0.000152  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_zs = pd.read_json(\"../data/eval-data/llama3-8b.jsonl\", lines=True)\n",
    "llama3_ft = pd.read_json(\"../data/eval-data/llama3-8b-finetune.jsonl\", lines=True)\n",
    "print(len(llama3_zs), len(llama3_ft))\n",
    "\n",
    "# Deduplicate based on the ['source', 'target'] columns\n",
    "\n",
    "llama3_zs = llama3_zs.drop_duplicates(subset=['source', 'target'])\n",
    "llama3_ft = llama3_ft.drop_duplicates(subset=['source', 'target'])\n",
    "print(len(llama3_zs), len(llama3_ft))\n",
    "\n",
    "# # Deduplicate based on hashing\n",
    "# import hashlib\n",
    "\n",
    "# def get_hash(row):\n",
    "#     source = row['source']\n",
    "#     target = row['target']\n",
    "#     subset = row['subset']\n",
    "#     try:\n",
    "#         hash_val = hashlib.md5(f\"{source}{target}\".encode()).hexdigest()\n",
    "#     except:\n",
    "#         print(subset)\n",
    "#         print(inp)\n",
    "#     row['hash'] = hash_val\n",
    "    \n",
    "#     return row\n",
    "\n",
    "# llama3_zs = llama3_zs.apply(get_hash, axis=1)\n",
    "# llama3_ft = llama3_ft.apply(get_hash, axis=1)\n",
    "# llama3_zs = llama3_zs.drop_duplicates(subset=['hash'])\n",
    "# llama3_ft = llama3_ft.drop_duplicates(subset=['hash'])\n",
    "# print(len(llama3_zs), len(llama3_ft))\n",
    "\n",
    "print(llama3_zs.label.value_counts(), llama3_zs.prediction.value_counts())\n",
    "print(llama3_ft.label.value_counts(), llama3_ft.prediction.value_counts())\n",
    "llama3_zs.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34373</th>\n",
       "      <td>Midfielder Cheikhou Kouyate has warned West Ham must be ready to face a 'wounded animal' at Manchester City on Sunday, but will be ready to inflict more pain on Manuel Pellegrini's men. The Barclays Premier League champions have seen their title defence left in tatters following a run of four defeats in six matches, thrashed 4-2 at rivals United last weekend - a result which left the long-term future of manager Pellegrini in doubt as City might now face a scrap with Liverpool for a Champions League qualifying spot. West Ham are also in need a pick-me-up, having seen victory slip through their fingers when Stoke netted a stoppage time equaliser at Upton Park. West Ham midfielder Cheikhou Kouyate is wary of facing champions Manchester City on Sunday. City midfielder Yaya Toure (centre) a...</td>\n",
       "      <td>West Ham face Manchester City at the Etihad on Sunday, KO at 1.30pm. Cheikhou Kouyate believes the Hammers must not underestimate City. Manuel Pellegrini's side have lost their last two Premier League games. Sam Allardyce wants West Ham to be defensively solid on Sunday.\\n</td>\n",
       "      <td>Yes</td>\n",
       "      <td>halueval_cnndm</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.573691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54658</th>\n",
       "      <td>By\\n- Judith Martin\\n- Nicholas Ivor Martin and Jacobina Martin\\nDEAR MISS MANNERS: I teach at a small college where, before COVID-19, I would regularly meet prospective students and their parents in my office on campus.\\nOccasionally these parents are prominent in politics, and given the deep rifts in our political culture these days, I wonder how I should treat a parent whose positions are abhorrent to me.\\nI would welcome the student just as I would welcome anyone, and I would greet the parent distantly but politely, since while on campus I try to be nonpolitical. But if that parent were to extend a hand, can I -- and should I -- refuse to take it, perhaps with a polite “I can’t shake your hand”?\\nGENTLE READER: If it would make you feel virtuous to do so -- and provided you do not ...</td>\n",
       "      <td>It is important to examine shifting beliefs and values through cultural history and consider the ethical implications of supporting people with abhorrent views.</td>\n",
       "      <td>No</td>\n",
       "      <td>ClaimVerify</td>\n",
       "      <td>No</td>\n",
       "      <td>0.076956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "34373  Midfielder Cheikhou Kouyate has warned West Ham must be ready to face a 'wounded animal' at Manchester City on Sunday, but will be ready to inflict more pain on Manuel Pellegrini's men. The Barclays Premier League champions have seen their title defence left in tatters following a run of four defeats in six matches, thrashed 4-2 at rivals United last weekend - a result which left the long-term future of manager Pellegrini in doubt as City might now face a scrap with Liverpool for a Champions League qualifying spot. West Ham are also in need a pick-me-up, having seen victory slip through their fingers when Stoke netted a stoppage time equaliser at Upton Park. West Ham midfielder Cheikhou Kouyate is wary of facing champions Manchester City on Sunday. City midfielder Yaya Toure (centre) a...   \n",
       "54658  By\\n- Judith Martin\\n- Nicholas Ivor Martin and Jacobina Martin\\nDEAR MISS MANNERS: I teach at a small college where, before COVID-19, I would regularly meet prospective students and their parents in my office on campus.\\nOccasionally these parents are prominent in politics, and given the deep rifts in our political culture these days, I wonder how I should treat a parent whose positions are abhorrent to me.\\nI would welcome the student just as I would welcome anyone, and I would greet the parent distantly but politely, since while on campus I try to be nonpolitical. But if that parent were to extend a hand, can I -- and should I -- refuse to take it, perhaps with a polite “I can’t shake your hand”?\\nGENTLE READER: If it would make you feel virtuous to do so -- and provided you do not ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                  target  \\\n",
       "34373  West Ham face Manchester City at the Etihad on Sunday, KO at 1.30pm. Cheikhou Kouyate believes the Hammers must not underestimate City. Manuel Pellegrini's side have lost their last two Premier League games. Sam Allardyce wants West Ham to be defensively solid on Sunday.\\n   \n",
       "54658                                                                                                                   It is important to examine shifting beliefs and values through cultural history and consider the ethical implications of supporting people with abhorrent views.   \n",
       "\n",
       "      label          subset prediction      prob  \n",
       "34373   Yes  halueval_cnndm        Yes  0.573691  \n",
       "54658    No     ClaimVerify         No  0.076956  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_ft.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    31469\n",
      "0    31354\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    31469\n",
      "0    31352\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert \"Yes\" to 1 and \"No\" to 0\n",
    "def convert_label(row):\n",
    "    if row['label'] == 'Yes':\n",
    "        row['label'] = 1\n",
    "    if row['label'] == 'No':\n",
    "        row['label'] = 0\n",
    "    return row\n",
    "\n",
    "llama3_zs = llama3_zs.apply(convert_label, axis=1)\n",
    "print(llama3_zs.label.value_counts())\n",
    "\n",
    "llama3_ft = llama3_ft.apply(convert_label, axis=1)\n",
    "print(llama3_ft.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7170519503877647\n",
      "ROC AUC: 0.7800030927531358\n",
      "\n",
      "aggrefact_cnndm: 0.6291189865666501\n",
      "fib_cnndm: 0.889180182699478\n",
      "Seahorse: 0.6897540752240492\n",
      "halueval_cnndm: 0.7059943888777754\n",
      "llm_summaries_cnndm: 0.8532925212624931\n",
      "alisawuffles/WANLI: 0.755825360630206\n",
      "DeFacto: 0.5943360748612956\n",
      "DADC-NLI: 0.8287257967198728\n",
      "llm_summaries_xsum: 0.6979800769566066\n",
      "anli: 0.683731078057128\n",
      "bump_cnndm: 0.7694952439850399\n",
      "fib_xsum: 0.7078539881344759\n",
      "scitail: 0.8758842616230456\n",
      "tofueval_meetingbank: 0.7893494623655914\n",
      "diasumfact_SAMSum: 0.7998652421762904\n",
      "WiCE: 0.6890615311667944\n",
      "FoolMeTwice: 0.928601332104734\n",
      "diasumfact_QMSum: 0.726707639843233\n",
      "tofueval_mediasum: 0.7763625467849784\n",
      "instrusum_instrusum: 0.5867424242424243\n",
      "gumsum_gumsum: 0.7923728813559323\n",
      "aggrefact_xsum: 0.7329510758288732\n",
      "Lfqa: 0.794342189952461\n",
      "ExpertQA: 0.5817252593584772\n",
      "ClaimVerify: 0.666626262110734\n",
      "FactCheck-GPT: 0.7752413524685504\n",
      "Reveal: 0.9110174053127151\n",
      "\n",
      "Seahorse: 0.742920702834496\n",
      "halueval_cnndm: 0.6951997599519903\n",
      "DADC-NLI: 0.8978765564148978\n",
      "FoolMeTwice: 0.9575523101456227\n",
      "fib_xsum: 0.7650243902439025\n",
      "aggrefact_cnndm: 0.6599276665773661\n",
      "alisawuffles/WANLI: 0.8724749205013639\n",
      "tofueval_meetingbank: 0.8288172043010753\n",
      "scitail: 0.9822023849164947\n",
      "llm_summaries_cnndm: 0.7772595588125772\n",
      "fib_cnndm: 0.47377190529455626\n",
      "aggrefact_xsum: 0.7576354215309458\n",
      "diasumfact_SAMSum: 0.8322071198665995\n",
      "DeFacto: 0.6913644311166679\n",
      "llm_summaries_xsum: 0.7618086581130256\n",
      "anli: 0.8535571058751261\n",
      "diasumfact_QMSum: 0.7129841706112893\n",
      "tofueval_mediasum: 0.7525810589175322\n",
      "bump_cnndm: 0.707276850133993\n",
      "gumsum_gumsum: 0.8394538606403013\n",
      "instrusum_instrusum: 0.6391065830721003\n",
      "WiCE: 0.7869752343436553\n",
      "ExpertQA: 0.6169338258892043\n",
      "Reveal: 0.9380000615164575\n",
      "Lfqa: 0.9065233347260019\n",
      "FactCheck-GPT: 0.8626673138521554\n",
      "ClaimVerify: 0.7574344382916104\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for llama3_zs\n",
    "llama3_zs_roc = roc_auc_score(llama3_zs['label'], llama3_zs['prob'])\n",
    "print(f\"ROC AUC: {llama3_zs_roc}\")\n",
    "llama3_ft_roc = roc_auc_score(llama3_ft['label'], llama3_ft['prob'])\n",
    "print(f\"ROC AUC: {llama3_ft_roc}\")\n",
    "\n",
    "print()  \n",
    "\n",
    "# roc for each subset\n",
    "for subset in llama3_zs['subset'].unique():\n",
    "    subset_data = llama3_zs[llama3_zs['subset'] == subset]\n",
    "    try:\n",
    "        roc = roc_auc_score(subset_data['label'], subset_data['prob'])\n",
    "    except Exception as e:\n",
    "        roc = 0\n",
    "        # print(subset_data)\n",
    "    print(f\"{subset}: {roc}\")\n",
    "\n",
    "print()  \n",
    "    \n",
    "for subset in llama3_ft['subset'].unique():\n",
    "    subset_data = llama3_ft[llama3_ft['subset'] == subset]\n",
    "    try:\n",
    "        roc = roc_auc_score(subset_data['label'], subset_data['prob'])\n",
    "    except Exception as e:\n",
    "        roc = 0\n",
    "        # print(subset_data)\n",
    "    print(f\"{subset}: {roc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    6939\n",
      "0    4884\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    8199\n",
      "No     3624\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    1580\n",
      "0     772\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    2158\n",
      "No      194\n",
      "Name: count, dtype: int64\n",
      "2352 1116\n",
      "prediction\n",
      "Yes    6381\n",
      "No     5442\n",
      "Name: count, dtype: int64 label\n",
      "1    6939\n",
      "0    4884\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    1580\n",
      "0     772\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    1723\n",
      "No      629\n",
      "Name: count, dtype: int64\n",
      "2352 1116\n",
      "1116 1116\n",
      "label\n",
      "Yes    786\n",
      "No     330\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    1031\n",
      "No       85\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "Yes    786\n",
      "No     330\n",
      "Name: count, dtype: int64 prediction\n",
      "Yes    844\n",
      "No     272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# calculate balanced accuracy on LLM-AggreFact for llama3_zs and llama3_ft\n",
    "\n",
    "llama3_zs_llm_aggrefact = llama3_zs[llama3_zs['subset'].isin(subsets_llm_aggrefact)]\n",
    "llama3_ft_llm_aggrefact = llama3_ft[llama3_ft['subset'].isin(subsets_llm_aggrefact)]\n",
    "x1_aggrefact = llama3_zs[llama3_zs['subset'].isin([\"aggrefact_cnndm\", \"aggrefact_xsum\"])]\n",
    "x2_aggrefact = llama3_ft[llama3_ft['subset'].isin([\"aggrefact_cnndm\", \"aggrefact_xsum\"])]\n",
    "\n",
    "print(llama3_zs_llm_aggrefact.label.value_counts(), llama3_zs_llm_aggrefact.prediction.value_counts())\n",
    "print(x1_aggrefact.label.value_counts(), x1_aggrefact.prediction.value_counts())\n",
    "print(len(x1_aggrefact), len(y_aggrefact))\n",
    "\n",
    "print(llama3_ft_llm_aggrefact.prediction.value_counts(), llama3_ft_llm_aggrefact.label.value_counts())\n",
    "print(x2_aggrefact.label.value_counts(), x2_aggrefact.prediction.value_counts())\n",
    "print(len(x2_aggrefact), len(y_aggrefact))\n",
    "\n",
    "y1 = y_aggrefact.merge(x1_aggrefact[['source', 'target', 'prediction', 'prob']], on=['source', 'target'], how='left')\n",
    "y2 = y_aggrefact.merge(x2_aggrefact[['source', 'target', 'prediction', 'prob']], on=['source', 'target'], how='left')\n",
    "print(len(y1), len(y2))\n",
    "print(y1.label.value_counts(), y1.prediction.value_counts())\n",
    "print(y2.label.value_counts(), y2.prediction.value_counts())\n",
    "\n",
    "llama3_zs_llm_aggrefact = pd.concat([llama3_zs_llm_aggrefact, y1])\n",
    "llama3_ft_llm_aggrefact = pd.concat([llama3_ft_llm_aggrefact, y2])\n",
    "\n",
    "def convert_prediction(row):\n",
    "    if row['prediction'] == 'Yes':\n",
    "        row['prediction'] = 1\n",
    "    if row['prediction'] == 'No':\n",
    "        row['prediction'] = 0\n",
    "    return row\n",
    "\n",
    "llama3_zs_llm_aggrefact = llama3_zs_llm_aggrefact.apply(convert_prediction, axis=1)\n",
    "llama3_zs_llm_aggrefact = llama3_zs_llm_aggrefact.apply(convert_label, axis=1)\n",
    "\n",
    "llama3_ft_llm_aggrefact = llama3_ft_llm_aggrefact.apply(convert_prediction, axis=1)\n",
    "llama3_ft_llm_aggrefact = llama3_ft_llm_aggrefact.apply(convert_label, axis=1)\n",
    "\n",
    "# llama3_ft_llm_aggrefact.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    7725\n",
      "0    5214\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "1    9230\n",
      "0    3709\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    7725\n",
      "0    5214\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "1    7225\n",
      "0    5714\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print label and prediction value counts\n",
    "print(llama3_zs_llm_aggrefact.label.value_counts())\n",
    "print(llama3_zs_llm_aggrefact.prediction.value_counts())\n",
    "print(llama3_ft_llm_aggrefact.label.value_counts())\n",
    "print(llama3_ft_llm_aggrefact.prediction.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tofueval_meetingbank: 0.7194623655913979\n",
      "WiCE: 0.5710508078929132\n",
      "tofueval_mediasum: 0.7202310862525758\n",
      "Lfqa: 0.6448243543852121\n",
      "ExpertQA: 0.5430426176247272\n",
      "ClaimVerify: 0.60490298653465\n",
      "FactCheck-GPT: 0.7053710430721328\n",
      "Reveal: 0.8167847654492816\n",
      "AggreFact-CNN: 0.5486395629793046\n",
      "AggreFact-XSum: 0.5907460960092539\n",
      "Average balanced accuracy: 0.646505568579145\n",
      "\n",
      "tofueval_meetingbank: 0.7277956989247312\n",
      "tofueval_mediasum: 0.7097018377560032\n",
      "WiCE: 0.7131524236787394\n",
      "ExpertQA: 0.581899538677807\n",
      "Reveal: 0.8652414713198741\n",
      "Lfqa: 0.8178530697049424\n",
      "FactCheck-GPT: 0.7740748528174937\n",
      "ClaimVerify: 0.7028946674492391\n",
      "AggreFact-CNN: 0.5386595230591449\n",
      "AggreFact-XSum: 0.7176980913823019\n",
      "Average balanced accuracy: 0.7148971174770277\n"
     ]
    }
   ],
   "source": [
    "# Print balanced accuracy for each subset\n",
    "s = 0\n",
    "n = 0\n",
    "for subset in llama3_zs_llm_aggrefact.subset.unique():\n",
    "    subset_data = llama3_zs_llm_aggrefact[llama3_zs_llm_aggrefact['subset'] == subset]\n",
    "    balanced_acc = balanced_accuracy_score(subset_data['label'], subset_data['prediction'])\n",
    "    if balanced_acc > 0:\n",
    "        print(f\"{subset}: {balanced_acc}\")\n",
    "        s += balanced_acc\n",
    "        n+=1\n",
    "    else:\n",
    "        print(f\"{subset}: {0}\")\n",
    "avg_balanced_acc = s / n\n",
    "print(f\"Average balanced accuracy: {avg_balanced_acc}\")\n",
    "print()\n",
    "\n",
    "\n",
    "s = 0\n",
    "n = 0\n",
    "for subset in llama3_ft_llm_aggrefact.subset.unique():\n",
    "    subset_data = llama3_ft_llm_aggrefact[llama3_ft_llm_aggrefact['subset'] == subset]\n",
    "    balanced_acc = balanced_accuracy_score(subset_data['label'], subset_data['prediction'])\n",
    "    if balanced_acc > 0:\n",
    "        print(f\"{subset}: {balanced_acc}\")\n",
    "        s += balanced_acc\n",
    "        n+=1\n",
    "    else:\n",
    "        print(f\"{subset}: {0}\")\n",
    "    \n",
    "avg_balanced_acc = s / n\n",
    "print(f\"Average balanced accuracy: {avg_balanced_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Win Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. LLaMa-3-8B (FT): 0.7811447811447811\n",
      "2. Flan-T5-L (FT): 0.7643097643097643\n",
      "3. Minicheck: 0.7239057239057239\n",
      "4. gpt-3.5-turbo: 0.6936026936026936\n",
      "5. Flan-T5-B (FT): 0.6599326599326599\n",
      "6. AlignScore-L: 0.531986531986532\n",
      "7. LLaMa 3-8B: 0.531986531986532\n",
      "8. AlignScore-B: 0.3939393939393939\n",
      "9. QuestEval: 0.3737373737373737\n",
      "10. BARTScore: 0.26936026936026936\n",
      "11. BERTScore: 0.20875420875420875\n",
      "12. ROUGE: 0.06734006734006734\n"
     ]
    }
   ],
   "source": [
    "# Taken from the HELM implementation\n",
    "# https://github.com/stanford-crfm/helm/blob/d5a43ad3572a7e507533f1f07863aa2033fa6dc9/src/helm/benchmark/presentation/summarize.py#L217\n",
    "\n",
    "from statistics import mean, median\n",
    "from typing import List, Optional\n",
    "\n",
    "# Data for each method across all benchmarks and tables\n",
    "# Scores from the four tables for different benchmarks and metrics\n",
    "rouge_scores = [\n",
    "    51.3, 75.2, 52.4, 45.3, 50.0, 44.1, 50.9, 50.9, 74.3, 45.7,  # Table 1\n",
    "    69.1, 51.9, 4.7, 85.3, 42.5, 47.1, 38.7, 60.1,               # Table 2\n",
    "    56.2, 57.2, 56.4, 67.3,                                      # Table 3\n",
    "    60.8, 56.8, 77.3, 51.5, 53.3                                 # Table 4\n",
    "]\n",
    "\n",
    "bertscore_scores = [\n",
    "    55.6, 80.1, 57.5, 42.5, 55.9, 43.8, 57.4, 56.4, 75.9, 52.3,  # Table 1\n",
    "    71.3, 54.4, 12.4, 88.7, 53.2, 55.2, 54.4, 68.4,              # Table 2\n",
    "    66.1, 63.3, 70.6, 68.5,                                      # Table 3\n",
    "    66.3, 72.7, 85.6, 55.1, 70.5                                 # Table 4\n",
    "]\n",
    "\n",
    "bartscore_scores = [\n",
    "    57.8, 87.6, 60.6, 45.2, 63.5, 49.7, 58.4, 58.9, 68.9, 57.1,  # Table 1\n",
    "    65.7, 58.3, 2.1, 87.2, 38.9, 71.8, 44.2, 72.7,               # Table 2\n",
    "    66.7, 63.3, 68.3, 71.2,                                      # Table 3\n",
    "    79.3, 70.4, 87.8, 57.9, 77.7                                 # Table 4\n",
    "]\n",
    "\n",
    "questeval_scores = [\n",
    "    62.4, 92.7, 68.4, 48.0, 60.0, 56.8, 64.5, 63.1, 79.4, 54.0,  # Table 1\n",
    "    71.4, 62.0, 34.2, 87.2, 58.1, 61.1, 61.2, 77.2,              # Table 2\n",
    "    57.0, 56.9, 66.4, 70.6,                                      # Table 3\n",
    "    84.9, 75.5, 80.7, 59.4, 71.3                                 # Table 4\n",
    "]\n",
    "\n",
    "alignscore_base_scores = [\n",
    "    82.6, 85.7, 86.0, 74.1, 72.4, 78.8, 70.6, 61.7, 77.4, 53.1,  # Table 1\n",
    "    64.8, 66.0, 14.1, 74.9, 65.4, 71.7, 71.1, 72.2,              # Table 2\n",
    "    66.3, 76.4, 75.3, 80.9,                                      # Table 3\n",
    "    91.7, 77.8, 84.6, 57.3, 72.7                                 # Table 4\n",
    "]\n",
    "\n",
    "alignscore_large_scores = [\n",
    "    83.9, 88.1, 83.6, 79.3, 77.9, 87.0, 71.4, 65.1, 74.4, 59.6,  # Table 1\n",
    "    55.8, 74.4, 13.2, 78.7, 73.2, 72.4, 78.2, 72.6,              # Table 2\n",
    "    67.4, 78.2, 74.1, 80.6,                                      # Table 3\n",
    "    92.2, 81.4, 82.2, 57.7, 70.4                                 # Table 4\n",
    "]\n",
    "\n",
    "gpt_35_turbo_scores = [\n",
    "    81.5, 90.3, 92.2, 80.0, 64.0, 84.1, 67.5, 73.5, 82.4, 50.5,  # Table 1\n",
    "    66.6, 80.3, 65.7, 86.5, 68.2, 78.4, 76.4, 76.0,              # Table 2\n",
    "    69.6, 82.7, 73.7, 82.0,                                      # Table 3\n",
    "    94.2, 81.0, 89.6, 63.5, 78.8                                 # Table 4\n",
    "]\n",
    "\n",
    "llama_3_8b_scores = [\n",
    "    75.6, 87.6, 92.9, 68.4, 68.9, 82.9, 59.4, 69.0, 79.2, 58.7,  # Table 1\n",
    "    66.0, 76.9, 89.9, 85.3, 70.6, 73.3, 70.8, 69.8,              # Table 2\n",
    "    72.7, 80.0, 77.6, 78.9,                                      # Table 3\n",
    "    91.1, 77.5, 79.4, 58.2, 66.7                                 # Table 4\n",
    "]\n",
    "\n",
    "minicheck_scores = [\n",
    "    83.2, 88.9, 86.9, 77.4, 76.8, 83.6, 74.9, 69.9, 78.4, 56.2,  # Table 1\n",
    "    67.3, 69.2, 46.9, 81.4, 67.3, 76.9, 76.8, 77.2,              # Table 2\n",
    "    73.4, 77.7, 81.1, 84.8,                                      # Table 3\n",
    "    93.9, 84.1, 93.1, 61.8, 81.1                                 # Table 4\n",
    "]\n",
    "\n",
    "\n",
    "flan_t5_b_ft_scores = [\n",
    "    87.7, 98.5, 91.9, 75.4, 86.6, 86.1, 77.3, 72.1, 81.5, 57.4,  # Table 1\n",
    "    68.5, 68.6, 27.2, 84.3, 59.8, 74.1, 82.1, 75.7,              # Table 2\n",
    "    70.0, 75.7, 78.1, 76.6,                                      # Table 3\n",
    "    90.0, 82.3, 88.5, 59.5, 79.9                                 # Table 4\n",
    "]\n",
    "\n",
    "flan_t5_l_ft_scores = [\n",
    "    89.0, 99.3, 94.0, 83.4, 88.8, 89.9, 80.8, 74.4, 82.7, 55.7,  # Table 1\n",
    "    69.7, 76.9, 54.6, 85.4, 67.4, 74.8, 87.6, 75.9,              # Table 2\n",
    "    62.3, 75.9, 75.4, 75.9,                                      # Table 3\n",
    "    90.5, 84.0, 88.1, 61.5, 80.0                                 # Table 4\n",
    "]\n",
    "\n",
    "llama_3_8b_ft_scores = [\n",
    "    87.2, 98.2, 95.8, 85.4, 78.7, 89.8, 69.1, 74.3, 83.9, 63.9,  # Table 1\n",
    "    66.0, 70.7, 47.4, 77.7, 69.5, 75.8, 76.5, 76.2,              # Table 2\n",
    "    71.3, 83.2, 75.3, 82.9,                                      # Table 3\n",
    "    93.8, 86.3, 90.7, 61.7, 75.7                                 # Table 4\n",
    "]\n",
    "\n",
    "# Combine all scores into a list of lists\n",
    "data_scores = [\n",
    "    rouge_scores,             # ROUGE\n",
    "    bertscore_scores,         # BERTScore\n",
    "    bartscore_scores,         # BARTScore\n",
    "    questeval_scores,         # QuestEval\n",
    "    alignscore_base_scores,   # AlignScore-B\n",
    "    alignscore_large_scores,  # AlignScore-L\n",
    "    gpt_35_turbo_scores,      # gpt-3.5-turbo\n",
    "    llama_3_8b_ft_scores,     # LLaMa-3-8B (FT)\n",
    "    minicheck_scores,         # Minicheck\n",
    "    llama_3_8b_scores,        # LLaMa 3-8B\n",
    "    flan_t5_b_ft_scores,      # Flan-T5-B (FT)\n",
    "    flan_t5_l_ft_scores       # Flan-T5-L (FT)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def compute_aggregate_row_win_rates(data: List[List[float]], aggregation: str = \"mean\") -> List[Optional[float]]:\n",
    "    win_rates_per_row: List[List[float]] = [[] for _ in data] # each row is a method\n",
    "\n",
    "    # Transpose the data to work with columns\n",
    "    data_transposed = list(zip(*data))\n",
    "    \n",
    "    # print(data_transposed)\n",
    "\n",
    "    for values in data_transposed:  # each column is a dataset\n",
    "        # print(values)\n",
    "        \n",
    "        x = [(row, j) for j, row in enumerate(values)]\n",
    "        \n",
    "        # print(x)\n",
    "        # print(sorted(x))\n",
    "        \n",
    "        for wins, (v, j) in enumerate(sorted(x)): # here j is the index of the method (stored as a row)\n",
    "            win_rate = wins / (len(values) - 1) # normalize to [0, 1]\n",
    "            win_rates_per_row[j].append(win_rate) # add to the list of scores for a method (stored as a row)\n",
    "            \n",
    "        # print()\n",
    "        \n",
    "    aggregate_win_rates: List[Optional[float]] = []\n",
    "    for win_rates in win_rates_per_row:\n",
    "        if len(win_rates) == 0:\n",
    "            aggregate_win_rates.append(None)\n",
    "        else:\n",
    "            aggregate = mean(win_rates) if aggregation == \"mean\" else median(win_rates)\n",
    "            aggregate_win_rates.append(aggregate)\n",
    "\n",
    "    return aggregate_win_rates\n",
    "\n",
    "# Compute median win rates\n",
    "# median_win_rates = compute_aggregate_row_win_rates(data_scores, \"median\")\n",
    "mean_win_rates = compute_aggregate_row_win_rates(data_scores, \"mean\")\n",
    "# print(median_win_rates)\n",
    "\n",
    "# Print mean win rates for each method\n",
    "methods = [\n",
    "    \"ROUGE\",\n",
    "    \"BERTScore\",\n",
    "    \"BARTScore\",\n",
    "    \"QuestEval\",\n",
    "    \"AlignScore-B\",\n",
    "    \"AlignScore-L\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"LLaMa-3-8B (FT)\",\n",
    "    \"Minicheck\",\n",
    "    \"LLaMa 3-8B\",\n",
    "    \"Flan-T5-B (FT)\",\n",
    "    \"Flan-T5-L (FT)\"\n",
    "]\n",
    "\n",
    "# Get rank of each method\n",
    "def get_rank(data):\n",
    "    return sorted(range(len(data)), key=lambda k: data[k], reverse=True)\n",
    "\n",
    "rank = get_rank(mean_win_rates)\n",
    "\n",
    "# for method, win_rate in zip(methods, mean_win_rates):\n",
    "#     print(f\"{method}: {win_rate}\")\n",
    "    \n",
    "# print rank, method and win rate\n",
    "for i, r in enumerate(rank):\n",
    "    print(f\"{i+1}. {methods[r]}: {mean_win_rates[r]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE: 54.67777777777778\n",
      "BERTScore: 61.26296296296296\n",
      "BARTScore: 62.63703703703704\n",
      "QuestEval: 66.08888888888889\n",
      "AlignScore-B: 71.31851851851852\n",
      "AlignScore-L: 73.07407407407408\n",
      "gpt-3.5-turbo: 77.00740740740741\n",
      "LLaMa-3-8B (FT): 78.03703703703704\n",
      "Minicheck: 76.67407407407407\n",
      "LLaMa 3-8B: 75.08518518518518\n",
      "Flan-T5-B (FT): 76.12592592592593\n",
      "Flan-T5-L (FT): 78.66296296296296\n"
     ]
    }
   ],
   "source": [
    "# Mean scores for each method\n",
    "\n",
    "mean_scores = [mean(scores) for scores in data_scores]\n",
    "for method, score in zip(methods, mean_scores):\n",
    "    print(f\"{method}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can you also do two  more things:\n",
    "\n",
    "Firstly multiply mean win rate by 100 (as it is a percentage)\n",
    "\n",
    "Secondly, add a new column to the table. it's called \"Average AUC\". i will post the data below:\n",
    "\n",
    "ROUGE: 54.67777777777778\n",
    "BERTScore: 63.455555555555556\n",
    "BARTScore: 62.63703703703704\n",
    "QuestEval: 66.08888888888889\n",
    "AlignScore-B: 71.31851851851852\n",
    "AlignScore-L: 73.07407407407408\n",
    "gpt-3.5-turbo: 77.06666666666666\n",
    "LLaMa-3-8B (FT): 78.03703703703704\n",
    "Minicheck: 76.67407407407407\n",
    "LLaMa 3-8B: 75.08518518518518\n",
    "Flan-T5-B (FT): 76.12592592592593\n",
    "Flan-T5-L (FT): 78.66296296296296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NLI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mNLI\u001b[49m \u001b[38;5;241m-\u001b[39m ANLI, WANLI, DADC\u001b[38;5;241m-\u001b[39mNLI, Sci\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NLI' is not defined"
     ]
    }
   ],
   "source": [
    "NLI - ANLI, WANLI, DADC-NLI, SciTail, \n",
    "\n",
    "\n",
    "Fact Verification/Claim Verification - \n",
    "\n",
    "News Summarization Evaluation - AggreFact, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
