{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1\n",
      "16\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "%env RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE=1\n",
    "\n",
    "import modin.pandas as pd \n",
    "\n",
    "import modin.config as cfg; print(cfg.CpuCount.get()); cfg.CpuCount.put(8); print(cfg.CpuCount.get())\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ftfy import fix_text\n",
    "\n",
    "pd.set_option('max_colwidth', 400)\n",
    "\n",
    "\n",
    "#Fix seed\n",
    "seed = 4212\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hf_dataset(name, train_slices, val_slices, test_slices, fields, label_dict, extra_hf_field=None):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "    name: Name of the dataset on HF\n",
    "    train_slices: \n",
    "    \"\"\"\n",
    "    if extra_hf_field:\n",
    "        dataset = load_dataset(name, extra_hf_field)\n",
    "    else:\n",
    "        dataset = load_dataset(name)\n",
    "        \n",
    "    name = name if not extra_hf_field else name+\"_\"+extra_hf_field\n",
    "    \n",
    "    print(\"Dataset Name: \", name)    \n",
    "    print(dataset)\n",
    "    \n",
    "    label_field = fields[2]\n",
    "    \n",
    "    train = pd.DataFrame()\n",
    "    val = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    if train_slices is not None:\n",
    "        for s in train_slices:\n",
    "            temp = pd.DataFrame(dataset[s][:])[fields]\n",
    "            train = pd.concat([train, temp], ignore_index=True)\n",
    "            # train = train.append(temp)\n",
    "        train['D'] = name\n",
    "        train = train.rename(columns = {label_field: 'L', fields[0]: 'P', fields[1]: 'H'})\n",
    "        train['L'] = train['L'].astype(str).replace(label_dict)\n",
    "        print(\"Train: \", len(train))\n",
    "    \n",
    "    if val_slices is not None:\n",
    "        for s in val_slices:\n",
    "            temp = pd.DataFrame(dataset[s][:])[fields]\n",
    "            val = pd.concat([val, temp], ignore_index=True)\n",
    "            # val = val.append(temp)               \n",
    "        val['D'] = name\n",
    "        val = val.rename(columns = {label_field: 'L', fields[0]: 'P', fields[1]: 'H'})\n",
    "        val['L'] = val['L'].astype(str).replace(label_dict)\n",
    "        print(\"Val: \", len(val))\n",
    "\n",
    "        \n",
    "    if test_slices is not None:\n",
    "        for s in test_slices:\n",
    "            temp = pd.DataFrame(dataset[s][:])[fields]\n",
    "            test = pd.concat([test, temp], ignore_index=True)\n",
    "            # test = test.append(temp)\n",
    "        test['D'] = name\n",
    "        test = test.rename(columns = {label_field: 'L', fields[0]: 'P', fields[1]: 'H'})\n",
    "        test['L'] = test['L'].astype(str).replace(label_dict)\n",
    "        print(\"Test: \", len(test))\n",
    "        \n",
    "    return train, val, test   \n",
    "\n",
    "def append_to_global(train, val, test):\n",
    "    global all_train, all_val, all_test\n",
    "    \n",
    "    if train is not None:\n",
    "        # all_train = all_train.append(train, ignore_index=True)\n",
    "        all_train = pd.concat([all_train, train], ignore_index=True)\n",
    "        \n",
    "    if val is not None:\n",
    "        # all_val = all_val.append(val, ignore_index=True)\n",
    "        all_val = pd.concat([all_val, val], ignore_index=True)\n",
    "        \n",
    "    if test is not None:\n",
    "        # all_test = all_test.append(test, ignore_index=True)\n",
    "        all_test = pd.concat([all_test, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Ray execution environment not yet initialized. Initializing...\n",
      "To remove this warning, run the following python code before doing dataframe operations:\n",
      "\n",
      "    import ray\n",
      "    ray.init()\n",
      "\n",
      "2024-02-07 10:38:53,981\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "all_train = pd.DataFrame()\n",
    "all_val = pd.DataFrame()\n",
    "all_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ANLI \n",
    "\n",
    "# t1,t2,t3 = load_hf_dataset(\"anli\",\n",
    "#                     [\"train_r3\"],\n",
    "#                     [\"dev_r1\",\"dev_r2\",\"dev_r3\"],\n",
    "#                     [\"test_r1\",\"test_r2\",\"test_r3\"],\n",
    "#                     ['premise','hypothesis','label'],\n",
    "#                     {'0': 'e', '1': 'n', '2': 'c'},\n",
    "#                    )\n",
    "\n",
    "# t1_r1_r2,_,_ = load_hf_dataset(\"anli\",\n",
    "#                     [\"train_r1\", \"train_r2\"],\n",
    "#                     None,\n",
    "#                     None,\n",
    "#                     ['premise','hypothesis','label'],\n",
    "#                     {'0': 'e', '1': 'n', '2': 'c'},\n",
    "#                    )\n",
    "\n",
    "\n",
    "# count = 0\n",
    "# def get_length(row):\n",
    "#     global count\n",
    "#     text_a = row['P']\n",
    "#     text_a = len(text_a.split())\n",
    "    \n",
    "#     row['len(P)'] = text_a\n",
    "    \n",
    "#     if not count % 1000:\n",
    "#         print(count)\n",
    "#     count+=1\n",
    "    \n",
    "#     return row\n",
    "\n",
    "\n",
    "# t1 = t1.apply(get_length, axis=1)\n",
    "# t1_r1_r2_1 = t1_r1_r2[t1_r1_r2['L'] == \"e\"]\n",
    "# t1_r1_r2_2 = t1_r1_r2[t1_r1_r2['L'] != \"e\"].sample(len(t1_r1_r2_1) - 10000, random_state=seed)\n",
    "\n",
    "# t1_r1_r2 = pd.concat([t1_r1_r2_1, t1_r1_r2_2])\n",
    "\n",
    "# tmp = t1[t1['L'] != \"e\"]\n",
    "# tmp1 = tmp[tmp[\"len(P)\"] < 15].drop_duplicates(subset=[\"P\"], keep=\"first\")\n",
    "# tmp2 = tmp[tmp[\"len(P)\"] > 15]\n",
    "\n",
    "# t1_new_entail = t1[t1['L'] == \"e\"]\n",
    "# t1_new_contradict = pd.concat([tmp1, tmp2])\n",
    " \n",
    "# t1_new_contradict = t1_new_contradict[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "# t1_new_contradict = t1_new_contradict.sample(len(t1_new_entail), random_state=seed)\n",
    "\n",
    "# t1_new_entail = t1_new_entail[['P','H','L','D']]\n",
    "\n",
    "# t1_new = pd.concat([t1_r1_r2, t1_new_entail, t1_new_contradict])\n",
    "\n",
    "\n",
    "# append_to_global(t1_new, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  anli\n",
      "DatasetDict({\n",
      "    train_r1: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 16946\n",
      "    })\n",
      "    dev_r1: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test_r1: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train_r2: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 45460\n",
      "    })\n",
      "    dev_r2: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    test_r2: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "    train_r3: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 100459\n",
      "    })\n",
      "    dev_r3: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 1200\n",
      "    })\n",
      "    test_r3: Dataset({\n",
      "        features: ['uid', 'premise', 'hypothesis', 'label', 'reason'],\n",
      "        num_rows: 1200\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  162865\n",
      "Val:  3200\n",
      "Test:  3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: `df.groupby(categorical_by, sort=False)` implementation has mismatches with pandas:\n",
      "the groupby keys will be sorted anyway, although the 'sort=False' was passed. See the following issue for more details: https://github.com/modin-project/modin/issues/3571.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    52111\n",
       "c    41965\n",
       "n    11000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANLI \n",
    "\n",
    "t1,t2,t3 = load_hf_dataset(\"anli\",\n",
    "                    [\"train_r1\", \"train_r2\", \"train_r3\"],\n",
    "                    [\"dev_r1\",\"dev_r2\",\"dev_r3\"],\n",
    "                    [\"test_r1\",\"test_r2\",\"test_r3\"],\n",
    "                    ['premise','hypothesis','label'],\n",
    "                    {'0': 'e', '1': 'n', '2': 'c'},\n",
    "                   )\n",
    "\n",
    "\n",
    "train_entail = t1[t1['L'] == \"e\"]\n",
    "train_contradict = t1[t1['L'] == \"c\"]\n",
    "train_neutral = t1[t1['L'] == \"n\"].sample(11000, random_state=seed)\n",
    "t1 = pd.concat([train_entail, train_contradict, train_neutral], ignore_index=True)\n",
    "\n",
    "append_to_global(t1, t2, t3)\n",
    "\n",
    "t1.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  alisawuffles/WANLI\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'gold', 'genre', 'pairID'],\n",
      "        num_rows: 102885\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'gold', 'genre', 'pairID'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  102885\n",
      "Val:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    63511\n",
       "n    48977\n",
       "c    15397\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WANLI\n",
    "t1,t2,t3 = load_hf_dataset(\"alisawuffles/WANLI\",\n",
    "                    [\"train\"],\n",
    "                    [\"test\"],\n",
    "                    None,\n",
    "                    ['premise','hypothesis','gold'],\n",
    "                    {'entailment': 'e', 'neutral': 'n', 'contradiction': 'c'},\n",
    "                   )\n",
    "\n",
    "\n",
    "# Increase the number of entailment examples in the training set\n",
    "x = t1[t1['L'] == \"e\"].sample(25000, random_state=seed)\n",
    "train = pd.concat([t1, x], ignore_index=True)\n",
    "\n",
    "\n",
    "append_to_global(train, None, t2)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #QQP:  Subsample 10k longest pairs from this dataset \n",
    "# t1,t2,t3 = load_hf_dataset(\"glue\",\n",
    "#                     [\"train\"],\n",
    "#                     [\"validation\"],\n",
    "#                     None,\n",
    "#                     ['question1','question2','label'],\n",
    "#                     {'1': 'e', '0': 'n'},\n",
    "#                     \"qqp\"\n",
    "#                    )\n",
    "\n",
    "\n",
    "# t1 = t1.apply(get_length, axis=1)\n",
    "# tmp = t1[t1[\"len(P)\"] > 19]\n",
    "# tmp1 = tmp[tmp[\"L\"] == \"e\"].sample(n=3000, random_state=seed)\n",
    "# tmp2 = tmp[tmp[\"L\"] != \"e\"].sample(n=3000, random_state=seed)\n",
    "\n",
    "# t1_new = pd.concat([tmp1, tmp2])[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "\n",
    "# append_to_global(t1_new, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  glue_rte\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 2490\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 277\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "})\n",
      "Train:  2490\n",
      "Val:  277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    1249\n",
       "n    1241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RTE\n",
    "t1,t2,t3 = load_hf_dataset(\"glue\",\n",
    "                    [\"train\"],\n",
    "                    [\"validation\"],\n",
    "                    None,\n",
    "                    ['sentence1','sentence2','label'],\n",
    "                    {'0': 'e', '1': 'n'},\n",
    "                    \"rte\"\n",
    "                   )\n",
    "\n",
    "append_to_global(t1, t2, None)\n",
    "\n",
    "t1.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name:  scitail_tsv_format\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 23097\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 2126\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'label'],\n",
      "        num_rows: 1304\n",
      "    })\n",
      "})\n",
      "Train:  23097\n",
      "Val:  1304\n",
      "Test:  2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'NoneType'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'dict'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    8472\n",
       "n    8472\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SciTail\n",
    "t1,t2,t3 = load_hf_dataset(\"scitail\",\n",
    "                    [\"train\"],\n",
    "                    [\"validation\"],\n",
    "                    [\"test\"],\n",
    "                    ['premise','hypothesis','label'],\n",
    "                    {'entails': 'e', 'neutral': 'n'},\n",
    "                    \"tsv_format\"\n",
    "                   )\n",
    "\n",
    "\n",
    "t1_contradict = t1[t1['L'] != \"e\"]\n",
    "t1_entail = t1[t1['L'] == \"e\"]\n",
    "\n",
    "t1_contradict = t1_contradict.sample(len(t1_entail), random_state=seed)\n",
    "t1 = pd.concat([t1_contradict, t1_entail], ignore_index=True)\n",
    "t1['D'] = \"scitail\"\n",
    "t2['D'] = \"scitail\"\n",
    "t3['D'] = \"scitail\"\n",
    "\n",
    "append_to_global(t1, t2, t3)\n",
    "\n",
    "t1.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14995\n",
      "2425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    9998\n",
       "n    4999\n",
       "c    4997\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LingNLI\n",
    "t1 = pandas.read_json(\"https://raw.githubusercontent.com/Alicia-Parrish/ling_in_loop/master/NLI_data/3_Ling_in_loop_protocol/train_round5_LitL_combined.jsonl\", lines=True)[['premise','hypothesis','label']]\n",
    "t1 = t1.rename(columns = {'premise':'P','hypothesis':'H','label':'L'})\n",
    "t1.L = t1.L.replace({\"entailment\":\"e\",\"neutral\":\"n\",\"contradiction\":\"c\"})\n",
    "t1['D'] = \"LingNLI\"\n",
    "\n",
    "t2 = pandas.read_json(\"https://raw.githubusercontent.com/Alicia-Parrish/ling_in_loop/master/NLI_data/3_Ling_in_loop_protocol/val_round5_LitL_combined.jsonl\", lines=True)[['premise','hypothesis','label']]\n",
    "t2 = t2.rename(columns = {'premise':'P','hypothesis':'H','label':'L'})\n",
    "t2.L = t2.L.replace({\"entailment\":\"e\",\"neutral\":\"n\",\"contradiction\":\"c\"})\n",
    "t2['D'] = \"LingNLI\"\n",
    "\n",
    "print(len(t1)), print(len(t2))\n",
    "\n",
    "t1 = pd.DataFrame(t1)\n",
    "\n",
    "x = t1[t1['L'] == \"e\"]\n",
    "train = pd.concat([t1, x], ignore_index=True)\n",
    "\n",
    "t2 = pd.DataFrame(t2)\n",
    "\n",
    "append_to_global(train, t2, None)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConTRoL-NLI\n",
    "\n",
    "# t1 = pandas.read_json(\"https://github.com/csitfun/ConTRoL-dataset/raw/main/data/train.jsonl\", lines=True)[['premise','hypothesis','label']]\n",
    "# t2 = pandas.read_json(\"https://github.com/csitfun/ConTRoL-dataset/raw/main/data/dev.jsonl\", lines=True)[['premise','hypothesis','label']]\n",
    "# t3 = pandas.read_json(\"https://github.com/csitfun/ConTRoL-dataset/raw/main/data/test.jsonl\", lines=True)[['premise','hypothesis','label']]\n",
    "\n",
    "# t1['D'] = \"ConTRoL\"\n",
    "# t2['D'] = \"ConTRoL\"\n",
    "# t3['D'] = \"ConTRoL\"\n",
    "\n",
    "# t1 = t1.rename(columns = {'premise':'P','hypothesis':'H','label':'L'})\n",
    "# t2 = t2.rename(columns = {'premise':'P','hypothesis':'H','label':'L'})\n",
    "# t3 = t3.rename(columns = {'premise':'P','hypothesis':'H','label':'L'})\n",
    "\n",
    "# t1 = pd.DataFrame(t1)\n",
    "# t2 = pd.DataFrame(t2)\n",
    "# t3 = pd.DataFrame(t3)\n",
    "\n",
    "# print(len(t1)), print(len(t2)), print(len(t3))\n",
    "\n",
    "# def get_length(row):\n",
    "#     text_a = row['P']\n",
    "#     text_a = len(text_a.split())\n",
    "    \n",
    "#     row['len(P)'] = text_a\n",
    "    \n",
    "#     return row\n",
    "\n",
    "# t1 = t1.apply(get_length, axis=1)\n",
    "# t2 = t2.apply(get_length, axis=1)\n",
    "# t3 = t3.apply(get_length, axis=1)\n",
    "\n",
    "# t1 = t1[t1[\"len(P)\"] > 25]\n",
    "# t2 = t2[t2[\"len(P)\"] > 25]\n",
    "# t3 = t3[t3[\"len(P)\"] > 25]\n",
    "\n",
    "# print(len(t1)), print(len(t2)), print(len(t3))\n",
    "\n",
    "# append_to_global(t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Contract-NLI https://huggingface.co/datasets/kiddothe2b/contract-nli\n",
    "\n",
    "# t1,t2,t3 = load_hf_dataset(\"kiddothe2b/contract-nli\",\n",
    "#                     [\"train\"],\n",
    "#                     [\"validation\"],\n",
    "#                     [\"test\"],\n",
    "#                     ['premise','hypothesis','label'],\n",
    "#                     {'1': 'e', '2': 'n', '0': 'c'},\n",
    "#                     \"contractnli_b\"\n",
    "#                    )\n",
    "\n",
    "# #for each premise, we choose one hypothesis from the same label\n",
    "# t1 = t1.drop_duplicates(subset=[\"P\",\"L\"], keep=\"first\")\n",
    "\n",
    "# tmp1 = t1[t1[\"L\"] == \"e\"].sample(n=250, random_state=seed)\n",
    "# tmp2 = t1[t1[\"L\"] != \"e\"].sample(n=150, random_state=seed)\n",
    "\n",
    "# train = pd.concat([tmp1, tmp2])\n",
    "\n",
    "# t2 = t2.drop_duplicates(subset=[\"P\",\"L\"], keep=\"first\")\n",
    "\n",
    "# append_to_global(train, t2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_deploy_ray_func pid=17470)\u001b[0m 0\n",
      "\u001b[36m(_deploy_ray_func pid=17465)\u001b[0m 3000\u001b[32m [repeated 24x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17471)\u001b[0m 6000\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17471)\u001b[0m 9000\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17471)\u001b[0m 12000\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17470)\u001b[0m 15000\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17466)\u001b[0m 18000\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17471)\u001b[0m 22000\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17468)\u001b[0m 25000\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17470)\u001b[0m 0\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    4206\n",
       "n    2173\n",
       "c    2110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VitaminC\n",
    "\n",
    "dataset = load_dataset(\"tals/vitaminc\")\n",
    "\n",
    "\n",
    "tmp1 = dataset[\"train\"].to_pandas()\n",
    "tmp2 = dataset[\"validation\"].to_pandas()\n",
    "tmp3 = dataset[\"test\"].to_pandas()\n",
    "\n",
    "t1 = pd.DataFrame(tmp1)\n",
    "t2 = pd.DataFrame(tmp2)\n",
    "t3 = pd.DataFrame(tmp3)\n",
    "\n",
    "\n",
    "t1 = t1.drop_duplicates(subset=[\"evidence\"], keep=\"first\")\n",
    "\n",
    "#check if evidence has a number in it\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "\n",
    "count = 0\n",
    "def clean_vitaminc(row):\n",
    "    premise = row['evidence']\n",
    "    hypothesis = row['claim']\n",
    "    label = row['label']\n",
    "    page = row['page']\n",
    "    premise_length = len(premise.split())\n",
    "    hypothesis_length = len(hypothesis.split())\n",
    "    mean = (premise_length + hypothesis_length) / 2\n",
    "    \n",
    "    if label == \"SUPPORTS\":\n",
    "        label = \"e\"\n",
    "    elif label == \"REFUTES\":\n",
    "        label = \"c\"\n",
    "    else:\n",
    "        label = \"n\"\n",
    "        \n",
    "    row['P'] = f\"Page Name: {page}\\n\\n{premise}\"\n",
    "    row['H'] = hypothesis\n",
    "    row['L'] = label\n",
    "    row['len'] = mean\n",
    "    row['D'] = \"vitaminc\"\n",
    "    row['hasNumbers'] = hasNumbers(hypothesis)\n",
    "    \n",
    "    global count\n",
    "    if not count % 1000:\n",
    "        print(count)\n",
    "    count+=1\n",
    "    \n",
    "    return row\n",
    "\n",
    "t1 = t1.apply(clean_vitaminc, axis=1)[[\"P\",\"H\",\"L\",\"D\", \"len\", \"hasNumbers\"]]\n",
    "t1 = t1[t1['hasNumbers'] == True]\n",
    "\n",
    "t1_ = t1[t1['len'] <= 35][[\"P\",\"H\",\"L\",\"D\"]]\n",
    "t1_e = t1_[t1_['L'] == \"e\"].sample(n=500, random_state=seed)\n",
    "t1_c = t1_[t1_['L'] == \"c\"].sample(n=800, random_state=seed)\n",
    "t1_n = t1_[t1_['L'] == \"n\"].sample(n=800, random_state=seed)\n",
    "\n",
    "t1 = t1[t1['len'] > 35][[\"P\",\"H\",\"L\",\"D\"]]\n",
    "t1 = pd.concat([t1, t1_e, t1_c, t1_n], ignore_index=True)\n",
    "\n",
    "t2 = t2.sample(n=1000, random_state=seed)\n",
    "t2 = t2.apply(clean_vitaminc, axis=1)[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "# t3 = t3.apply(clean_vitaminc, axis=1)[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "\n",
    "append_to_global(t1, t2, None)\n",
    "\n",
    "t1.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HealthFact\n",
    "# t1,t2,t3 = load_hf_dataset(\"health_fact\",\n",
    "#                     [\"train\"],\n",
    "#                     [\"validation\"],\n",
    "#                     [\"test\"],\n",
    "#                     ['main_text','claim','label'],\n",
    "#                     {'2': 'e', '1': 'n', '0': 'c'},\n",
    "#                    )\n",
    "\n",
    "# #remove -1 and 3\n",
    "# t1 = t1[(t1['L'] != \"-1\") & (t1['L'] != \"3\")]\n",
    "# t2 = t2[(t2['L'] != \"-1\") & (t2['L'] != \"3\")]\n",
    "# t3 = t3[(t3['L'] != \"-1\") & (t3['L'] != \"3\")]\n",
    "\n",
    "# count = 0\n",
    "# def get_length(row):\n",
    "#     global count\n",
    "#     text_a = row['P']\n",
    "#     text_a = len(text_a.split())\n",
    "#     text_b = row['H']\n",
    "#     text_b = len(text_b.split())\n",
    "    \n",
    "#     row['len(P)'] = text_a\n",
    "#     row['len(H)'] = text_b\n",
    "    \n",
    "#     if not count % 1000:\n",
    "#         print(count)\n",
    "#     count+=1\n",
    "    \n",
    "#     return row\n",
    "\n",
    "# t1 = t1.apply(get_length, axis=1)\n",
    "# t1 = t1[t1['L'] != 'n']\n",
    "# t1 = t1[t1[\"len(P)\"] < 1500][[\"P\",\"H\",\"L\",\"D\", \"len(H)\"]]\n",
    "# t1 = t1[t1['len(H)'] > 15][[\"P\",\"H\",\"L\",\"D\"]]\n",
    "\n",
    "# tmp1 = t1[t1[\"L\"] == \"e\"]\n",
    "# tmp2 = t1[t1[\"L\"] == \"c\"].sample(n=len(tmp1), random_state=seed)\n",
    "\n",
    "# train = pd.concat([tmp1, tmp2])\n",
    "\n",
    "# t2 = t2.apply(get_length, axis=1)\n",
    "# t2 = t2[t2['L'] != 'n']\n",
    "# t2 = t2[t2[\"len(P)\"] < 1500][[\"P\",\"H\",\"L\",\"D\", \"len(H)\"]]\n",
    "# t2 = t2[t2['len(H)'] > 15][[\"P\",\"H\",\"L\",\"D\"]].sample(n=200, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "# # t3 = t3.apply(get_length, axis=1)\n",
    "# # t3 = t3[t3[\"len(P)\"] < 2500][[\"P\",\"H\",\"L\",\"D\"]]\n",
    "\n",
    "# append_to_global(train, t2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HealthVer\n",
    "\n",
    "# train = pandas.read_csv(\"https://raw.githubusercontent.com/sarrouti/HealthVer/master/data/healthver_train.csv\")[['evidence','claim','label']]\n",
    "# validation = pandas.read_csv(\"https://raw.githubusercontent.com/sarrouti/HealthVer/master/data/healthver_dev.csv\")[['evidence','claim','label']]\n",
    "# test = pandas.read_csv(\"https://raw.githubusercontent.com/sarrouti/HealthVer/master/data/healthver_test.csv\")[['evidence','claim','label']]\n",
    "\n",
    "# train['label'] = train['label'].astype(str).replace({'Supports': 'e', 'Neutral': 'n', 'Refutes': 'c'})\n",
    "# validation['label'] = validation['label'].astype(str).replace({'Supports': 'e', 'Neutral': 'n', 'Refutes': 'c'})\n",
    "# test['label'] = test['label'].astype(str).replace({'Supports': 'e', 'Neutral': 'n', 'Refutes': 'c'})\n",
    "\n",
    "\n",
    "# train = train.rename(columns = {'evidence':'P','claim':'H','label':'L'})\n",
    "# validation = validation.rename(columns = {'evidence':'P','claim':'H','label':'L'})\n",
    "# test = test.rename(columns = {'evidence':'P','claim':'H','label':'L'})\n",
    "\n",
    "# train['D'] = \"HealthVer\"\n",
    "# validation['D'] = \"HealthVer\"\n",
    "# test['D'] = \"HealthVer\"\n",
    "\n",
    "# append_to_global(train, validation, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 1000, len(validation): 486, len(test): 1075\n",
      "len(train): 2001, len(validation): 827, len(test): 1854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "c    1001\n",
       "e    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DeFacto\n",
    "\n",
    "train = pandas.read_json(\"https://github.com/microsoft/DeFacto/raw/main/data/train.jsonl\", lines=True)[['article', 'candidate', 'has_error', 'feedback']]\n",
    "validation = pandas.read_json(\"https://github.com/microsoft/DeFacto/raw/main/data/val.jsonl\", lines=True)[['article', 'candidate', 'has_error', 'feedback']]\n",
    "test = pandas.read_json(\"https://github.com/microsoft/DeFacto/raw/main/data/test.jsonl\", lines=True)[['article', 'candidate', 'has_error', 'feedback']]\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "validation = pd.DataFrame(validation)\n",
    "test = pd.DataFrame(test)\n",
    "\n",
    "print(f\"len(train): {len(train)}, len(validation): {len(validation)}, len(test): {len(test)}\")\n",
    "\n",
    "def clean_defacto(row):\n",
    "    article = row['article']\n",
    "    candidate = row['candidate']\n",
    "    has_error = row['has_error']\n",
    "    feedback = row['feedback']\n",
    "    \n",
    "    if has_error:\n",
    "        label = \"c\"\n",
    "        correct = feedback['summary']\n",
    "    else:\n",
    "        label = \"e\"\n",
    "        correct = \"\"\n",
    "    \n",
    "    row['L'] = label\n",
    "    row['D'] = \"DeFacto\"\n",
    "    row['correct'] = correct\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "# Train set preprocessing\n",
    "train = train.apply(clean_defacto, axis=1)\n",
    "\n",
    "corrected_train = train[train['correct'] != \"\"]\n",
    "uncorrected_train = train[train['correct'] == \"\"]\n",
    "\n",
    "corrected_train_entailment = corrected_train.rename(columns = {'article':'P','correct':'H'})[['P','H','L','D']]\n",
    "corrected_train_entailment['L'] = \"e\"\n",
    "corrected_train_contradiction = corrected_train.rename(columns = {'article':'P','candidate':'H'})[['P','H','L','D']]\n",
    "corrected_train_contradiction['L'] = \"c\"\n",
    "\n",
    "corrected_train_contradiction_upsampled = corrected_train_contradiction.sample(300, random_state=seed)\n",
    "\n",
    "uncorrected_train = uncorrected_train.rename(columns = {'article':'P','candidate':'H'})[['P','H','L','D']]\n",
    "uncorrected_train['L'] = \"e\"\n",
    "\n",
    "# Validation set preprocessing\n",
    "validation = validation.apply(clean_defacto, axis=1)\n",
    "\n",
    "corrected_validation = validation[validation['correct'] != \"\"]\n",
    "uncorrected_validation = validation[validation['correct'] == \"\"]\n",
    "\n",
    "corrected_validation_entailment = corrected_validation.rename(columns = {'article':'P','correct':'H'})[['P','H','L','D']]\n",
    "corrected_validation_entailment['L'] = \"e\"\n",
    "corrected_validation_contradiction = corrected_validation.rename(columns = {'article':'P','candidate':'H'})[['P','H','L','D']]\n",
    "corrected_validation_contradiction['L'] = \"c\"\n",
    "\n",
    "uncorrected_validation = uncorrected_validation.rename(columns = {'article':'P','candidate':'H'})[['P','H','L','D']]\n",
    "uncorrected_validation['L'] = \"e\"\n",
    "\n",
    "# Test set preprocessing\n",
    "test = test.apply(clean_defacto, axis=1)\n",
    "\n",
    "corrected_test = test[test['correct'] != \"\"]\n",
    "uncorrected_test = test[test['correct'] == \"\"]\n",
    "corrected_test_entailment = corrected_test.rename(columns = {'article':'P','correct':'H'})[['P','H','L','D']]\n",
    "corrected_test_entailment['L'] = \"e\"\n",
    "corrected_test_contradiction = corrected_test.rename(columns = {'article':'P','candidate':'H'})[['P','H','L','D']]\n",
    "corrected_test_contradiction['L'] = \"c\"\n",
    "\n",
    "uncorrected_test = uncorrected_test.rename(columns = {'article':'P','candidate':'H'})[['P','H','L','D']]\n",
    "uncorrected_test['L'] = \"e\"\n",
    "\n",
    "train = pd.concat([corrected_train_entailment, corrected_train_contradiction, uncorrected_train, corrected_train_contradiction_upsampled], ignore_index=True)\n",
    "validation = pd.concat([corrected_validation_entailment, corrected_validation_contradiction, uncorrected_validation], ignore_index=True)\n",
    "test = pd.concat([corrected_test_entailment, corrected_test_contradiction, uncorrected_test], ignore_index=True)\n",
    "\n",
    "print(f\"len(train): {len(train)}, len(validation): {len(validation)}, len(test): {len(test)}\")\n",
    "\n",
    "append_to_global(train, validation, test)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 8665, len(test): 766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "c    4693\n",
       "e    4672\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DADC-NLI\n",
    "\n",
    "train = pandas.read_json(\"https://raw.githubusercontent.com/facebookresearch/dadc-limit/main/data/dynamic-adversarial-with-rounds.jsonl\", lines=True)\n",
    "test = pandas.read_json(\"https://raw.githubusercontent.com/facebookresearch/dadc-limit/main/data/expert-test-set.jsonl\", lines=True)\n",
    "\n",
    "print(f\"len(train): {len(train)}, len(test): {len(test)}\")\n",
    "\n",
    "train = pd.DataFrame(train)[['sentence1', 'sentence2', 'label']]\n",
    "test = pd.DataFrame(test)[['sentence1', 'sentence2', 'label']]\n",
    "\n",
    "#Rename\n",
    "train = train.rename(columns = {'sentence1':'P','sentence2':'H','label':'L'})\n",
    "test = test.rename(columns = {'sentence1':'P','sentence2':'H','label':'L'})\n",
    "\n",
    "train['L'] = train['L'].astype(str).replace({'entailment': 'e', 'contradiction': 'c'})\n",
    "test['L'] = test['L'].astype(str).replace({'entailment': 'e', 'contradiction': 'c'})\n",
    "\n",
    "train_upsampled = train[train['L'] == \"e\"].sample(700, random_state=seed)\n",
    "train = pd.concat([train, train_upsampled], ignore_index=True)\n",
    "train['D'] = \"DADC-NLI\"\n",
    "test['D'] = \"DADC-NLI\"\n",
    "\n",
    "append_to_global(train, None, test)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 10419, len(validation): 1169, len(test): 1380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "c    5293\n",
       "e    5276\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FoolMeTwice\n",
    "\n",
    "train = pandas.read_json(\"https://raw.githubusercontent.com/google-research/fool-me-twice/main/dataset/train.jsonl\", lines=True)\n",
    "train = pd.DataFrame(train)\n",
    "\n",
    "validation = pandas.read_json(\"https://raw.githubusercontent.com/google-research/fool-me-twice/main/dataset/dev.jsonl\", lines=True)\n",
    "validation = pd.DataFrame(validation)\n",
    "\n",
    "test = pandas.read_json(\"https://raw.githubusercontent.com/google-research/fool-me-twice/main/dataset/test.jsonl\", lines=True)\n",
    "test = pd.DataFrame(test)\n",
    "\n",
    "\n",
    "print(f\"len(train): {len(train)}, len(validation): {len(validation)}, len(test): {len(test)}\")\n",
    "\n",
    "def process_foolmetwice(row):\n",
    "    page = row['wikipedia_page']\n",
    "    text = row['text']\n",
    "    gold_evidence = row['gold_evidence']\n",
    "    \n",
    "    joined_evidence = f\"Page Name: {page}\\n\\n\"\n",
    "    for evidence in gold_evidence:\n",
    "        section_header = evidence['section_header']\n",
    "        joined_evidence += section_header + \": \"\n",
    "        joined_evidence += evidence['text'] + \"\\n\"\n",
    "    \n",
    "    joined_evidence = joined_evidence.strip(\"\\n\")\n",
    "\n",
    "    row['P'] = joined_evidence\n",
    "    row['H'] = text\n",
    "    row['L'] = row['label']\n",
    "    row['D'] = \"FoolMeTwice\"\n",
    "    \n",
    "    return row\n",
    "\n",
    "train = train.apply(process_foolmetwice, axis=1)[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "train['L'] = train['L'].astype(str).replace({'SUPPORTS': 'e', 'REFUTES': 'c'})\n",
    "train_upsampled = train[train['L'] == \"e\"].sample(150, random_state=seed)\n",
    "train = pd.concat([train, train_upsampled], ignore_index=True)\n",
    "\n",
    "validation = validation.apply(process_foolmetwice, axis=1)[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "validation['L'] = validation['L'].astype(str).replace({'SUPPORTS': 'e', 'REFUTES': 'c'})\n",
    "\n",
    "test = test.apply(process_foolmetwice, axis=1)[[\"P\",\"H\",\"L\",\"D\"]]\n",
    "test['L'] = test['L'].astype(str).replace({'SUPPORTS': 'e', 'REFUTES': 'c'})\n",
    "\n",
    "append_to_global(train, validation, test)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CORE Dataset\n",
    "\n",
    "# train = pandas.read_csv(\"https://raw.githubusercontent.com/Sai90000/ScientificHypothesisEvidencing/main/data/train_mapped.csv\")[['abstract_collected', 'declarative', 'label']]\n",
    "# validation = pandas.read_csv(\"https://raw.githubusercontent.com/Sai90000/ScientificHypothesisEvidencing/main/data/held_out_mapped.csv\")[['abstract_collected', 'declarative', 'label']]\n",
    "# test = pandas.read_csv(\"https://raw.githubusercontent.com/Sai90000/ScientificHypothesisEvidencing/main/data/test_mapped.csv\")[['abstract_collected', 'declarative', 'label']]\n",
    "\n",
    "# print(f\"len(train): {len(train)}, len(validation): {len(validation)}, len(test): {len(test)}\")\n",
    "\n",
    "# train = pd.DataFrame(train)\n",
    "# train['declarative'] = train['declarative'].apply(lambda x: str.lower(x))\n",
    "# train = train.rename(columns = {'abstract_collected':'P','declarative':'H','label':'L'})\n",
    "# train['L'] = train['L'].astype(str).replace({'ENTAIL': 'e', 'CONTRADICT': 'c', 'INCONCLUSIVE': 'n'})\n",
    "# train['D'] = \"CORE\"\n",
    "\n",
    "# validation = pd.DataFrame(validation)\n",
    "# validation['declarative'] = validation['declarative'].apply(lambda x: str.lower(x))\n",
    "# validation = validation.rename(columns = {'abstract_collected':'P','declarative':'H','label':'L'})\n",
    "# validation['L'] = validation['L'].astype(str).replace({'ENTAIL': 'e', 'CONTRADICT': 'c', 'INCONCLUSIVE': 'n'})\n",
    "# validation['D'] = \"CORE\"\n",
    "\n",
    "# test = pd.DataFrame(test)\n",
    "# test['declarative'] = test['declarative'].apply(lambda x: str.lower(x))\n",
    "# test = test.rename(columns = {'abstract_collected':'P','declarative':'H','label':'L'})\n",
    "# test['L'] = test['L'].astype(str).replace({'ENTAIL': 'e', 'CONTRADICT': 'c', 'INCONCLUSIVE': 'n'})\n",
    "# test['D'] = \"CORE\"\n",
    "\n",
    "# append_to_global(train, validation, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CoVERT Dataset: https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/bioclaim/\n",
    "\n",
    "# train = pandas.read_json(\"../data/covert/CoVERT_FC_annotations.jsonl\", lines=True)\n",
    "# train = pd.DataFrame(train)\n",
    "\n",
    "\n",
    "# def get_covert(row):\n",
    "#     claim = row['claim']\n",
    "#     evidences = row['evidence']\n",
    "#     pairs = []\n",
    "#     for evidence in evidences:\n",
    "#         if evidence[1]:\n",
    "#             x = (claim, evidence[2], evidence[0])\n",
    "#             # print(x)\n",
    "#             pairs.append(x)\n",
    "\n",
    "#     row['pairs'] = pairs\n",
    "            \n",
    "#     return row\n",
    "\n",
    "\n",
    "# train = train.apply(get_covert, axis=1)\n",
    "# pairs = train['pairs'].to_list()\n",
    "\n",
    "# import re\n",
    "# url_regex = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "\n",
    "# def clean_covert_text(text):\n",
    "#     text = fix_text(text)\n",
    "#     text = text.replace(\"@username\", \" \")\n",
    "#     text = text.replace(\"[NEWLINE]\", \"\\n\")\n",
    "#     text = re.sub(url_regex, '', text)\n",
    "#     text = text.replace(\"Source:\", \" \")\n",
    "#     return \" \".join(text.split())\n",
    "\n",
    "# clean_pairs = []\n",
    "# for pair in pairs:\n",
    "#     for p in pair:\n",
    "#         claim = clean_covert_text(p[0])\n",
    "#         evidence = p[1]\n",
    "#         label = p[2]\n",
    "#         clean_pairs.append((evidence, claim, label))\n",
    "        \n",
    "\n",
    "# train = pd.DataFrame(clean_pairs, columns=['P', 'H', 'L'])\n",
    "# train[\"L\"] = train[\"L\"].replace({\"SUPPORTS\": \"e\", \"REFUTES\": \"c\", \"NOT ENOUGH INFO\": \"n\"})\n",
    "# train['D'] = \"CoVERT\"\n",
    "# print(f\"len(train): {len(train)}\")\n",
    "# print(train['L'].value_counts())\n",
    "\n",
    "# train = train.dropna()\n",
    "\n",
    "# append_to_global(train, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 1600, len(validation): 349, len(test): 358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    800\n",
       "n    633\n",
       "c    167\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WiCE\n",
    "\n",
    "train = pandas.read_json(\"https://raw.githubusercontent.com/ryokamoi/wice/main/data/entailment_retrieval/claim/train.jsonl\",\n",
    "                         lines=True)\n",
    "\n",
    "validation = pandas.read_json(\"https://raw.githubusercontent.com/ryokamoi/wice/main/data/entailment_retrieval/claim/dev.jsonl\",\n",
    "                            lines=True)\n",
    "\n",
    "test = pandas.read_json(\"https://raw.githubusercontent.com/ryokamoi/wice/main/data/entailment_retrieval/claim/test.jsonl\",\n",
    "                            lines=True)\n",
    "\n",
    "train = pd.DataFrame(train)\n",
    "validation = pd.DataFrame(validation)\n",
    "test = pd.DataFrame(test)\n",
    "\n",
    "\n",
    "def clean_wice(row):\n",
    "    label = row['label']\n",
    "    supporting_sentences = row['supporting_sentences']\n",
    "    claim = row['claim']\n",
    "    evidence = row['evidence']\n",
    "    claim_title = row['meta']['claim_title']\n",
    "    claim_section = row['meta']['claim_section']\n",
    "    \n",
    "    claim_meta = \"\"\n",
    "    if claim_title:\n",
    "        claim_meta = claim_meta + \" \" + claim_title\n",
    "    if claim_section:\n",
    "        claim_meta = claim_meta + \" \" + claim_section\n",
    "    if claim_meta:\n",
    "        claim = claim_meta + \"\\n\" + claim\n",
    "    \n",
    "    all_supporting_sentences = []\n",
    "    if \"(meta data) TITLE:\" in evidence[0]:\n",
    "        evidence[0] = evidence[0].replace(\"(meta data) TITLE:\", \" \") + \"\\n\"\n",
    "        all_supporting_sentences.extend([0])\n",
    "    for supporting_sentence in supporting_sentences:\n",
    "        all_supporting_sentences.extend(supporting_sentence)\n",
    "    all_supporting_sentences = list(set(all_supporting_sentences))\n",
    "    all_supporting_sentences.sort()\n",
    "    all_supporting_sentences = [evidence[sent] for sent in all_supporting_sentences]\n",
    "    all_supporting_sentences = \" \".join(all_supporting_sentences).strip()\n",
    "\n",
    "    row['final_evidence'] = fix_text(all_supporting_sentences.strip())\n",
    "    row['claim'] = fix_text(claim.strip())\n",
    "    \n",
    "    return row\n",
    "\n",
    "train = train.apply(clean_wice, axis=1)[['final_evidence', 'claim', 'label']]\n",
    "validation = validation.apply(clean_wice, axis=1)[['final_evidence', 'claim', 'label']]\n",
    "test = test.apply(clean_wice, axis=1)[['final_evidence', 'claim', 'label']]\n",
    "\n",
    "train = train.rename(columns = {'final_evidence':'P','claim':'H','label':'L'})\n",
    "validation = validation.rename(columns = {'final_evidence':'P','claim':'H','label':'L'})\n",
    "test = test.rename(columns = {'final_evidence':'P','claim':'H','label':'L'})\n",
    "\n",
    "train[\"D\"] = \"WiCE\"\n",
    "validation[\"D\"] = \"WiCE\"\n",
    "test[\"D\"] = \"WiCE\"\n",
    "\n",
    "train['L'] = train['L'].astype(str).replace({'supported': 'e', 'not_supported': 'c', \"partially_supported\": \"n\"})\n",
    "validation['L'] = validation['L'].astype(str).replace({'supported': 'e', 'not_supported': 'c', \"partially_supported\": \"n\"})\n",
    "test['L'] = test['L'].astype(str).replace({'supported': 'e', 'not_supported': 'c', \"partially_supported\": \"n\"})\n",
    "\n",
    "train_upsampled = train[train['L'] == \"e\"].sample(340, random_state=seed)\n",
    "train = pd.concat([train, train_upsampled], ignore_index=True)\n",
    "\n",
    "print(f\"len(train): {len(train)}, len(validation): {len(validation)}, len(test): {len(test)}\")\n",
    "\n",
    "append_to_global(train, validation, test)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Seahorse data...\n",
      "Formatting text...\n",
      "len(train): 31666, len(validation): 2074, len(test): 4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    15838\n",
       "c    15828\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seahorse\n",
    "\n",
    "folder_path = \"../data/seahorse_data/\"\n",
    "\n",
    "print('Preparing Seahorse data...')\n",
    "train = pandas.read_json(folder_path + 'seahorse-train.jsonl', lines=True)\n",
    "validation = pandas.read_json(folder_path + 'seahorse-validation.jsonl', lines=True)\n",
    "test = pandas.read_json(folder_path + 'seahorse-test.jsonl', lines=True)\n",
    "\n",
    "print('Formatting text...')\n",
    "# train = train.apply(format_text, axis=1)[['text']]\n",
    "# validation = validation.apply(format_text, axis=1)[['text']]\n",
    "train = train.rename(columns = {'source':'P','target':'H','label':'L'})\n",
    "validation = validation.rename(columns = {'source':'P','target':'H','label':'L'})\n",
    "test = test.rename(columns = {'source':'P','target':'H','label':'L'})\n",
    "\n",
    "train['L'] = train['L'].astype(str).replace({'Yes': 'e', 'No': 'c'})\n",
    "validation['L'] = validation['L'].astype(str).replace({'Yes': 'e', 'No': 'c'})\n",
    "test['L'] = test['L'].astype(str).replace({'Yes': 'e', 'No': 'c'})\n",
    "\n",
    "train['D'] = \"Seahorse\"\n",
    "validation['D'] = \"Seahorse\"\n",
    "test['D'] = \"Seahorse\"\n",
    "\n",
    "train_upsampled = train[train['L'] == \"c\"].sample(1780, random_state=seed)\n",
    "train = pd.concat([train, train_upsampled], ignore_index=True)\n",
    "\n",
    "# Double the number of examples in the training set \n",
    "train = pd.concat([train, train], ignore_index=True)\n",
    "\n",
    "\n",
    "print(f\"len(train): {len(train)}, len(validation): {len(validation)}, len(test): {len(test)}\")\n",
    "\n",
    "append_to_global(train, validation, test)\n",
    "\n",
    "train.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Distributing <class 'list'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    5873\n",
       "c    5852\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoolQ\n",
    "\n",
    "boolq = pd.read_csv(\"boolq_positives.csv\", sep=\",\")\n",
    "boolq_dict = boolq.set_index('input').T.to_dict()\n",
    "boolq_ds = load_dataset(\"boolq\")\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for example in boolq_ds['train']:\n",
    "    input_ = example['question']\n",
    "    try:\n",
    "        output = boolq_dict[input_]['output']\n",
    "        passage = example['passage']\n",
    "        label = example['answer']\n",
    "        rows.append((passage, output, label))\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    \n",
    "\n",
    "boolq_df = pd.DataFrame(rows, columns=['P', 'H', 'L'])\n",
    "boolq_df['D'] = \"boolq\"\n",
    "boolq_df['L'] = boolq_df['L'].astype(str).replace({'True': 'e', 'False': 'c'})\n",
    "\n",
    "boolq_df_upsampled = boolq_df[boolq_df['L'] == \"c\"].sample(2300, random_state=seed)\n",
    "boolq_df = pd.concat([boolq_df, boolq_df_upsampled], ignore_index=True)\n",
    "\n",
    "append_to_global(boolq_df, None, None)\n",
    "\n",
    "boolq_df.value_counts('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347804, 12618, 18815)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_train = all_train.drop_duplicates(subset=['P','H'], keep=\"first\")\n",
    "all_val = all_val.drop_duplicates(subset=['P','H'], keep=\"first\")\n",
    "all_test = all_test.drop_duplicates(subset=['P','H'], keep=\"first\")\n",
    "\n",
    "len(all_train), len(all_val), len(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def get_length(row):\n",
    "    global count\n",
    "    text_a = row['P']\n",
    "    text_b = row['H']\n",
    "    text_a = len(text_a.split())\n",
    "    text_b = len(text_b.split())\n",
    "    \n",
    "    row['len(P)'] = text_a\n",
    "    row['len(H)'] = text_b\n",
    "    \n",
    "    if not count % 1000:\n",
    "        print(count)\n",
    "    count+=1\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_text\n",
    "\n",
    "def fix_all(row):\n",
    "    row['P'] = fix_text(row['P'])\n",
    "    row['H'] = fix_text(row['H'])\n",
    "    return row\n",
    "\n",
    "all_train = all_train.apply(fix_all, axis=1)\n",
    "all_val = all_val.apply(fix_all, axis=1)\n",
    "all_test = all_test.apply(fix_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_deploy_ray_func pid=17468)\u001b[0m 0\n",
      "\u001b[36m(_deploy_ray_func pid=17468)\u001b[0m 8000\u001b[32m [repeated 65x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17465)\u001b[0m 16000\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17470)\u001b[0m 24000\u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17470)\u001b[0m 32000\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17472)\u001b[0m 39000\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17471)\u001b[0m 47000\u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17466)\u001b[0m 56000\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(_deploy_ray_func pid=17470)\u001b[0m 0\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "all_train = all_train.apply(get_length, axis=1)\n",
    "all_val = all_val.apply(get_length, axis=1)\n",
    "all_test = all_test.apply(get_length, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D\n",
       "alisawuffles/WANLI    127885\n",
       "anli                  105076\n",
       "Seahorse               31666\n",
       "LingNLI                19994\n",
       "scitail                16944\n",
       "boolq                  11725\n",
       "FoolMeTwice            10569\n",
       "vitaminc                8489\n",
       "glue_rte                2490\n",
       "DeFacto                 2001\n",
       "WiCE                    1600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.D.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L\n",
       "e    173006\n",
       "c     97303\n",
       "n     77495\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.L.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train.rename(columns = {'P':'source','H':'target','L':'label','D':'subset'})\n",
    "all_val = all_val.rename(columns = {'P':'source','H':'target','L':'label','D':'subset'})\n",
    "all_test = all_test.rename(columns = {'P':'source','H':'target','L':'label','D':'subset'})\n",
    "\n",
    "all_train['label'] = all_train['label'].astype(str).replace({'e': 'Yes', 'c': 'No', 'n': 'No'})\n",
    "all_val['label'] = all_val['label'].astype(str).replace({'e': 'Yes', 'c': 'No', 'n': 'No'})\n",
    "all_test['label'] = all_test['label'].astype(str).replace({'e': 'Yes', 'c': 'No', 'n': 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28404444"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train['len(P)'].sum() + all_train['len(H)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " No     174798\n",
       " Yes    173006\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " No     6992\n",
       " Yes    5626\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " No     10601\n",
       " Yes     8214\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.label.value_counts(), all_val.label.value_counts(), all_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.to_json` is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "Please refer to https://modin.readthedocs.io/en/stable/supported_apis/defaulting_to_pandas.html for explanation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: `DataFrame.to_json` is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n",
      "UserWarning: `DataFrame.to_json` is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.frame.DataFrame'> object. This may take some time.\n"
     ]
    }
   ],
   "source": [
    "out_columns = ['source', 'target', 'label', 'subset']\n",
    "\n",
    "all_train[out_columns].to_json(\"../data/combined-train.jsonl\", lines=True, orient=\"records\")\n",
    "all_val[out_columns].to_json(\"../data/combined-validation.jsonl\", lines=True, orient=\"records\")\n",
    "all_test[out_columns].to_json(\"../data/combined-test.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "alisawuffles/WANLI    127885\n",
       "anli                  105076\n",
       "Seahorse               31666\n",
       "LingNLI                19994\n",
       "scitail                16944\n",
       "boolq                  11725\n",
       "FoolMeTwice            10569\n",
       "vitaminc                8489\n",
       "glue_rte                2490\n",
       "DeFacto                 2001\n",
       "WiCE                    1600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_train = pandas.read_json(\"../data/combined-train.jsonl\", lines=True)\n",
    "\n",
    "all_train.subset.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "      <th>len(P)</th>\n",
       "      <th>len(H)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173289</th>\n",
       "      <td>You must be crazy to be trying to go up against the Bisons.</td>\n",
       "      <td>The Bisons are not good.</td>\n",
       "      <td>No</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124093</th>\n",
       "      <td>The wily fox, after escaping from the lion's den, took refuge in a tree.</td>\n",
       "      <td>The fox hid in the tree after he was captured.</td>\n",
       "      <td>No</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134258</th>\n",
       "      <td>In the early part of the nineteenth century, the Irish, or \"Famine Irish\" as they were called, emigrated in large numbers to the United States.</td>\n",
       "      <td>The Irish were the only people who emigrated to the United States.</td>\n",
       "      <td>No</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179366</th>\n",
       "      <td>I've never seen any good movies.</td>\n",
       "      <td>Some movies are good.</td>\n",
       "      <td>No</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201325</th>\n",
       "      <td>If you think that being a newspaper reporter is hard, try being a newspaper reporter and a football player.</td>\n",
       "      <td>Football players are a lot of fun, but reporters are a lot of work.</td>\n",
       "      <td>No</td>\n",
       "      <td>alisawuffles/WANLI</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 source  \\\n",
       "173289                                                                                      You must be crazy to be trying to go up against the Bisons.   \n",
       "124093                                                                         The wily fox, after escaping from the lion's den, took refuge in a tree.   \n",
       "134258  In the early part of the nineteenth century, the Irish, or \"Famine Irish\" as they were called, emigrated in large numbers to the United States.   \n",
       "179366                                                                                                                 I've never seen any good movies.   \n",
       "201325                                      If you think that being a newspaper reporter is hard, try being a newspaper reporter and a football player.   \n",
       "\n",
       "                                                                     target  \\\n",
       "173289                                             The Bisons are not good.   \n",
       "124093                       The fox hid in the tree after he was captured.   \n",
       "134258   The Irish were the only people who emigrated to the United States.   \n",
       "179366                                                Some movies are good.   \n",
       "201325  Football players are a lot of fun, but reporters are a lot of work.   \n",
       "\n",
       "       label              subset  len(P)  len(H)  \n",
       "173289    No  alisawuffles/WANLI      13       5  \n",
       "124093    No  alisawuffles/WANLI      14      10  \n",
       "134258    No  alisawuffles/WANLI      25      12  \n",
       "179366    No  alisawuffles/WANLI       6       4  \n",
       "201325    No  alisawuffles/WANLI      19      14  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 2000\n",
    "\n",
    "all_train[all_train.subset ==\"alisawuffles/WANLI\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_train[all_train['len(P)'] > 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "DeFacto                 579057\n",
       "FoolMeTwice             410330\n",
       "LingNLI                 388897\n",
       "Seahorse              11763554\n",
       "WiCE                    123158\n",
       "alisawuffles/WANLI     2240403\n",
       "anli                   5720300\n",
       "boolq                  1092152\n",
       "glue_rte                108478\n",
       "scitail                 301743\n",
       "vitaminc                541884\n",
       "Name: len(P), dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print total len(P) and len(H) for each dataset\n",
    "\n",
    "all_train.groupby('subset')['len(P)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347804, 12618, 18815)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train), len(all_val), len(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `Series.groupby_on_multiple_columns` is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DeFacto</th>\n",
       "      <th>No</th>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FoolMeTwice</th>\n",
       "      <th>No</th>\n",
       "      <td>5293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LingNLI</th>\n",
       "      <th>Yes</th>\n",
       "      <td>9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seahorse</th>\n",
       "      <th>Yes</th>\n",
       "      <td>15838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>15828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WiCE</th>\n",
       "      <th>Yes</th>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">alisawuffles/WANLI</th>\n",
       "      <th>No</th>\n",
       "      <td>64374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>63511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">anli</th>\n",
       "      <th>No</th>\n",
       "      <td>52965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>52111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">boolq</th>\n",
       "      <th>Yes</th>\n",
       "      <td>5873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>5852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">glue_rte</th>\n",
       "      <th>Yes</th>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">scitail</th>\n",
       "      <th>Yes</th>\n",
       "      <td>8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vitaminc</th>\n",
       "      <th>No</th>\n",
       "      <td>4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>4206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count\n",
       "subset             label       \n",
       "DeFacto            No      1001\n",
       "                   Yes     1000\n",
       "FoolMeTwice        No      5293\n",
       "                   Yes     5276\n",
       "LingNLI            Yes     9998\n",
       "                   No      9996\n",
       "Seahorse           Yes    15838\n",
       "                   No     15828\n",
       "WiCE               Yes      800\n",
       "                   No       800\n",
       "alisawuffles/WANLI No     64374\n",
       "                   Yes    63511\n",
       "anli               No     52965\n",
       "                   Yes    52111\n",
       "boolq              Yes     5873\n",
       "                   No      5852\n",
       "glue_rte           Yes     1249\n",
       "                   No      1241\n",
       "scitail            Yes     8472\n",
       "                   No      8472\n",
       "vitaminc           No      4283\n",
       "                   Yes     4206"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_train.groupby('subset').label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `Series.groupby_on_multiple_columns` is not currently supported by PandasOnRay, defaulting to pandas implementation.\n",
      "UserWarning: Distributing <class 'pandas.core.series.Series'> object. This may take some time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subset</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DeFacto</th>\n",
       "      <th>Yes</th>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FoolMeTwice</th>\n",
       "      <th>Yes</th>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LingNLI</th>\n",
       "      <th>No</th>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Seahorse</th>\n",
       "      <th>Yes</th>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WiCE</th>\n",
       "      <th>No</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">anli</th>\n",
       "      <th>No</th>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">glue_rte</th>\n",
       "      <th>Yes</th>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">scitail</th>\n",
       "      <th>Yes</th>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vitaminc</th>\n",
       "      <th>Yes</th>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "subset      label       \n",
       "DeFacto     Yes      486\n",
       "            No       337\n",
       "FoolMeTwice Yes      596\n",
       "            No       573\n",
       "LingNLI     No      1546\n",
       "            Yes      876\n",
       "Seahorse    Yes     1178\n",
       "            No       896\n",
       "WiCE        No       234\n",
       "            Yes      115\n",
       "anli        No      2130\n",
       "            Yes     1070\n",
       "glue_rte    Yes      146\n",
       "            No       131\n",
       "scitail     Yes      657\n",
       "            No       647\n",
       "vitaminc    Yes      502\n",
       "            No       498"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_val.groupby('subset').label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "alisawuffles/WANLI     17.518888\n",
       "scitail                17.808251\n",
       "LingNLI                19.450685\n",
       "FoolMeTwice            38.823919\n",
       "glue_rte               43.565462\n",
       "anli                   54.439644\n",
       "vitaminc               63.833667\n",
       "WiCE                   76.973750\n",
       "boolq                  93.147292\n",
       "DeFacto               289.383808\n",
       "Seahorse              371.488473\n",
       "Name: len(P), dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average token length of P and H for each subset\n",
    "\n",
    "all_train.groupby('subset')['len(P)'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "boolq                  8.557783\n",
       "glue_rte               8.790361\n",
       "anli                   9.670572\n",
       "alisawuffles/WANLI     9.850663\n",
       "LingNLI               10.074322\n",
       "scitail               11.687559\n",
       "FoolMeTwice           13.685685\n",
       "DeFacto               16.770115\n",
       "vitaminc              19.551184\n",
       "Seahorse              22.963431\n",
       "WiCE                  27.805000\n",
       "Name: len(H), dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.groupby('subset')['len(H)'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "scitail                16.849953\n",
       "alisawuffles/WANLI     17.483800\n",
       "FoolMeTwice            39.286439\n",
       "anli                   54.415625\n",
       "WiCE                   88.329609\n",
       "DeFacto               309.589286\n",
       "Seahorse              383.268004\n",
       "Name: len(P), dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test.groupby('subset')['len(P)'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "scitail         17.312883\n",
       "LingNLI         19.819571\n",
       "vitaminc        33.559000\n",
       "FoolMeTwice     40.073567\n",
       "glue_rte        42.386282\n",
       "anli            54.464062\n",
       "WiCE            90.879656\n",
       "DeFacto        305.572296\n",
       "Seahorse       369.850048\n",
       "Name: len(P), dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_val.groupby('subset')['len(P)'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347804, 12618, 18815)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "len(all_train), len(all_val), len(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
