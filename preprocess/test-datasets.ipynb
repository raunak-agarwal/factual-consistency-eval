{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggreFact\t\t     HaluEval\n",
      "benchmark_llm_summarization  llm_aggrefact.json\n",
      "benchmark_test_data.json     llm_aggrefact_partial.json\n",
      "BUMP\t\t\t     test.json\n",
      "dadc-nli-test.jsonl\t     tofueval\n",
      "DiaSumFact\t\t     trueteacher_unique_sampled.json\n",
      "GUMSum4EVAL\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/test-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/test-data/benchmark_llm_summarization/likert_evaluation_results.json',\n",
       " '../data/test-data/BUMP/task1_dataset.json',\n",
       " '../data/test-data/GUMSum4EVAL/data',\n",
       " '../data/test-data/HaluEval/summarization_data.json',\n",
       " '../data/test-data/DiaSumFact/annotations.json',\n",
       " '../data/test-data/tofueval/mediasum_dev_doc.csv',\n",
       " '../data/test-data/tofueval/meetingbank_dev_doc.csv',\n",
       " '../data/test-data/tofueval/mediasum_test_doc.csv',\n",
       " '../data/test-data/tofueval/news_dialogue.json',\n",
       " '../data/test-data/tofueval/meetingbank_test_doc.csv',\n",
       " '../data/test-data/tofueval/document_ids_dev_test_split.json',\n",
       " '../data/test-data/tofueval/news_dialogue.zip',\n",
       " '../data/test-data/AggreFact/aggre_fact_sota.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "glob.glob('../data/test-data/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_dfs = pd.DataFrame()\n",
    "\n",
    "\n",
    "def append_df(df):\n",
    "    global all_test_dfs\n",
    "    all_test_dfs = pd.concat([all_test_dfs, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>origin</th>\n",
       "      <th>id</th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>model_name</th>\n",
       "      <th>label</th>\n",
       "      <th>cut</th>\n",
       "      <th>DAE_score</th>\n",
       "      <th>DAE_label</th>\n",
       "      <th>QuestEval_score</th>\n",
       "      <th>QuestEval_label</th>\n",
       "      <th>SummaC-ZS_score</th>\n",
       "      <th>SummaC-ZS_label</th>\n",
       "      <th>SummaC-Conv_score</th>\n",
       "      <th>SummaC-Conv_label</th>\n",
       "      <th>QAFactEval_score</th>\n",
       "      <th>QAFactEval_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polytope</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>b383-10</td>\n",
       "      <td>looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring...</td>\n",
       "      <td>lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day ....</td>\n",
       "      <td>BART</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>0.912608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.966453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.856083</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polytope</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>b364-10</td>\n",
       "      <td>tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential ...</td>\n",
       "      <td>a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalen...</td>\n",
       "      <td>BART</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "      <td>0.780049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.518639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.887718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.721094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset origin       id  \\\n",
       "0  Polytope  cnndm  b383-10   \n",
       "1  Polytope  cnndm  b364-10   \n",
       "\n",
       "                                                                                                   doc  \\\n",
       "0  looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring...   \n",
       "1  tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential ...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day ....   \n",
       "1  a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalen...   \n",
       "\n",
       "  model_name  label  cut  DAE_score  DAE_label  QuestEval_score  \\\n",
       "0       BART      1  val   0.912608        NaN         0.556987   \n",
       "1       BART      1  val   0.780049        NaN         0.518639   \n",
       "\n",
       "   QuestEval_label  SummaC-ZS_score  SummaC-ZS_label  SummaC-Conv_score  \\\n",
       "0              NaN         0.827759              NaN           0.966453   \n",
       "1              NaN         0.887718              NaN           0.848480   \n",
       "\n",
       "   SummaC-Conv_label  QAFactEval_score  QAFactEval_label  \n",
       "0                NaN          4.856083               NaN  \n",
       "1                NaN          4.721094               NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AggreFact\n",
    "\n",
    "\n",
    "aggrefact = pd.read_csv(\"https://raw.githubusercontent.com/Liyan06/AggreFact/main/data/aggre_fact_sota.csv\")\n",
    "aggrefact.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggrefact = aggrefact[['doc','summary','label', 'origin']]\n",
    "\n",
    "aggrefact = aggrefact.rename(columns={'origin':'source'})\n",
    "aggrefact['benchmark'] = 'aggrefact'\n",
    "\n",
    "append_df(aggrefact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_type\n",
      "Extrinsic Circumstance Error    99\n",
      "Extrinsic Entity Error          99\n",
      "Intrinsic Circumstance Error    99\n",
      "Intrinsic Entity Error          99\n",
      "Extrinsic Predicate Error       99\n",
      "Intrinsic Predicate Error       99\n",
      "Coreference Error               99\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article</th>\n",
       "      <th>reference_summary</th>\n",
       "      <th>edited_summary</th>\n",
       "      <th>error_type</th>\n",
       "      <th>corrected_error_type</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>636</td>\n",
       "      <td>1337</td>\n",
       "      <td>Wigan climbed up to third place in the First Utility Super League after exacting sweet revenge o...</td>\n",
       "      <td>Wigan exact revenge on St Helens in Super League Grand-Final rematch . Warriors come out on top ...</td>\n",
       "      <td>Wigan exact revenge on Warriors in Super League Grand-Final rematch . Warriors come out on top i...</td>\n",
       "      <td>Intrinsic Circumstance Error</td>\n",
       "      <td>Intrinsic Entity Error</td>\n",
       "      <td>{'QAFactEval_edited': 0.42573932670000003, 'CoCo_edited': 0.35365559999999996, 'DAE_edited': 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>1587</td>\n",
       "      <td>A Chinese villager who was desperate to become a grandfather has been arrested for buying a wife...</td>\n",
       "      <td>The man, known only as Xu, was keen to have a grandchild . He bought the 'daughter-in-law' for £...</td>\n",
       "      <td>The man, known only as Xu, was keen to have a grandchild . He left the 'daughter-in-law' for £1,...</td>\n",
       "      <td>Extrinsic Predicate Error</td>\n",
       "      <td>Extrinsic Predicate Error</td>\n",
       "      <td>{'QAFactEval_edited': 0.6213724862000001, 'CoCo_edited': 0.39436847, 'DAE_edited': 0.6608075, 'F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  article_id  \\\n",
       "636  636        1337   \n",
       "78    78        1587   \n",
       "\n",
       "                                                                                                 article  \\\n",
       "636  Wigan climbed up to third place in the First Utility Super League after exacting sweet revenge o...   \n",
       "78   A Chinese villager who was desperate to become a grandfather has been arrested for buying a wife...   \n",
       "\n",
       "                                                                                       reference_summary  \\\n",
       "636  Wigan exact revenge on St Helens in Super League Grand-Final rematch . Warriors come out on top ...   \n",
       "78   The man, known only as Xu, was keen to have a grandchild . He bought the 'daughter-in-law' for £...   \n",
       "\n",
       "                                                                                          edited_summary  \\\n",
       "636  Wigan exact revenge on Warriors in Super League Grand-Final rematch . Warriors come out on top i...   \n",
       "78   The man, known only as Xu, was keen to have a grandchild . He left the 'daughter-in-law' for £1,...   \n",
       "\n",
       "                       error_type       corrected_error_type  \\\n",
       "636  Intrinsic Circumstance Error     Intrinsic Entity Error   \n",
       "78      Extrinsic Predicate Error  Extrinsic Predicate Error   \n",
       "\n",
       "                                                                                                  scores  \n",
       "636  {'QAFactEval_edited': 0.42573932670000003, 'CoCo_edited': 0.35365559999999996, 'DAE_edited': 0.5...  \n",
       "78   {'QAFactEval_edited': 0.6213724862000001, 'CoCo_edited': 0.39436847, 'DAE_edited': 0.6608075, 'F...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BUMP\n",
    "\n",
    "bump = pd.read_json(\"https://raw.githubusercontent.com/dataminr-ai/BUMP/main/data/task1_dataset.json\", lines=False)\n",
    "\n",
    "print(bump['error_type'].value_counts())\n",
    "bump.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)As the model for Norman Rockwell's \"Rosie the Riveter,\" Mary Doyle Keefe became the symbol ...</td>\n",
       "      <td>Rosie the Riveter appeared on the cover of the Saturday Evening Post on May 29, 1943 . Mary Doyl...</td>\n",
       "      <td>1</td>\n",
       "      <td>bump</td>\n",
       "      <td>cnndm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(CNN)Famed cosmologist Stephen Hawking has proved his comedy chops on shows like \"The Big Bang T...</td>\n",
       "      <td>Stephen Hawking is a famed cosmologist and mathematician . He sings Monty Python's \"Galaxy Song\"...</td>\n",
       "      <td>1</td>\n",
       "      <td>bump</td>\n",
       "      <td>cnndm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   doc  \\\n",
       "0  (CNN)As the model for Norman Rockwell's \"Rosie the Riveter,\" Mary Doyle Keefe became the symbol ...   \n",
       "7  (CNN)Famed cosmologist Stephen Hawking has proved his comedy chops on shows like \"The Big Bang T...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  Rosie the Riveter appeared on the cover of the Saturday Evening Post on May 29, 1943 . Mary Doyl...   \n",
       "7  Stephen Hawking is a famed cosmologist and mathematician . He sings Monty Python's \"Galaxy Song\"...   \n",
       "\n",
       "   label benchmark source  \n",
       "0      1      bump  cnndm  \n",
       "7      1      bump  cnndm  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bump_correct = bump[['article', 'reference_summary']].rename(columns={'article': 'doc', 'reference_summary': 'summary'})\n",
    "bump_correct['label'] = 1\n",
    "\n",
    "\n",
    "bump_incorrect = bump[['article', 'edited_summary']].rename(columns={'article': 'doc', 'edited_summary': 'summary'})\n",
    "bump_incorrect['label'] = 0\n",
    "\n",
    "bump = pd.concat([bump_correct, bump_incorrect], axis=0)\n",
    "bump = bump.drop_duplicates(subset=['doc', 'summary'])\n",
    "\n",
    "\n",
    "bump['benchmark'] = 'bump'\n",
    "bump['source'] = 'cnndm'\n",
    "\n",
    "append_df(bump)\n",
    "bump.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    10000\n",
      "0    10000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwi...</td>\n",
       "      <td>Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media ...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>halueval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwi...</td>\n",
       "      <td>A video showing the final moments of Germanwings Flight 9525 has been recovered by investigators...</td>\n",
       "      <td>0</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>halueval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   doc  \\\n",
       "0  Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwi...   \n",
       "1  Marseille, France (CNN)The French prosecutor leading an investigation into the crash of Germanwi...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media ...   \n",
       "1  A video showing the final moments of Germanwings Flight 9525 has been recovered by investigators...   \n",
       "\n",
       "   label source benchmark  \n",
       "0      1  cnndm  halueval  \n",
       "1      0  cnndm  halueval  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HaluEval\n",
    "\n",
    "halueval = pd.read_json('https://raw.githubusercontent.com/RUCAIBox/HaluEval/main/data/summarization_data.json', lines=True)\n",
    "\n",
    "rows = []\n",
    "for row in halueval.itertuples():\n",
    "    document = row[1]\n",
    "    right_summary = row[2]\n",
    "    hallucinated_summary = row[3]\n",
    "    rows.append([document, right_summary, 1])\n",
    "    rows.append([document, hallucinated_summary, 0])\n",
    "\n",
    "\n",
    "# halueval.head(2)\n",
    "halueval = pd.DataFrame(rows, columns=['doc', 'summary', 'label'])\n",
    "halueval['source'] = 'cnndm'\n",
    "halueval['benchmark'] = 'halueval'\n",
    "\n",
    "print(halueval.label.value_counts())\n",
    "append_df(halueval)\n",
    "halueval.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raunak/micromamba/envs/zs-sum/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    3579\n",
      "1    3579\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>Strikes planned for Christmas were suspended after the new offer was made but members rejected i...</td>\n",
       "      <td>British Airways has suspended a further 2,000 customers from its contingency plan in a row of st...</td>\n",
       "      <td>0</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>For its 3-2 victory over a team backed by phone-maker Samsung, SKT's five members shared a prize...</td>\n",
       "      <td>SKT has won the League of Legends (LoL) final game.</td>\n",
       "      <td>1</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>That was just over over half of last year's haul, when the website auctioned a coffee meeting wi...</td>\n",
       "      <td>A lunch date with Mr Cook has sold on the auction website CharityBuzz.</td>\n",
       "      <td>1</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>He and his son Gorka were arrested earlier this month as part of a corruption investigation.\\nVi...</td>\n",
       "      <td>Suspended Spanish Football Federation head Villar has resigned from his role in Uefa.</td>\n",
       "      <td>1</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>The court in Novorossiysk gave two of the dancers 10 days in jail each, a third 15 days and two ...</td>\n",
       "      <td>A Russian court has sentenced three teenagers to jail for performing an \"erotic\" twerk dance at ...</td>\n",
       "      <td>0</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Media playback is unsupported on your device\\n16 December 2014 Last updated at 08:58 GMT\\nDr And...</td>\n",
       "      <td>Hospitals in Wales may have to cut back on non-urgent operations to cope with pressures over the...</td>\n",
       "      <td>0</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>( cnn ) a 32-year-old massachusetts man is facing murder charges , authorities said wednesday , ...</td>\n",
       "      <td>earlier this week , colina was arraigned on charges of assault and battery causing serious bodil...</td>\n",
       "      <td>0</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>The 26-year-old, who has been linked with a move to Real Madrid, fractured his right ankle while...</td>\n",
       "      <td>Chelsea's Hazard will miss the start of the Premier League season after having surgery on a brok...</td>\n",
       "      <td>1</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>The sturgeon, named Steve, swam out of World of Water in Romsey, Hampshire when it was inundated...</td>\n",
       "      <td>A fish that escaped from an aquatic shop during flooding has been found.</td>\n",
       "      <td>1</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>In 2014, a report by the public protector said Mr Zuma had \"benefited unduly\" from the upgrades....</td>\n",
       "      <td>President Jacob Zuma has agreed to repay at least some of the money controversially spent on upg...</td>\n",
       "      <td>1</td>\n",
       "      <td>xsum</td>\n",
       "      <td>fib</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      doc  \\\n",
       "2889  Strikes planned for Christmas were suspended after the new offer was made but members rejected i...   \n",
       "1009  For its 3-2 victory over a team backed by phone-maker Samsung, SKT's five members shared a prize...   \n",
       "2374  That was just over over half of last year's haul, when the website auctioned a coffee meeting wi...   \n",
       "2491  He and his son Gorka were arrested earlier this month as part of a corruption investigation.\\nVi...   \n",
       "1535  The court in Novorossiysk gave two of the dancers 10 days in jail each, a third 15 days and two ...   \n",
       "553   Media playback is unsupported on your device\\n16 December 2014 Last updated at 08:58 GMT\\nDr And...   \n",
       "3401  ( cnn ) a 32-year-old massachusetts man is facing murder charges , authorities said wednesday , ...   \n",
       "1861  The 26-year-old, who has been linked with a move to Real Madrid, fractured his right ankle while...   \n",
       "2842  The sturgeon, named Steve, swam out of World of Water in Romsey, Hampshire when it was inundated...   \n",
       "163   In 2014, a report by the public protector said Mr Zuma had \"benefited unduly\" from the upgrades....   \n",
       "\n",
       "                                                                                                  summary  \\\n",
       "2889  British Airways has suspended a further 2,000 customers from its contingency plan in a row of st...   \n",
       "1009                                                  SKT has won the League of Legends (LoL) final game.   \n",
       "2374                               A lunch date with Mr Cook has sold on the auction website CharityBuzz.   \n",
       "2491                Suspended Spanish Football Federation head Villar has resigned from his role in Uefa.   \n",
       "1535  A Russian court has sentenced three teenagers to jail for performing an \"erotic\" twerk dance at ...   \n",
       "553   Hospitals in Wales may have to cut back on non-urgent operations to cope with pressures over the...   \n",
       "3401  earlier this week , colina was arraigned on charges of assault and battery causing serious bodil...   \n",
       "1861  Chelsea's Hazard will miss the start of the Premier League season after having surgery on a brok...   \n",
       "2842                             A fish that escaped from an aquatic shop during flooding has been found.   \n",
       "163   President Jacob Zuma has agreed to repay at least some of the money controversially spent on upg...   \n",
       "\n",
       "      label source benchmark  \n",
       "2889      0   xsum       fib  \n",
       "1009      1   xsum       fib  \n",
       "2374      1   xsum       fib  \n",
       "2491      1   xsum       fib  \n",
       "1535      0   xsum       fib  \n",
       "553       0   xsum       fib  \n",
       "3401      0  cnndm       fib  \n",
       "1861      1   xsum       fib  \n",
       "2842      1   xsum       fib  \n",
       "163       1   xsum       fib  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIB\n",
    "\n",
    "fib = load_dataset(\"r-three/fib\")['test']\n",
    "fib_df = fib.to_pandas()\n",
    "fib_df = fib_df.explode('list_choices')\n",
    "\n",
    "# fib_df.loc[fib_df['correct_choice'] == fib_df['list_choices'], 'label'] = 1\n",
    "# fib_df.loc[fib_df['correct_choice'] != fib_df['list_choices'], 'label'] = 0\n",
    "\n",
    "def fix(row):\n",
    "    choice = row['list_choices']\n",
    "    correct_choice = row['correct_choice']\n",
    "    \n",
    "    if choice == correct_choice:\n",
    "        row['label'] = 1\n",
    "    else:\n",
    "        row['label'] = 0\n",
    "        \n",
    "    return row\n",
    "\n",
    "fib_df = fib_df.apply(fix, axis=1)\n",
    "\n",
    "fib_df = fib_df[['input', 'list_choices', 'label', 'dataset']].rename(columns={'input': 'doc', \n",
    "                                                                                 'list_choices': 'summary', \n",
    "                                                                                 'dataset': 'source'\n",
    "                                                                                 })\n",
    "\n",
    "fib_df['summary'] = fib_df['summary'].apply(lambda x: x.replace('<t>', ' ').replace('</t>', ' ').strip())\n",
    "fib_df['summary'] = fib_df['summary'].apply(lambda x: ' '.join(x.split()))\n",
    "fib_df['label'] = fib_df['label'].astype(int)\n",
    "\n",
    "fib_df['benchmark'] = 'fib'\n",
    "fib_df['source'] = fib_df['source'].replace({\"cnn_dm\": \"cnndm\"})\n",
    "\n",
    "print(fib_df.label.value_counts())\n",
    "append_df(fib_df)\n",
    "fib_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    2992\n",
      "0     564\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN)Two years ago, the storied Boston Marathon ended in terror and altered the lives of runners...</td>\n",
       "      <td>The two bombers who killed 3 and injured 264 were sentenced to death.\\n\\nThe two bombers who kil...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>llm_summaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>She might be a new mother to twins but that didn't prevent a fresh-faced Charlene of Monaco from...</td>\n",
       "      <td>What is the main idea of the article?\\n\\nWhat is the main idea of the article?\\n\\nWhat is the ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>llm_summaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    doc  \\\n",
       "0   (CNN)Two years ago, the storied Boston Marathon ended in terror and altered the lives of runners...   \n",
       "12  She might be a new mother to twins but that didn't prevent a fresh-faced Charlene of Monaco from...   \n",
       "\n",
       "                                                                                                summary  \\\n",
       "0   The two bombers who killed 3 and injured 264 were sentenced to death.\\n\\nThe two bombers who kil...   \n",
       "12  What is the main idea of the article?\\n\\nWhat is the main idea of the article?\\n\\nWhat is the ma...   \n",
       "\n",
       "    label source      benchmark  \n",
       "0       1  cnndm  llm_summaries  \n",
       "12      0  cnndm  llm_summaries  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zhang et al. (LLM Summaries) https://arxiv.org/abs/2301.13848\n",
    "\n",
    "llm_summaries = pd.read_json('https://raw.githubusercontent.com/Tiiiger/benchmark_llm_summarization/main/likert_evaluation_results.json', lines=False)\n",
    "llm_summaries = llm_summaries.rename(columns={'article': 'doc', 'summary': 'summary', 'faithfulness': 'label', 'dataset': 'source'})\n",
    "llm_summaries = llm_summaries[['doc', 'summary', 'label', 'source']]\n",
    "llm_summaries.dropna(inplace=True)\n",
    "llm_summaries.drop_duplicates(subset=['summary'], inplace=True)\n",
    "\n",
    "remove = \"original article\"\n",
    "llm_summaries = llm_summaries[~llm_summaries['summary'].str.contains(remove)]\n",
    "\n",
    "llm_summaries['benchmark'] = 'llm_summaries'\n",
    "print(llm_summaries.label.value_counts())\n",
    "append_df(llm_summaries)\n",
    "llm_summaries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    60\n",
      "0    36\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The prevalence of discrimination across racial groups in contemporary America: Results from a na...</td>\n",
       "      <td>A new study by Kessler and colleagues estimates the prevalence of discrimination across racial g...</td>\n",
       "      <td>0</td>\n",
       "      <td>gumsum</td>\n",
       "      <td>gumsum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The prevalence of discrimination across racial groups in contemporary America: Results from a na...</td>\n",
       "      <td>This study is the first to estimate the prevalence of discrimination across racial groups in con...</td>\n",
       "      <td>0</td>\n",
       "      <td>gumsum</td>\n",
       "      <td>gumsum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   doc  \\\n",
       "0  The prevalence of discrimination across racial groups in contemporary America: Results from a na...   \n",
       "1  The prevalence of discrimination across racial groups in contemporary America: Results from a na...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  A new study by Kessler and colleagues estimates the prevalence of discrimination across racial g...   \n",
       "1  This study is the first to estimate the prevalence of discrimination across racial groups in con...   \n",
       "\n",
       "   label  source benchmark  \n",
       "0      0  gumsum    gumsum  \n",
       "1      0  gumsum    gumsum  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GUMSUM\n",
    "\n",
    "path = \"../data/test-data/GUMSum4EVAL/data/GUMSum_final.json\"\n",
    "\n",
    "gumsum_dict = json.load(io.open(path))\n",
    "labels = pd.read_csv('../data/test-data/GUMSum4EVAL/data/labels.csv')\n",
    "\n",
    "gumsum = pd.DataFrame()\n",
    "cols = ['doc', 'summary', 'label']\n",
    "\n",
    "for row in labels.itertuples():\n",
    "    key = row[1]\n",
    "    brio = row[2]\n",
    "    simcls = row[3]\n",
    "    gpt3 = row[4]\n",
    "    human = row[5]\n",
    "    \n",
    "    fulltext = gumsum_dict[key]['fulltext']\n",
    "    brio_summary = gumsum_dict[key]['brio']\n",
    "    simcls_summary = gumsum_dict[key]['simcls']\n",
    "    gpt3_summary = gumsum_dict[key]['gpt3']\n",
    "    human_summary = gumsum_dict[key]['human1']\n",
    "    \n",
    "    row1 = [ fulltext, brio_summary, brio]\n",
    "    row2 = [ fulltext, simcls_summary, simcls]\n",
    "    row3 = [ fulltext, gpt3_summary, gpt3]\n",
    "    row4 = [fulltext, human_summary, human]\n",
    "    \n",
    "    gumsum = pd.concat([gumsum, pd.DataFrame([row1, row2, row3, row4], columns=cols)], axis=0)\n",
    "    \n",
    "    \n",
    "gumsum = gumsum.replace({'label': {'yes': 0, 'no': 1}})\n",
    "gumsum['source'] = 'gumsum'\n",
    "gumsum['benchmark'] = 'gumsum'\n",
    "\n",
    "print(gumsum.label.value_counts())\n",
    "\n",
    "append_df(gumsum)\n",
    "\n",
    "gumsum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#InstruSum\n",
    "instrusum = load_dataset(\"Salesforce/InstruSum\", \"human_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 12750.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    387\n",
      "0    113\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I was shaking with rage and stress, I couldn't believe this had happened.\" By Dan WhitworthMone...</td>\n",
       "      <td>Lloyds Bank has refunded more than £14,000 stolen from the account of a dementia sufferer after ...</td>\n",
       "      <td>1</td>\n",
       "      <td>instrusum</td>\n",
       "      <td>instrusum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I was shaking with rage and stress, I couldn't believe this had happened.\" By Dan WhitworthMone...</td>\n",
       "      <td>Lloyds Bank has apologized and refunded over £14,000, plus interest and £600 in compensation, to...</td>\n",
       "      <td>1</td>\n",
       "      <td>instrusum</td>\n",
       "      <td>instrusum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   doc  \\\n",
       "0  \"I was shaking with rage and stress, I couldn't believe this had happened.\" By Dan WhitworthMone...   \n",
       "1  \"I was shaking with rage and stress, I couldn't believe this had happened.\" By Dan WhitworthMone...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  Lloyds Bank has refunded more than £14,000 stolen from the account of a dementia sufferer after ...   \n",
       "1  Lloyds Bank has apologized and refunded over £14,000, plus interest and £600 in compensation, to...   \n",
       "\n",
       "   label     source  benchmark  \n",
       "0      1  instrusum  instrusum  \n",
       "1      1  instrusum  instrusum  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "append_rows = []\n",
    "\n",
    "for row in tqdm(instrusum['data']):\n",
    "    # pprint(row)\n",
    "    doc = row['article']\n",
    "    annotations = row['annotations']\n",
    "    for annotation in annotations:\n",
    "        # print(annotation)\n",
    "        summary = annotations[annotation]['summary']\n",
    "        label = int(annotations[annotation]['score']['factual'])\n",
    "        # print(doc, summary, label)\n",
    "        append_rows.append([doc, summary, label])\n",
    "        # break\n",
    "    # break\n",
    "\n",
    "x = pd.DataFrame(append_rows, columns=['doc', 'summary', 'label'])\n",
    "x['source'] = 'instrusum'\n",
    "x['benchmark'] = 'instrusum'\n",
    "\n",
    "print(x.label.value_counts())\n",
    "\n",
    "append_df(x)\n",
    "\n",
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TofuEval - MediaSum\n",
    "\n",
    "def obtain_dialogue_mediasum(dialogue_selected):\n",
    "    dialogue_df = pd.DataFrame(columns=['doc_id', 'source'])\n",
    "    for dialogue in dialogue_selected:\n",
    "        dialogue_id = dialogue['id']\n",
    "        speakers = dialogue['speaker']\n",
    "        utts = dialogue['utt']\n",
    "        transcript = ''\n",
    "        for speaker, utt in zip(speakers, utts):\n",
    "            transcript += f\"{speaker}: {utt}\\n\"\n",
    "        transcript = transcript.strip()\n",
    "        dialogue_df.loc[len(dialogue_df)] = [dialogue_id, transcript]\n",
    "    return dialogue_df\n",
    "\n",
    "base_path = \"../data/test-data/tofueval/\"\n",
    "\n",
    "with open(base_path+\"document_ids_dev_test_split.json\") as file:\n",
    "    document_mapping = json.load(file)\n",
    "\n",
    "meetingbank_dev_ids = document_mapping['dev']['meetingbank']\n",
    "meetingbank_test_ids = document_mapping['test']['meetingbank']\n",
    "mediasum_dev_ids = document_mapping['dev']['mediasum']\n",
    "mediasum_test_ids = document_mapping['test']['mediasum']\n",
    "\n",
    "\n",
    "meetingbank = pd.DataFrame(load_dataset(\"lytang/MeetingBank-transcript\")['test'])\n",
    "meetingbank[meetingbank.meeting_id.isin(meetingbank_dev_ids)][['meeting_id', 'source']].reset_index(drop=True).to_csv(base_path+\"meetingbank_dev_doc.csv\", index=False)\n",
    "meetingbank[meetingbank.meeting_id.isin(meetingbank_test_ids)][['meeting_id', 'source']].reset_index(drop=True).to_csv(base_path+\"meetingbank_test_doc.csv\", index=False)\n",
    "\n",
    "meetingbank_dev = pd.read_csv(base_path+\"meetingbank_dev_doc.csv\")\n",
    "meetingbank_test = pd.read_csv(base_path+\"meetingbank_test_doc.csv\")\n",
    "\n",
    "\n",
    "with open(base_path+\"news_dialogue.json\") as file:\n",
    "    news_dialogue = json.load(file)\n",
    "dialogue_dev = [dialogue for dialogue in news_dialogue if dialogue['id'] in mediasum_dev_ids]\n",
    "dialogue_test = [dialogue for dialogue in news_dialogue if dialogue['id'] in mediasum_test_ids]\n",
    "\n",
    "obtain_dialogue_mediasum(dialogue_dev).to_csv(base_path+\"mediasum_dev_doc.csv\", index=False)\n",
    "obtain_dialogue_mediasum(dialogue_test).to_csv(base_path+\"mediasum_test_doc.csv\", index=False)\n",
    "\n",
    "mediasum_dev = pd.read_csv(base_path+\"mediasum_dev_doc.csv\")\n",
    "mediasum_test = pd.read_csv(base_path+\"mediasum_test_doc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediasum_eval_dev = pd.read_csv(\"https://raw.githubusercontent.com/amazon-science/tofueval/main/factual_consistency/mediasum_factual_eval_dev.csv\")\n",
    "mediasum_eval_test = pd.read_csv(\"https://raw.githubusercontent.com/amazon-science/tofueval/main/factual_consistency/mediasum_factual_eval_test.csv\")\n",
    "\n",
    "meetingbank_eval_dev = pd.read_csv(\"https://raw.githubusercontent.com/amazon-science/tofueval/main/factual_consistency/meetingbank_factual_eval_dev.csv\")\n",
    "meetingbank_eval_test = pd.read_csv(\"https://raw.githubusercontent.com/amazon-science/tofueval/main/factual_consistency/meetingbank_factual_eval_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Speaker 0: Thank you very much. That concludes public comment. We're going on to Iowa. We have t...</td>\n",
       "      <td>Reduction in conditional use permit fees for development services in Long Beach, California.</td>\n",
       "      <td>1</td>\n",
       "      <td>meetingbank</td>\n",
       "      <td>tofueval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Speaker 0: Thank you very much. That concludes public comment. We're going on to Iowa. We have t...</td>\n",
       "      <td>Fee reduction of $950 and establishment of a new tiered fee structure for public noticing.</td>\n",
       "      <td>1</td>\n",
       "      <td>meetingbank</td>\n",
       "      <td>tofueval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   doc  \\\n",
       "0  Speaker 0: Thank you very much. That concludes public comment. We're going on to Iowa. We have t...   \n",
       "1  Speaker 0: Thank you very much. That concludes public comment. We're going on to Iowa. We have t...   \n",
       "\n",
       "                                                                                        summary  \\\n",
       "0  Reduction in conditional use permit fees for development services in Long Beach, California.   \n",
       "1    Fee reduction of $950 and establishment of a new tiered fee structure for public noticing.   \n",
       "\n",
       "   label       source benchmark  \n",
       "0      1  meetingbank  tofueval  \n",
       "1      1  meetingbank  tofueval  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediasum_dev_final = mediasum_dev.merge(mediasum_eval_dev, left_on='doc_id', right_on='doc_id', how='inner')\n",
    "mediasum_dev_final['label'] = mediasum_dev_final['sent_label'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "mediasum_dev_final['doc'] = mediasum_dev_final['source']\n",
    "mediasum_dev_final['summary'] = mediasum_dev_final['summ_sent']\n",
    "mediasum_dev_final['source'] = 'mediasum'\n",
    "mediasum_dev_final['benchmark'] = 'tofueval'\n",
    "\n",
    "mediasum_dev_final = mediasum_dev_final[['doc', 'summary', 'label', 'source', 'benchmark']]\n",
    "\n",
    "mediasum_test_final = mediasum_test.merge(mediasum_eval_test, left_on='doc_id', right_on='doc_id', how='inner')\n",
    "mediasum_test_final['label'] = mediasum_test_final['sent_label'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "mediasum_test_final['doc'] = mediasum_test_final['source']\n",
    "mediasum_test_final['summary'] = mediasum_test_final['summ_sent']\n",
    "mediasum_test_final['source'] = 'mediasum'\n",
    "mediasum_test_final['benchmark'] = 'tofueval'\n",
    "\n",
    "mediasum_test_final = mediasum_test_final[['doc', 'summary', 'label', 'source', 'benchmark']]\n",
    "# mediasum_test_final.head(2)\n",
    "\n",
    "meetingbank_dev_final = meetingbank_dev.merge(meetingbank_eval_dev, left_on='meeting_id', right_on='doc_id', how='inner')\n",
    "meetingbank_dev_final['label'] = meetingbank_dev_final['sent_label'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "meetingbank_dev_final['doc'] = meetingbank_dev_final['source']\n",
    "meetingbank_dev_final['summary'] = meetingbank_dev_final['summ_sent']\n",
    "meetingbank_dev_final['source'] = 'meetingbank'\n",
    "meetingbank_dev_final['benchmark'] = 'tofueval'\n",
    "\n",
    "meetingbank_dev_final = meetingbank_dev_final[['doc', 'summary', 'label', 'source', 'benchmark']]\n",
    "\n",
    "meetingbank_test_final = meetingbank_test.merge(meetingbank_eval_test, left_on='meeting_id', right_on='doc_id', how='inner')\n",
    "meetingbank_test_final['label'] = meetingbank_test_final['sent_label'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "meetingbank_test_final['doc'] = meetingbank_test_final['source']\n",
    "meetingbank_test_final['summary'] = meetingbank_test_final['summ_sent']\n",
    "meetingbank_test_final['source'] = 'meetingbank'\n",
    "meetingbank_test_final['benchmark'] = 'tofueval'\n",
    "\n",
    "meetingbank_test_final = meetingbank_test_final[['doc', 'summary', 'label', 'source', 'benchmark']]\n",
    "\n",
    "append_df(mediasum_test_final)\n",
    "append_df(meetingbank_test_final)\n",
    "\n",
    "meetingbank_test_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    1334\n",
      "0     290\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    627\n",
      "0    150\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    1459\n",
      "0     354\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "1    561\n",
      "0    172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print label value counts\n",
    "print(meetingbank_dev_final.label.value_counts())\n",
    "print(meetingbank_test_final.label.value_counts())\n",
    "print(mediasum_dev_final.label.value_counts())\n",
    "print(mediasum_test_final.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Diversumm\n",
    "\n",
    "# diversumm = pd.read_csv(\"https://raw.githubusercontent.com/HJZnlp/Infuse/main/DiverSumm.csv\")[['doc','summary','label','origin']]\n",
    "\n",
    "# diversumm = diversumm[diversumm['origin'].isin(['multinews','qmsum'])]\n",
    "# diversumm = diversumm.rename(columns={'origin':'source'})\n",
    "\n",
    "# diversumm['benchmark'] = 'unisumm'\n",
    "\n",
    "\n",
    "# append_df(diversumm)\n",
    "\n",
    "# diversumm.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiaSumFact\n",
    "\n",
    "# https://aclanthology.org/2023.acl-long.377/\n",
    "\n",
    "import json \n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/731935354/Dia-Sum-Fact/main/annotations.json'\n",
    "response = requests.get(url)\n",
    "annotations = response.json()\n",
    "\n",
    "\n",
    "diasumfact = []\n",
    "for k, v in annotations.items():\n",
    "    utterances = v['utterances']\n",
    "    dataset_name = v['dataset_name']\n",
    "    doc = \"\\n\".join([u for u in utterances])\n",
    "    predictions = v['annotations']\n",
    "    for _, prediction in predictions.items():\n",
    "        sentence_annotations = prediction['sentence_annotations']\n",
    "        for s in sentence_annotations:\n",
    "            sentence = s['sentence']\n",
    "            label = s['annotation'][0]['error_class']\n",
    "            diasumfact.append([doc, sentence, label, dataset_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    853\n",
       "0    487\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diasumfact = pd.DataFrame(diasumfact, columns=['doc', 'summary', 'label', 'source'])\n",
    "diasumfact['benchmark'] = 'diasumfact'\n",
    "\n",
    "# replace \"No Error\" with 1 and everything else with 0\n",
    "diasumfact['label'] = diasumfact['label'].apply(lambda x: 1 if x == \"No Error\" else 0)\n",
    "\n",
    "\n",
    "append_df(diasumfact)\n",
    "diasumfact.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # zero_shot_faceval_domains\n",
    "\n",
    "# cols = ['article', 'summary', 'score', 'task']\n",
    "\n",
    "# zero_shot_faceval_billsum = pd.read_csv(\"https://raw.githubusercontent.com/sanjanaramprasad/zero_shot_faceval_domains/main/datasets/annotations/billsum_annotation_scores.csv\")[cols]\n",
    "# zero_shot_faceval_news = pd.read_csv(\"https://raw.githubusercontent.com/sanjanaramprasad/zero_shot_faceval_domains/main/datasets/annotations/news_annotation_scores.csv\")[cols]\n",
    "# zero_shot_faceval_pubmed = pd.read_csv(\"https://raw.githubusercontent.com/sanjanaramprasad/zero_shot_faceval_domains/main/datasets/annotations/pubmed_annotation_scores.csv\")[cols]\n",
    "\n",
    "# # replace scores < 1 with 0 and 1.0 with 1\n",
    "# zero_shot_faceval_billsum['score'] = zero_shot_faceval_billsum['score'].apply(lambda x: 1 if x == 1.0 else 0)\n",
    "# zero_shot_faceval_news['score'] = zero_shot_faceval_news['score'].apply(lambda x: 1 if x == 1.0 else 0)\n",
    "# zero_shot_faceval_pubmed['score'] = zero_shot_faceval_pubmed['score'].apply(lambda x: 1 if x == 1.0 else 0)\n",
    "\n",
    "# zero_shot_faceval_billsum = zero_shot_faceval_billsum[['article', 'summary', 'score', 'task']].rename(columns={'article': 'doc', 'task': 'source', 'score': 'label'})\n",
    "# zero_shot_faceval_news = zero_shot_faceval_news[['article', 'summary', 'score', 'task']].rename(columns={'article': 'doc', 'task': 'source', 'score': 'label'})\n",
    "# zero_shot_faceval_pubmed = zero_shot_faceval_pubmed[['article', 'summary', 'score', 'task']].rename(columns={'article': 'doc', 'task': 'source', 'score': 'label'})\n",
    "\n",
    "# zero_shot_faceval = pd.concat([zero_shot_faceval_billsum, zero_shot_faceval_news, zero_shot_faceval_pubmed], axis=0)\n",
    "# zero_shot_faceval['benchmark'] = 'zero_shot_faceval'\n",
    "\n",
    "# append_df(zero_shot_faceval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring...</td>\n",
       "      <td>lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day ....</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential ...</td>\n",
       "      <td>a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalen...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   doc  \\\n",
       "0  looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring...   \n",
       "1  tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential ...   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day ....   \n",
       "1  a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalen...   \n",
       "\n",
       "   label source  benchmark  length  \n",
       "0      1  cnndm  aggrefact     507  \n",
       "1      1  cnndm  aggrefact     460  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total words\n",
    "\n",
    "\n",
    "def count_words(row):\n",
    "    doc = row['doc']\n",
    "    summary = row['summary']\n",
    "    words = len(doc.split()) + len(summary.split())\n",
    "    row['length'] = words\n",
    "    return row\n",
    "\n",
    "all_test_dfs = all_test_dfs.apply(count_words, axis=1)\n",
    "all_test_dfs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21705375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_dfs['length'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>source_dataset</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring...</td>\n",
       "      <td>lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day ....</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential ...</td>\n",
       "      <td>a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalen...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more than 25 women have been airlifted from royal navy ships because of pregnancy .\\none ship - ...</td>\n",
       "      <td>more than 25 women have been airlifted from royal navy ships because of pregnancy . \\none ship -...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breast cancer patients may be spared chemotherapy thanks to new tests that pinpoint genetic ` ma...</td>\n",
       "      <td>breast cancer patients may be spared chemotherapy thanks to new tests . \\ntests pinpoint genetic...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazing pictures have emerged of blue fluorescent algae lighting up australia 's east coast .\\nt...</td>\n",
       "      <td>amazing pictures have emerged of blue fluorescent algae lighting up australia 's east coast . \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>cnndm</td>\n",
       "      <td>aggrefact</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...</td>\n",
       "      <td>we're trying to agree with partners, including estyn and the welsh government, a broader range o...</td>\n",
       "      <td>1</td>\n",
       "      <td>QMSum</td>\n",
       "      <td>diasumfact</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...</td>\n",
       "      <td>david hopkins thought that the delegation levels were already very high in most authority areas,...</td>\n",
       "      <td>1</td>\n",
       "      <td>QMSum</td>\n",
       "      <td>diasumfact</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...</td>\n",
       "      <td>on the additional learning needs side, although the minister had currently made some more money ...</td>\n",
       "      <td>1</td>\n",
       "      <td>QMSum</td>\n",
       "      <td>diasumfact</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...</td>\n",
       "      <td>the delegation levels were already very high in most authority areas, and they had got agreement...</td>\n",
       "      <td>1</td>\n",
       "      <td>QMSum</td>\n",
       "      <td>diasumfact</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...</td>\n",
       "      <td>on the additional learning needs side, whilst the minister had currently made some more money av...</td>\n",
       "      <td>1</td>\n",
       "      <td>QMSum</td>\n",
       "      <td>diasumfact</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37298 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   source  \\\n",
       "0     looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring...   \n",
       "1     tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential ...   \n",
       "2     more than 25 women have been airlifted from royal navy ships because of pregnancy .\\none ship - ...   \n",
       "3     breast cancer patients may be spared chemotherapy thanks to new tests that pinpoint genetic ` ma...   \n",
       "4     amazing pictures have emerged of blue fluorescent algae lighting up australia 's east coast .\\nt...   \n",
       "...                                                                                                   ...   \n",
       "1335  david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...   \n",
       "1336  david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...   \n",
       "1337  david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...   \n",
       "1338  david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...   \n",
       "1339  david hopkins: Yes, sure. The delegation levels are already very high in most authority areas, a...   \n",
       "\n",
       "                                                                                                   target  \\\n",
       "0     lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day ....   \n",
       "1     a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalen...   \n",
       "2     more than 25 women have been airlifted from royal navy ships because of pregnancy . \\none ship -...   \n",
       "3     breast cancer patients may be spared chemotherapy thanks to new tests . \\ntests pinpoint genetic...   \n",
       "4     amazing pictures have emerged of blue fluorescent algae lighting up australia 's east coast . \\n...   \n",
       "...                                                                                                   ...   \n",
       "1335  we're trying to agree with partners, including estyn and the welsh government, a broader range o...   \n",
       "1336  david hopkins thought that the delegation levels were already very high in most authority areas,...   \n",
       "1337  on the additional learning needs side, although the minister had currently made some more money ...   \n",
       "1338  the delegation levels were already very high in most authority areas, and they had got agreement...   \n",
       "1339  on the additional learning needs side, whilst the minister had currently made some more money av...   \n",
       "\n",
       "      label source_dataset   benchmark  length  \n",
       "0         1          cnndm   aggrefact     507  \n",
       "1         1          cnndm   aggrefact     460  \n",
       "2         1          cnndm   aggrefact     606  \n",
       "3         1          cnndm   aggrefact     641  \n",
       "4         1          cnndm   aggrefact     358  \n",
       "...     ...            ...         ...     ...  \n",
       "1335      1          QMSum  diasumfact     409  \n",
       "1336      1          QMSum  diasumfact     432  \n",
       "1337      1          QMSum  diasumfact     459  \n",
       "1338      1          QMSum  diasumfact     429  \n",
       "1339      1          QMSum  diasumfact     447  \n",
       "\n",
       "[37298 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_dfs = all_test_dfs.rename({\n",
    "    'doc': 'source',\n",
    "    'summary': 'target',\n",
    "    'source': 'source_dataset',\n",
    "}, axis=1)\n",
    "\n",
    "\n",
    "all_test_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 1 and 0 with Yes and No in the label column\n",
    "\n",
    "all_test_dfs['label'] = all_test_dfs['label'].replace({1: 'Yes', 0: 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(benchmark\n",
       " halueval         20000\n",
       " fib               7158\n",
       " llm_summaries     3556\n",
       " aggrefact         2353\n",
       " tofueval          1510\n",
       " diasumfact        1340\n",
       " bump               785\n",
       " instrusum          500\n",
       " gumsum              96\n",
       " Name: count, dtype: int64,\n",
       " source_dataset\n",
       " cnndm          24546\n",
       " xsum            9306\n",
       " meetingbank      777\n",
       " SAMSum           757\n",
       " mediasum         733\n",
       " QMSum            583\n",
       " instrusum        500\n",
       " gumsum            96\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " Yes    20739\n",
       " No     16559\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_dfs['benchmark'].value_counts(), all_test_dfs['source_dataset'].value_counts(), all_test_dfs.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine source_dataset and benchmark into one column called benchmark\n",
    "all_test_dfs['subset'] =  all_test_dfs['benchmark'] + \"_\" + all_test_dfs['source_dataset'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = ['source', 'target', 'label', 'subset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_testset = pd.read_json(\"../data/combined-test.jsonl\", lines=True)\n",
    "\n",
    "# join the two dataframes\n",
    "all_test_dfs = pd.concat([all_test_dfs[output_columns], other_testset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "halueval_cnndm          20000\n",
       "fib_xsum                 6244\n",
       "alisawuffles/WANLI       5000\n",
       "Seahorse                 4138\n",
       "anli                     3200\n",
       "scitail                  2126\n",
       "DeFacto                  1848\n",
       "llm_summaries_cnndm      1829\n",
       "llm_summaries_xsum       1727\n",
       "FoolMeTwice              1379\n",
       "aggrefact_xsum           1335\n",
       "aggrefact_cnndm          1018\n",
       "fib_cnndm                 914\n",
       "bump_cnndm                785\n",
       "tofueval_meetingbank      777\n",
       "DADC-NLI                  766\n",
       "diasumfact_SAMSum         757\n",
       "tofueval_mediasum         733\n",
       "diasumfact_QMSum          583\n",
       "instrusum_instrusum       500\n",
       "WiCE                      358\n",
       "gumsum_gumsum              96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_dfs['subset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_dfs[output_columns].\\\n",
    "    to_json('../data/test-data/benchmark_test_data.json', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_dfs[output_columns].sample(frac=0.1).\\\n",
    "    to_json('../data/test-data/test.json', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52853"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduplicate the data\n",
    "\n",
    "test_data = pd.read_json(\"../data/test-data/benchmark_test_data.json\", lines=True)\n",
    "\n",
    "\n",
    "import hashlib\n",
    "\n",
    "def get_hash(row):\n",
    "    source = row['source']\n",
    "    target = row['target']\n",
    "    row['hash'] = hashlib.md5(f\"{source}{target}\".encode()).hexdigest()\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "test_data = test_data.apply(get_hash, axis=1)\n",
    "\n",
    "test_data = test_data.drop_duplicates(subset=['hash'])\n",
    "\n",
    "len(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[output_columns].\\\n",
    "    to_json('../data/test-data/benchmark_test_data.json', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, target, label, subset]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_dfs = pd.read_json('../data/test-data/benchmark_test_data.json', lines=True)\n",
    "\n",
    "all_test_dfs[all_test_dfs['subset'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add llm_aggrefact to the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>doc</th>\n",
       "      <th>claim</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>Lfqa</td>\n",
       "      <td>[1] When it comes to tire design, the most important factor is the ability of air to be compress...</td>\n",
       "      <td>This makes air-filled tires particularly useful for high-speed automobiles, since they are able ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9486</th>\n",
       "      <td>ExpertQA</td>\n",
       "      <td>Community-based tourism approach for The Bahamas: The fundamentals, pt.1 - The Nassau Guardian t...</td>\n",
       "      <td>This type of tourism contributes to the well-being of communities.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset  \\\n",
       "11275      Lfqa   \n",
       "9486   ExpertQA   \n",
       "\n",
       "                                                                                                       doc  \\\n",
       "11275  [1] When it comes to tire design, the most important factor is the ability of air to be compress...   \n",
       "9486   Community-based tourism approach for The Bahamas: The fundamentals, pt.1 - The Nassau Guardian t...   \n",
       "\n",
       "                                                                                                     claim  \\\n",
       "11275  This makes air-filled tires particularly useful for high-speed automobiles, since they are able ...   \n",
       "9486                                    This type of tourism contributes to the well-being of communities.   \n",
       "\n",
       "       label  \n",
       "11275      1  \n",
       "9486       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "llm_aggrefact = load_dataset(\"lytang/LLM-AggreFact\")\n",
    "llm_aggrefact = llm_aggrefact['test'].to_pandas()\n",
    "llm_aggrefact.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12949\n",
      "12939\n"
     ]
    }
   ],
   "source": [
    "llm_aggrefact = llm_aggrefact.rename(columns={'doc': 'source', 'claim': 'target', 'label': 'label', 'dataset': 'subset'})\n",
    "\n",
    "# replace 1 and 0 with Yes and No\n",
    "def replace_label(row):\n",
    "    label = row['label']\n",
    "    if label == 1:\n",
    "        row['label'] = 'Yes'\n",
    "    else:\n",
    "        row['label'] = 'No'\n",
    "    return row\n",
    "print(len(llm_aggrefact))\n",
    "llm_aggrefact = llm_aggrefact.apply(replace_label, axis=1).drop_duplicates(subset=['source', 'target'])\n",
    "print(len(llm_aggrefact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AggreFact-CNN\n",
      "label\n",
      "Yes    501\n",
      "No      57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AggreFact-XSum\n",
      "label\n",
      "Yes    285\n",
      "No     273\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TofuEval-MediaS\n",
      "label\n",
      "Yes    553\n",
      "No     172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TofuEval-MeetB\n",
      "label\n",
      "Yes    620\n",
      "No     150\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Wice\n",
      "label\n",
      "No     247\n",
      "Yes    111\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Reveal\n",
      "label\n",
      "No     1307\n",
      "Yes     398\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ClaimVerify\n",
      "label\n",
      "Yes    789\n",
      "No     298\n",
      "Name: count, dtype: int64\n",
      "\n",
      "FactCheck-GPT\n",
      "label\n",
      "No     1189\n",
      "Yes     376\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ExpertQA\n",
      "label\n",
      "Yes    2971\n",
      "No      731\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Lfqa\n",
      "label\n",
      "Yes    1121\n",
      "No      790\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(subset\n",
       " ExpertQA         3702\n",
       " Lfqa             1911\n",
       " Reveal           1705\n",
       " FactCheck-GPT    1565\n",
       " ClaimVerify      1087\n",
       " Name: count, dtype: int64,\n",
       " subset\n",
       " AggreFact-CNN     558\n",
       " AggreFact-XSum    558\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label value counts for each subset\n",
    "\n",
    "for subset in llm_aggrefact['subset'].unique():\n",
    "    print(subset)\n",
    "    print(llm_aggrefact[llm_aggrefact['subset'] == subset]['label'].value_counts())\n",
    "    print()\n",
    "\n",
    "# Create a subset for llm_aggrefact without \"AggreFact-CNN\", \"AggreFact-XSum\", \"TofuEval-MediaS\", \"TofuEval-MeetB\", \"wice\"\n",
    "\n",
    "to_remove = [\"AggreFact-CNN\", \"AggreFact-XSum\", \"TofuEval-MediaS\", \"TofuEval-MeetB\", \"Wice\"]\n",
    "aggrefact_keep = [\"AggreFact-CNN\", \"AggreFact-XSum\"]\n",
    "llm_aggrefact_partial = llm_aggrefact[~llm_aggrefact['subset'].isin(to_remove)]\n",
    "llm_aggrefact_partial_2 = llm_aggrefact[llm_aggrefact['subset'].isin(aggrefact_keep)]\n",
    "\n",
    "llm_aggrefact_partial['subset'].value_counts(), llm_aggrefact_partial_2['subset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52853\n",
      "9970\n",
      "62823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add llm_aggrefact_partial to the final benchmark test data\n",
    "\n",
    "df = pd.read_json('../data/test-data/benchmark_test_data.json', lines=True)\n",
    "final_combined_df = pd.concat([df, llm_aggrefact_partial[output_columns]], axis=0)\n",
    "\n",
    "print(len(df)), print(len(llm_aggrefact_partial)), print(len(final_combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823\n"
     ]
    }
   ],
   "source": [
    "final_combined_df = final_combined_df.drop_duplicates(subset=['source', 'target'])\n",
    "print(len(final_combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_aggrefact[output_columns].to_json('../data/test-data/llm_aggrefact.json', orient='records', lines=True, force_ascii=False)\n",
    "llm_aggrefact_partial[output_columns].to_json('../data/test-data/llm_aggrefact_partial.json', orient='records', lines=True, force_ascii=False)\n",
    "final_combined_df[output_columns].to_json('../data/test-data/final_combined_test_data.json', orient='records', lines=True, force_ascii=False)\n",
    "llm_aggrefact_partial_2[output_columns].to_json('../data/test-data/llm_aggrefact_partial_2.json', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"source\":\"looking after elderly parents can be difficult at the best of times .\\nbut this man takes caring for his alzheimer 's - suffering mother to another level .\\na security guard from china has touched hearts across the country because he takes his 84-year-old mother with him to work on the back of his motorbike every single day , reported the people 's daily online .\\nlu xincai , who lives in zhejiang province in eastern china , says that he is scared his mother will get lost if he leaves her at home by herself because she suffers from the degenerative disease .\\ndevoted : lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day .\\nhe ties a sash around both of their waists to make sure she does n't fall off\\nshe would often go up to the mountains to collect firewood and there were a few occasions when she got lost after dark .\\nwhen mr lu 's father passed away earlier this year , he decided to take his mother with him to work because there was no one else who could look after her .\\nhis wife works in a different city and his son is still in school .\\nafter helping his mother to get up at 5 am every morning , he puts her on the back seat of his motorbike and ties a sash around both of their waists to ensure that she does not fall off .\\nmr lu said that he rides the four kilometres to work slowly to make sure his mother feels safe and so that they can chat along the way .\\nthe whole journey takes an hour .\\neven when at work he checks up on his mother , who has been given her own room by his employers , a bank , to make sure that she has not wandered off somewhere .\\nhe said that his mother devoted her life to caring for her children , and now he feels like he has a duty to care for her in return .\\nvulnerable : his elderly mother suffers from alzheimer 's and used to get lost when she was left alone\\nhe said : ` i was an apple in my mum 's eye , and now she 's my apple . '\\n` our mother carried us on her back to the fields when she went to work on the farm and collect firewood when we were young . '\\nhe added : ` only if i see her will i feel relaxed .\\notherwise i would be afraid is she had wandered away . '\",\"target\":\"lu xincai takes his 84-year-old mother to work with him on the back of his motorbike every day . \\nhis mother suffers from alzheimer 's and used to get lost when she was left alone . \\nhe ties a sash around both of their waists to ensure that she does not fall off .\",\"label\":\"Yes\",\"subset\":\"aggrefact_cnndm\"}\n",
      "{\"source\":\"tokyo ( cnn ) a bizarre and alarming discovery is raising concerns in japan about the potential for terrorism involving drones .\\na drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house on wednesday , police and government officials said .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant in kagoshima prefecture , more than four years after the fukushima daiichi nuclear disaster .\\nprime minister shinzo abe 's push to restart the reactors is unpopular among many japanese , who view nuclear energy as too dangerous .\\na staff member spotted the drone wednesday morning on the roof of abe 's residence , tokyo metropolitan police said .\\ndozens of police investigators were dispatched to the roof to investigate the origin of the drone , which had four propeller and was 50 centimeters ( 20 inches ) wide .\\npolice say the drone was equipped with a small camera , smoke flares and a plastic bottle containing small traces of a radioactive material believed to be cesium , a common byproduct of nuclear reactors .\\ncesium was also discovered in areas around the failed fukushima daiichi nuclear plant after its 2011 meltdown .\\ninvestigators suspect the cesium was placed in the bottle .\\nthe amount inside is not immediately harmful to humans .\\nchief cabinet secretary yoshihide suga said the discovery is raising concerns about terrorism .\\n\\\" there might be terrorism attempts in the future at the olympics and g7 summit using drones , \\\" suga said .\\n\\\" so we need to examine and review continuously the way small unmanned vehicles like drones should be operated and how to cope with the threat of terrorism from drones .\\nthe government will do all that we can to prevent terrorism . \\\"\\njapanese law restricts drone flights around airports to prevent problems with aircraft , but there are no flight restrictions for most of tokyo , including the prime minister 's residence and local and federal government buildings .\\nabe was not in his office at the time .\\nhe is in indonesia , attending the asian-african conference .\\ncnn 's elizabeth joseph , joshua berlinger and josh levs contributed to this report .\",\"target\":\"a drone carrying traces of a radioactive material was found on the rooftop of japan 's equivalent to the white house .\\nthe discovery came on the same day a japanese court approved a government plan to restart two reactors at the sendai nuclear power plant . \\nthe drone was equipped with a small camera , smoke flares and a bottle containing small traces of cesium .\",\"label\":\"Yes\",\"subset\":\"aggrefact_cnndm\"}\n"
     ]
    }
   ],
   "source": [
    "# !head -n 2 ../data/test-data/benchmark_test_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62823\n",
      "subset\n",
      "halueval_cnndm          19998\n",
      "alisawuffles/WANLI       5000\n",
      "Seahorse                 4135\n",
      "ExpertQA                 3702\n",
      "fib_xsum                 3534\n",
      "anli                     3200\n",
      "scitail                  2126\n",
      "Lfqa                     1911\n",
      "DeFacto                  1836\n",
      "llm_summaries_cnndm      1829\n",
      "llm_summaries_xsum       1726\n",
      "Reveal                   1705\n",
      "FactCheck-GPT            1565\n",
      "FoolMeTwice              1379\n",
      "aggrefact_xsum           1335\n",
      "ClaimVerify              1087\n",
      "aggrefact_cnndm          1017\n",
      "bump_cnndm                785\n",
      "tofueval_meetingbank      770\n",
      "DADC-NLI                  766\n",
      "tofueval_mediasum         725\n",
      "diasumfact_SAMSum         669\n",
      "diasumfact_QMSum          569\n",
      "fib_cnndm                 543\n",
      "instrusum_instrusum       458\n",
      "WiCE                      358\n",
      "gumsum_gumsum              95\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "Yes    31469\n",
      "No     31354\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # test loading\n",
    "\n",
    "# df = pd.read_json('../data/test-data/final_combined_test_data.json', lines=True)\n",
    "# print(len(df))\n",
    "# print(df['subset'].value_counts())\n",
    "# print(df['label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
